


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torch.nn &mdash; PyTorch master documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/docs/stable/nn.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="torch.nn.functional" href="nn.functional.html" />
    <link rel="prev" title="torch.Storage" href="storage.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/features">Features</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://pytorch.org/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>

  </div>
</div>


<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  master (1.2.0a0+31599e5 )
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
<div>
  <a style="color:#F05732" href="https://pytorch.org/docs/stable/nn.html">
    You are viewing unstable developer preview docs.
    Click here to view docs for latest stable release.
  </a>
</div>

            
            
              
            
            
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="notes/autograd.html">Autograd mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/broadcasting.html">Broadcasting semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/cuda.html">CUDA semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/extending.html">Extending PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/large_scale_deployments.html">Features for large-scale deployments</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/multiprocessing.html">Multiprocessing best practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/randomness.html">Reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/serialization.html">Serialization semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/windows.html">Windows FAQ</a></li>
</ul>
<p class="caption"><span class="caption-text">Community</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="community/contribution_guide.html">PyTorch Contribution Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="community/governance.html">PyTorch Governance</a></li>
<li class="toctree-l1"><a class="reference internal" href="community/persons_of_interest.html">PyTorch Governance | Persons of Interest</a></li>
</ul>
<p class="caption"><span class="caption-text">Package Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="torch.html">torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensors.html">torch.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_attributes.html">Tensor Attributes</a></li>
<li class="toctree-l1"><a class="reference internal" href="type_info.html">Type Info</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse.html">torch.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="cuda.html">torch.cuda</a></li>
<li class="toctree-l1"><a class="reference internal" href="storage.html">torch.Storage</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">torch.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.functional.html">torch.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.init.html">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">torch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="autograd.html">torch.autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.html">torch.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributions.html">torch.distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="hub.html">torch.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="jit.html">torch.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="multiprocessing.html">torch.multiprocessing</a></li>
<li class="toctree-l1"><a class="reference internal" href="bottleneck.html">torch.utils.bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="checkpoint.html">torch.utils.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpp_extension.html">torch.utils.cpp_extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="data.html">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="dlpack.html">torch.utils.dlpack</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_zoo.html">torch.utils.model_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensorboard.html">torch.utils.tensorboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="onnx.html">torch.onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="__config__.html">torch.__config__</a></li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>torch.nn</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="_sources/nn.rst.txt" rel="nofollow"><img src="_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="section" id="module-torch.nn">
<span id="torch-nn"></span><h1>torch.nn<a class="headerlink" href="#module-torch.nn" title="Permalink to this headline">¶</a></h1>
<div class="section" id="parameters">
<h2>Parameters<a class="headerlink" href="#parameters" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torch.nn.Parameter">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">Parameter</code><a class="reference internal" href="_modules/torch/nn/parameter.html#Parameter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Parameter" title="Permalink to this definition">¶</a></dt>
<dd><p>A kind of Tensor that is to be considered a module parameter.</p>
<p>Parameters are <a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></a> subclasses, that have a
very special property when used with <a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a> s - when they’re
assigned as Module attributes they are automatically added to the list of
its parameters, and will appear e.g. in <a class="reference internal" href="#torch.nn.Module.parameters" title="torch.nn.Module.parameters"><code class="xref py py-meth docutils literal notranslate"><span class="pre">parameters()</span></code></a> iterator.
Assigning a Tensor doesn’t have such effect. This is because one might
want to cache some temporary state, like last hidden state of the RNN, in
the model. If there was no such class as <a class="reference internal" href="#torch.nn.Parameter" title="torch.nn.Parameter"><code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code></a>, these
temporaries would get registered too.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>data</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – parameter tensor.</p></li>
<li><p><strong>requires_grad</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – if the parameter requires gradient. See
<a class="reference internal" href="notes/autograd.html#excluding-subgraphs"><span class="std std-ref">Excluding subgraphs from backward</span></a> for more details. Default: <cite>True</cite></p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="containers">
<h2>Containers<a class="headerlink" href="#containers" title="Permalink to this headline">¶</a></h2>
<div class="section" id="module">
<h3><span class="hidden-section">Module</span><a class="headerlink" href="#module" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.Module">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">Module</code><a class="reference internal" href="_modules/torch/nn/modules/module.html#Module"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Module" title="Permalink to this definition">¶</a></dt>
<dd><p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>

<span class="k">class</span> <span class="nc">Model</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Model</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call <a class="reference internal" href="#torch.nn.Module.to" title="torch.nn.Module.to"><code class="xref py py-meth docutils literal notranslate"><span class="pre">to()</span></code></a>, etc.</p>
<dl class="method">
<dt id="torch.nn.Module.add_module">
<code class="sig-name descname">add_module</code><span class="sig-paren">(</span><em class="sig-param">name</em>, <em class="sig-param">module</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/module.html#Module.add_module"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Module.add_module" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a child module to the current module.</p>
<p>The module can be accessed as an attribute using the given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>string</em>) – name of the child module. The child module can be
accessed from this module using the given name</p></li>
<li><p><strong>module</strong> (<a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module"><em>Module</em></a>) – child module to be added to the module.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch.nn.Module.apply">
<code class="sig-name descname">apply</code><span class="sig-paren">(</span><em class="sig-param">fn</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/module.html#Module.apply"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Module.apply" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies <code class="docutils literal notranslate"><span class="pre">fn</span></code> recursively to every submodule (as returned by <code class="docutils literal notranslate"><span class="pre">.children()</span></code>)
as well as self. Typical use includes initializing the parameters of a model
(see also <span class="xref std std-ref">torch-nn-init</span>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fn</strong> (<a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a> -&gt; None) – function to be applied to each submodule</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module">Module</a></p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">m</span><span class="p">)</span> <span class="o">==</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">fill_</span><span class="p">(</span><span class="mf">1.0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">init_weights</span><span class="p">)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 1.,  1.],</span>
<span class="go">        [ 1.,  1.]])</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 1.,  1.],</span>
<span class="go">        [ 1.,  1.]])</span>
<span class="go">Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">)</span>
<span class="go">Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="torch.nn.Module.buffers">
<code class="sig-name descname">buffers</code><span class="sig-paren">(</span><em class="sig-param">recurse=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/module.html#Module.buffers"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Module.buffers" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over module buffers.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>recurse</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – if True, then yields buffers of this module
and all submodules. Otherwise, yields only buffers that
are direct members of this module.</p>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>torch.Tensor</em> – module buffer</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">buf</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">buffers</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">buf</span><span class="o">.</span><span class="n">data</span><span class="p">),</span> <span class="n">buf</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">&lt;class &#39;torch.FloatTensor&#39;&gt; (20L,)</span>
<span class="go">&lt;class &#39;torch.FloatTensor&#39;&gt; (20L, 1L, 5L, 5L)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="torch.nn.Module.children">
<code class="sig-name descname">children</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/module.html#Module.children"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Module.children" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over immediate children modules.</p>
<dl class="field-list simple">
<dt class="field-odd">Yields</dt>
<dd class="field-odd"><p><em>Module</em> – a child module</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch.nn.Module.cpu">
<code class="sig-name descname">cpu</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/module.html#Module.cpu"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Module.cpu" title="Permalink to this definition">¶</a></dt>
<dd><p>Moves all model parameters and buffers to the CPU.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module">Module</a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch.nn.Module.cuda">
<code class="sig-name descname">cuda</code><span class="sig-paren">(</span><em class="sig-param">device=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/module.html#Module.cuda"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Module.cuda" title="Permalink to this definition">¶</a></dt>
<dd><p>Moves all model parameters and buffers to the GPU.</p>
<p>This also makes associated parameters and buffers different objects. So
it should be called before constructing optimizer if the module will
live on GPU while being optimized.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>device</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em>) – if specified, all parameters will be
copied to that device</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module">Module</a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch.nn.Module.double">
<code class="sig-name descname">double</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/module.html#Module.double"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Module.double" title="Permalink to this definition">¶</a></dt>
<dd><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">double</span></code> datatype.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module">Module</a></p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="torch.nn.Module.dump_patches">
<code class="sig-name descname">dump_patches</code><em class="property"> = False</em><a class="headerlink" href="#torch.nn.Module.dump_patches" title="Permalink to this definition">¶</a></dt>
<dd><p>This allows better BC support for <a class="reference internal" href="#torch.nn.Module.load_state_dict" title="torch.nn.Module.load_state_dict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">load_state_dict()</span></code></a>. In
<a class="reference internal" href="#torch.nn.Module.state_dict" title="torch.nn.Module.state_dict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code></a>, the version number will be saved as in the attribute
<cite>_metadata</cite> of the returned state dict, and thus pickled. <cite>_metadata</cite> is a
dictionary with keys that follow the naming convention of state dict. See
<code class="docutils literal notranslate"><span class="pre">_load_from_state_dict</span></code> on how to use this information in loading.</p>
<p>If new parameters/buffers are added/removed from a module, this number shall
be bumped, and the module’s <cite>_load_from_state_dict</cite> method can compare the
version number and do appropriate changes if the state dict is from before
the change.</p>
</dd></dl>

<dl class="method">
<dt id="torch.nn.Module.eval">
<code class="sig-name descname">eval</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/module.html#Module.eval"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Module.eval" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the module in evaluation mode.</p>
<p>This has any effect only on certain modules. See documentations of
particular modules for details of their behaviors in training/evaluation
mode, if they are affected, e.g. <a class="reference internal" href="#torch.nn.Dropout" title="torch.nn.Dropout"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dropout</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">BatchNorm</span></code>,
etc.</p>
<p>This is equivalent with <a class="reference internal" href="#torch.nn.Module.train" title="torch.nn.Module.train"><code class="xref py py-meth docutils literal notranslate"><span class="pre">self.train(False)</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module">Module</a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch.nn.Module.extra_repr">
<code class="sig-name descname">extra_repr</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/module.html#Module.extra_repr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Module.extra_repr" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the extra representation of the module</p>
<p>To print customized extra information, you should reimplement
this method in your own modules. Both single-line and multi-line
strings are acceptable.</p>
</dd></dl>

<dl class="method">
<dt id="torch.nn.Module.float">
<code class="sig-name descname">float</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/module.html#Module.float"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Module.float" title="Permalink to this definition">¶</a></dt>
<dd><p>Casts all floating point parameters and buffers to float datatype.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module">Module</a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch.nn.Module.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">*input</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/module.html#Module.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Module.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="torch.nn.Module.half">
<code class="sig-name descname">half</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/module.html#Module.half"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Module.half" title="Permalink to this definition">¶</a></dt>
<dd><p>Casts all floating point parameters and buffers to <code class="docutils literal notranslate"><span class="pre">half</span></code> datatype.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>self</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module">Module</a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch.nn.Module.load_state_dict">
<code class="sig-name descname">load_state_dict</code><span class="sig-paren">(</span><em class="sig-param">state_dict</em>, <em class="sig-param">strict=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/module.html#Module.load_state_dict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Module.load_state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Copies parameters and buffers from <a class="reference internal" href="#torch.nn.Module.state_dict" title="torch.nn.Module.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> into
this module and its descendants. If <code class="xref py py-attr docutils literal notranslate"><span class="pre">strict</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, then
the keys of <a class="reference internal" href="#torch.nn.Module.state_dict" title="torch.nn.Module.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> must exactly match the keys returned
by this module’s <a class="reference internal" href="#torch.nn.Module.state_dict" title="torch.nn.Module.state_dict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code></a> function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>state_dict</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)"><em>dict</em></a>) – a dict containing parameters and
persistent buffers.</p></li>
<li><p><strong>strict</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – whether to strictly enforce that the keys
in <a class="reference internal" href="#torch.nn.Module.state_dict" title="torch.nn.Module.state_dict"><code class="xref py py-attr docutils literal notranslate"><span class="pre">state_dict</span></code></a> match the keys returned by this module’s
<a class="reference internal" href="#torch.nn.Module.state_dict" title="torch.nn.Module.state_dict"><code class="xref py py-meth docutils literal notranslate"><span class="pre">state_dict()</span></code></a> function. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>missing_keys</strong> is a list of str containing the missing keys</p></li>
<li><p><strong>unexpected_keys</strong> is a list of str containing the unexpected keys</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">NamedTuple</span></code> with <code class="docutils literal notranslate"><span class="pre">missing_keys</span></code> and <code class="docutils literal notranslate"><span class="pre">unexpected_keys</span></code> fields</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch.nn.Module.modules">
<code class="sig-name descname">modules</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/module.html#Module.modules"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Module.modules" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over all modules in the network.</p>
<dl class="field-list simple">
<dt class="field-odd">Yields</dt>
<dd class="field-odd"><p><em>Module</em> – a module in the network</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Duplicate modules are returned only once. In the following
example, <code class="docutils literal notranslate"><span class="pre">l</span></code> will be returned only once.</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">modules</span><span class="p">()):</span>
<span class="go">        print(idx, &#39;-&gt;&#39;, m)</span>

<span class="go">0 -&gt; Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">)</span>
<span class="go">1 -&gt; Linear(in_features=2, out_features=2, bias=True)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="torch.nn.Module.named_buffers">
<code class="sig-name descname">named_buffers</code><span class="sig-paren">(</span><em class="sig-param">prefix=''</em>, <em class="sig-param">recurse=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/module.html#Module.named_buffers"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Module.named_buffers" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over module buffers, yielding both the
name of the buffer as well as the buffer itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prefix</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a>) – prefix to prepend to all buffer names.</p></li>
<li><p><strong>recurse</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – if True, then yields buffers of this module
and all submodules. Otherwise, yields only buffers that
are direct members of this module.</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>(string, torch.Tensor)</em> – Tuple containing the name and buffer</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">buf</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_buffers</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;running_var&#39;</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>       <span class="nb">print</span><span class="p">(</span><span class="n">buf</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="torch.nn.Module.named_children">
<code class="sig-name descname">named_children</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/module.html#Module.named_children"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Module.named_children" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over immediate children modules, yielding both
the name of the module as well as the module itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Yields</dt>
<dd class="field-odd"><p><em>(string, Module)</em> – Tuple containing a name and child module</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">module</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_children</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;conv4&#39;</span><span class="p">,</span> <span class="s1">&#39;conv5&#39;</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>        <span class="nb">print</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="torch.nn.Module.named_modules">
<code class="sig-name descname">named_modules</code><span class="sig-paren">(</span><em class="sig-param">memo=None</em>, <em class="sig-param">prefix=''</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/module.html#Module.named_modules"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Module.named_modules" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over all modules in the network, yielding
both the name of the module as well as the module itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Yields</dt>
<dd class="field-odd"><p><em>(string, Module)</em> – Tuple of name and module</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Duplicate modules are returned only once. In the following
example, <code class="docutils literal notranslate"><span class="pre">l</span></code> will be returned only once.</p>
</div>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">l</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">l</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">m</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">named_modules</span><span class="p">()):</span>
<span class="go">        print(idx, &#39;-&gt;&#39;, m)</span>

<span class="go">0 -&gt; (&#39;&#39;, Sequential(</span>
<span class="go">  (0): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">  (1): Linear(in_features=2, out_features=2, bias=True)</span>
<span class="go">))</span>
<span class="go">1 -&gt; (&#39;0&#39;, Linear(in_features=2, out_features=2, bias=True))</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="torch.nn.Module.named_parameters">
<code class="sig-name descname">named_parameters</code><span class="sig-paren">(</span><em class="sig-param">prefix=''</em>, <em class="sig-param">recurse=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/module.html#Module.named_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Module.named_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over module parameters, yielding both the
name of the parameter as well as the parameter itself.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>prefix</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a>) – prefix to prepend to all parameter names.</p></li>
<li><p><strong>recurse</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – if True, then yields parameters of this module
and all submodules. Otherwise, yields only parameters that
are direct members of this module.</p></li>
</ul>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>(string, Parameter)</em> – Tuple containing the name and parameter</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>   <span class="k">if</span> <span class="n">name</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;bias&#39;</span><span class="p">]:</span>
<span class="gp">&gt;&gt;&gt; </span>       <span class="nb">print</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="torch.nn.Module.parameters">
<code class="sig-name descname">parameters</code><span class="sig-paren">(</span><em class="sig-param">recurse=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/module.html#Module.parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Module.parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns an iterator over module parameters.</p>
<p>This is typically passed to an optimizer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>recurse</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – if True, then yields parameters of this module
and all submodules. Otherwise, yields only parameters that
are direct members of this module.</p>
</dd>
<dt class="field-even">Yields</dt>
<dd class="field-even"><p><em>Parameter</em> – module parameter</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
<span class="gp">&gt;&gt;&gt; </span>    <span class="nb">print</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">param</span><span class="o">.</span><span class="n">data</span><span class="p">),</span> <span class="n">param</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">&lt;class &#39;torch.FloatTensor&#39;&gt; (20L,)</span>
<span class="go">&lt;class &#39;torch.FloatTensor&#39;&gt; (20L, 1L, 5L, 5L)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="torch.nn.Module.register_backward_hook">
<code class="sig-name descname">register_backward_hook</code><span class="sig-paren">(</span><em class="sig-param">hook</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/module.html#Module.register_backward_hook"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Module.register_backward_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a backward hook on the module.</p>
<p>The hook will be called every time the gradients with respect to module
inputs are computed. The hook should have the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">grad_input</span><span class="p">,</span> <span class="n">grad_output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span> <span class="ow">or</span> <span class="kc">None</span>
</pre></div>
</div>
<p>The <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> may be tuples if the
module has multiple inputs or outputs. The hook should not modify its
arguments, but it can optionally return a new gradient with respect to
input that will be used in place of <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> in subsequent
computations.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The current implementation will not have the presented behavior
for complex <a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a> that perform many operations.
In some failure cases, <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_input</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">grad_output</span></code> will only
contain the gradients for a subset of the inputs and outputs.
For such <a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a>, you should use <a class="reference internal" href="tensors.html#torch.Tensor.register_hook" title="torch.Tensor.register_hook"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.Tensor.register_hook()</span></code></a>
directly on a specific input or output to get the required gradients.</p>
</div>
</dd></dl>

<dl class="method">
<dt id="torch.nn.Module.register_buffer">
<code class="sig-name descname">register_buffer</code><span class="sig-paren">(</span><em class="sig-param">name</em>, <em class="sig-param">tensor</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/module.html#Module.register_buffer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Module.register_buffer" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a persistent buffer to the module.</p>
<p>This is typically used to register a buffer that should not to be
considered a model parameter. For example, BatchNorm’s <code class="docutils literal notranslate"><span class="pre">running_mean</span></code>
is not a parameter, but is part of the persistent state.</p>
<p>Buffers can be accessed as attributes using given names.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>string</em>) – name of the buffer. The buffer can be accessed
from this module using the given name</p></li>
<li><p><strong>tensor</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – buffer to be registered.</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;running_mean&#39;</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">num_features</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="torch.nn.Module.register_forward_hook">
<code class="sig-name descname">register_forward_hook</code><span class="sig-paren">(</span><em class="sig-param">hook</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/module.html#Module.register_forward_hook"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Module.register_forward_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a forward hook on the module.</p>
<p>The hook will be called every time after <a class="reference internal" href="#torch.nn.Module.forward" title="torch.nn.Module.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> has computed an output.
It should have the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="nb">input</span><span class="p">,</span> <span class="n">output</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="n">output</span>
</pre></div>
</div>
<p>The hook can modify the output. It can modify the input inplace but
it will not have effect on forward since this is called after
<a class="reference internal" href="#torch.nn.Module.forward" title="torch.nn.Module.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> is called.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch.nn.Module.register_forward_pre_hook">
<code class="sig-name descname">register_forward_pre_hook</code><span class="sig-paren">(</span><em class="sig-param">hook</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/module.html#Module.register_forward_pre_hook"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Module.register_forward_pre_hook" title="Permalink to this definition">¶</a></dt>
<dd><p>Registers a forward pre-hook on the module.</p>
<p>The hook will be called every time before <a class="reference internal" href="#torch.nn.Module.forward" title="torch.nn.Module.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> is invoked.
It should have the following signature:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">hook</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="nb">input</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">modified</span> <span class="nb">input</span>
</pre></div>
</div>
<p>The hook can modify the input. User can either return a tuple or a
single modified value in the hook. We will wrap the value into a tuple
if a single value is returned(unless that value is already a tuple).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a handle that can be used to remove the added hook by calling
<code class="docutils literal notranslate"><span class="pre">handle.remove()</span></code></p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.utils.hooks.RemovableHandle</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch.nn.Module.register_parameter">
<code class="sig-name descname">register_parameter</code><span class="sig-paren">(</span><em class="sig-param">name</em>, <em class="sig-param">param</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/module.html#Module.register_parameter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Module.register_parameter" title="Permalink to this definition">¶</a></dt>
<dd><p>Adds a parameter to the module.</p>
<p>The parameter can be accessed as an attribute using given name.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>string</em>) – name of the parameter. The parameter can be accessed
from this module using the given name</p></li>
<li><p><strong>param</strong> (<a class="reference internal" href="#torch.nn.Parameter" title="torch.nn.Parameter"><em>Parameter</em></a>) – parameter to be added to the module.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch.nn.Module.requires_grad_">
<code class="sig-name descname">requires_grad_</code><span class="sig-paren">(</span><em class="sig-param">requires_grad=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/module.html#Module.requires_grad_"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Module.requires_grad_" title="Permalink to this definition">¶</a></dt>
<dd><p>Change if autograd should record operations on parameters in this
module.</p>
<p>This method sets the parameters’ <code class="xref py py-attr docutils literal notranslate"><span class="pre">requires_grad</span></code> attributes
in-place.</p>
<p>This method is helpful for freezing part of the module for finetuning
or training parts of a model individually (e.g., GAN training).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>requires_grad</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – whether autograd should record operations on
parameters in this module. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module">Module</a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch.nn.Module.state_dict">
<code class="sig-name descname">state_dict</code><span class="sig-paren">(</span><em class="sig-param">destination=None</em>, <em class="sig-param">prefix=''</em>, <em class="sig-param">keep_vars=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/module.html#Module.state_dict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Module.state_dict" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns a dictionary containing a whole state of the module.</p>
<p>Both parameters and persistent buffers (e.g. running averages) are
included. Keys are corresponding parameter and buffer names.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a dictionary containing a whole state of the module</p>
</dd>
<dt class="field-even">Return type</dt>
<dd class="field-even"><p><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)">dict</a></p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">module</span><span class="o">.</span><span class="n">state_dict</span><span class="p">()</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
<span class="go">[&#39;bias&#39;, &#39;weight&#39;]</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="torch.nn.Module.to">
<code class="sig-name descname">to</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/module.html#Module.to"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Module.to" title="Permalink to this definition">¶</a></dt>
<dd><p>Moves and/or casts the parameters and buffers.</p>
<p>This can be called as</p>
<dl class="function">
<dt>
<code class="sig-name descname">to</code><span class="sig-paren">(</span><em class="sig-param">device=None</em>, <em class="sig-param">dtype=None</em>, <em class="sig-param">non_blocking=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/module.html#Module.to"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="function">
<dt>
<code class="sig-name descname">to</code><span class="sig-paren">(</span><em class="sig-param">dtype</em>, <em class="sig-param">non_blocking=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/module.html#Module.to"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<dl class="function">
<dt>
<code class="sig-name descname">to</code><span class="sig-paren">(</span><em class="sig-param">tensor</em>, <em class="sig-param">non_blocking=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/module.html#Module.to"><span class="viewcode-link">[source]</span></a></dt>
<dd></dd></dl>

<p>Its signature is similar to <a class="reference internal" href="tensors.html#torch.Tensor.to" title="torch.Tensor.to"><code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.Tensor.to()</span></code></a>, but only accepts
floating point desired <code class="xref py py-attr docutils literal notranslate"><span class="pre">dtype</span></code> s. In addition, this method will
only cast the floating point parameters and buffers to <code class="xref py py-attr docutils literal notranslate"><span class="pre">dtype</span></code>
(if given). The integral parameters and buffers will be moved
<code class="xref py py-attr docutils literal notranslate"><span class="pre">device</span></code>, if that is given, but with dtypes unchanged. When
<code class="xref py py-attr docutils literal notranslate"><span class="pre">non_blocking</span></code> is set, it tries to convert/move asynchronously
with respect to the host if possible, e.g., moving CPU Tensors with
pinned memory to CUDA devices.</p>
<p>See below for examples.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This method modifies the module in-place.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>device</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.device</span></code>) – the desired device of the parameters
and buffers in this module</p></li>
<li><p><strong>dtype</strong> (<code class="xref py py-class docutils literal notranslate"><span class="pre">torch.dtype</span></code>) – the desired floating point type of
the floating point parameters and buffers in this module</p></li>
<li><p><strong>tensor</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>torch.Tensor</em></a>) – Tensor whose dtype and device are the desired
dtype and device for all parameters and buffers in this module</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module">Module</a></p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 0.1913, -0.3420],</span>
<span class="go">        [-0.5113, -0.2325]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">double</span><span class="p">)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 0.1913, -0.3420],</span>
<span class="go">        [-0.5113, -0.2325]], dtype=torch.float64)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gpu1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:1&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">gpu1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">half</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 0.1914, -0.3420],</span>
<span class="go">        [-0.5112, -0.2324]], dtype=torch.float16, device=&#39;cuda:1&#39;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cpu</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">cpu</span><span class="p">)</span>
<span class="go">Linear(in_features=2, out_features=2, bias=True)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span>
<span class="go">Parameter containing:</span>
<span class="go">tensor([[ 0.1914, -0.3420],</span>
<span class="go">        [-0.5112, -0.2324]], dtype=torch.float16)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="torch.nn.Module.train">
<code class="sig-name descname">train</code><span class="sig-paren">(</span><em class="sig-param">mode=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/module.html#Module.train"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Module.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets the module in training mode.</p>
<p>This has any effect only on certain modules. See documentations of
particular modules for details of their behaviors in training/evaluation
mode, if they are affected, e.g. <a class="reference internal" href="#torch.nn.Dropout" title="torch.nn.Dropout"><code class="xref py py-class docutils literal notranslate"><span class="pre">Dropout</span></code></a>, <code class="xref py py-class docutils literal notranslate"><span class="pre">BatchNorm</span></code>,
etc.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – whether to set training mode (<code class="docutils literal notranslate"><span class="pre">True</span></code>) or evaluation
mode (<code class="docutils literal notranslate"><span class="pre">False</span></code>). Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module">Module</a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch.nn.Module.type">
<code class="sig-name descname">type</code><span class="sig-paren">(</span><em class="sig-param">dst_type</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/module.html#Module.type"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Module.type" title="Permalink to this definition">¶</a></dt>
<dd><p>Casts all parameters and buffers to <code class="xref py py-attr docutils literal notranslate"><span class="pre">dst_type</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dst_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#type" title="(in Python v3.7)"><em>type</em></a><em> or </em><em>string</em>) – the desired type</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>self</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module">Module</a></p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch.nn.Module.zero_grad">
<code class="sig-name descname">zero_grad</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/module.html#Module.zero_grad"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Module.zero_grad" title="Permalink to this definition">¶</a></dt>
<dd><p>Sets gradients of all model parameters to zero.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="sequential">
<h3><span class="hidden-section">Sequential</span><a class="headerlink" href="#sequential" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.Sequential">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">Sequential</code><span class="sig-paren">(</span><em class="sig-param">*args</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/container.html#Sequential"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Sequential" title="Permalink to this definition">¶</a></dt>
<dd><p>A sequential container.
Modules will be added to it in the order they are passed in the constructor.
Alternatively, an ordered dict of modules can also be passed in.</p>
<p>To make it easier to understand, here is a small example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Example of using Sequential</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
          <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span>
          <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(),</span>
          <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">5</span><span class="p">),</span>
          <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="p">)</span>

<span class="c1"># Example of using Sequential with OrderedDict</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">OrderedDict</span><span class="p">([</span>
          <span class="p">(</span><span class="s1">&#39;conv1&#39;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">)),</span>
          <span class="p">(</span><span class="s1">&#39;relu1&#39;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()),</span>
          <span class="p">(</span><span class="s1">&#39;conv2&#39;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">5</span><span class="p">)),</span>
          <span class="p">(</span><span class="s1">&#39;relu2&#39;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">())</span>
        <span class="p">]))</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="modulelist">
<h3><span class="hidden-section">ModuleList</span><a class="headerlink" href="#modulelist" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.ModuleList">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">ModuleList</code><span class="sig-paren">(</span><em class="sig-param">modules=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/container.html#ModuleList"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ModuleList" title="Permalink to this definition">¶</a></dt>
<dd><p>Holds submodules in a list.</p>
<p><a class="reference internal" href="#torch.nn.ModuleList" title="torch.nn.ModuleList"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModuleList</span></code></a> can be indexed like a regular Python list, but
modules it contains are properly registered, and will be visible by all
<a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a> methods.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>modules</strong> (<em>iterable</em><em>, </em><em>optional</em>) – an iterable of modules to add</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyModule</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MyModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linears</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)])</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># ModuleList can act as an iterable, or be indexed using ints</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">l</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linears</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linears</span><span class="p">[</span><span class="n">i</span> <span class="o">//</span> <span class="mi">2</span><span class="p">](</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">l</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
<dl class="method">
<dt id="torch.nn.ModuleList.append">
<code class="sig-name descname">append</code><span class="sig-paren">(</span><em class="sig-param">module</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/container.html#ModuleList.append"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ModuleList.append" title="Permalink to this definition">¶</a></dt>
<dd><p>Appends a given module to the end of the list.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>module</strong> (<a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module"><em>nn.Module</em></a>) – module to append</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch.nn.ModuleList.extend">
<code class="sig-name descname">extend</code><span class="sig-paren">(</span><em class="sig-param">modules</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/container.html#ModuleList.extend"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ModuleList.extend" title="Permalink to this definition">¶</a></dt>
<dd><p>Appends modules from a Python iterable to the end of the list.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>modules</strong> (<em>iterable</em>) – iterable of modules to append</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch.nn.ModuleList.insert">
<code class="sig-name descname">insert</code><span class="sig-paren">(</span><em class="sig-param">index</em>, <em class="sig-param">module</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/container.html#ModuleList.insert"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ModuleList.insert" title="Permalink to this definition">¶</a></dt>
<dd><p>Insert a given module before a given index in the list.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – index to insert.</p></li>
<li><p><strong>module</strong> (<a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module"><em>nn.Module</em></a>) – module to insert</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="moduledict">
<h3><span class="hidden-section">ModuleDict</span><a class="headerlink" href="#moduledict" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.ModuleDict">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">ModuleDict</code><span class="sig-paren">(</span><em class="sig-param">modules=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/container.html#ModuleDict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ModuleDict" title="Permalink to this definition">¶</a></dt>
<dd><p>Holds submodules in a dictionary.</p>
<p><a class="reference internal" href="#torch.nn.ModuleDict" title="torch.nn.ModuleDict"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModuleDict</span></code></a> can be indexed like a regular Python dictionary,
but modules it contains are properly registered, and will be visible by all
<a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a> methods.</p>
<p><a class="reference internal" href="#torch.nn.ModuleDict" title="torch.nn.ModuleDict"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModuleDict</span></code></a> is an <strong>ordered</strong> dictionary that respects</p>
<ul class="simple">
<li><p>the order of insertion, and</p></li>
<li><p>in <a class="reference internal" href="#torch.nn.ModuleDict.update" title="torch.nn.ModuleDict.update"><code class="xref py py-meth docutils literal notranslate"><span class="pre">update()</span></code></a>, the order of the merged <code class="docutils literal notranslate"><span class="pre">OrderedDict</span></code>
or another <a class="reference internal" href="#torch.nn.ModuleDict" title="torch.nn.ModuleDict"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModuleDict</span></code></a> (the argument to <a class="reference internal" href="#torch.nn.ModuleDict.update" title="torch.nn.ModuleDict.update"><code class="xref py py-meth docutils literal notranslate"><span class="pre">update()</span></code></a>).</p></li>
</ul>
<p>Note that <a class="reference internal" href="#torch.nn.ModuleDict.update" title="torch.nn.ModuleDict.update"><code class="xref py py-meth docutils literal notranslate"><span class="pre">update()</span></code></a> with other unordered mapping
types (e.g., Python’s plain <code class="docutils literal notranslate"><span class="pre">dict</span></code>) does not preserve the order of the
merged mapping.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>modules</strong> (<em>iterable</em><em>, </em><em>optional</em>) – a mapping (dictionary) of (string: module)
or an iterable of key-value pairs of type (string, module)</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyModule</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MyModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">choices</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleDict</span><span class="p">({</span>
                <span class="s1">&#39;conv&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
                <span class="s1">&#39;pool&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
        <span class="p">})</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activations</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleDict</span><span class="p">([</span>
                <span class="p">[</span><span class="s1">&#39;lrelu&#39;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">()],</span>
                <span class="p">[</span><span class="s1">&#39;prelu&#39;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">()]</span>
        <span class="p">])</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">choice</span><span class="p">,</span> <span class="n">act</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">choices</span><span class="p">[</span><span class="n">choice</span><span class="p">](</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activations</span><span class="p">[</span><span class="n">act</span><span class="p">](</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
<dl class="method">
<dt id="torch.nn.ModuleDict.clear">
<code class="sig-name descname">clear</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/container.html#ModuleDict.clear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ModuleDict.clear" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove all items from the ModuleDict.</p>
</dd></dl>

<dl class="method">
<dt id="torch.nn.ModuleDict.items">
<code class="sig-name descname">items</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/container.html#ModuleDict.items"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ModuleDict.items" title="Permalink to this definition">¶</a></dt>
<dd><p>Return an iterable of the ModuleDict key/value pairs.</p>
</dd></dl>

<dl class="method">
<dt id="torch.nn.ModuleDict.keys">
<code class="sig-name descname">keys</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/container.html#ModuleDict.keys"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ModuleDict.keys" title="Permalink to this definition">¶</a></dt>
<dd><p>Return an iterable of the ModuleDict keys.</p>
</dd></dl>

<dl class="method">
<dt id="torch.nn.ModuleDict.pop">
<code class="sig-name descname">pop</code><span class="sig-paren">(</span><em class="sig-param">key</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/container.html#ModuleDict.pop"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ModuleDict.pop" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove key from the ModuleDict and return its module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>key</strong> (<em>string</em>) – key to pop from the ModuleDict</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch.nn.ModuleDict.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param">modules</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/container.html#ModuleDict.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ModuleDict.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the <a class="reference internal" href="#torch.nn.ModuleDict" title="torch.nn.ModuleDict"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModuleDict</span></code></a> with the key-value pairs from a
mapping or an iterable, overwriting existing keys.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">modules</span></code> is an <code class="docutils literal notranslate"><span class="pre">OrderedDict</span></code>, a <a class="reference internal" href="#torch.nn.ModuleDict" title="torch.nn.ModuleDict"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModuleDict</span></code></a>, or
an iterable of key-value pairs, the order of new elements in it is preserved.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>modules</strong> (<em>iterable</em>) – a mapping (dictionary) from string to <a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a>,
or an iterable of key-value pairs of type (string, <a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a>)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch.nn.ModuleDict.values">
<code class="sig-name descname">values</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/container.html#ModuleDict.values"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ModuleDict.values" title="Permalink to this definition">¶</a></dt>
<dd><p>Return an iterable of the ModuleDict values.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="parameterlist">
<h3><span class="hidden-section">ParameterList</span><a class="headerlink" href="#parameterlist" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.ParameterList">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">ParameterList</code><span class="sig-paren">(</span><em class="sig-param">parameters=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/container.html#ParameterList"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ParameterList" title="Permalink to this definition">¶</a></dt>
<dd><p>Holds parameters in a list.</p>
<p><a class="reference internal" href="#torch.nn.ParameterList" title="torch.nn.ParameterList"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParameterList</span></code></a> can be indexed like a regular Python
list, but parameters it contains are properly registered, and will be
visible by all <a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a> methods.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>parameters</strong> (<em>iterable</em><em>, </em><em>optional</em>) – an iterable of <a class="reference internal" href="#torch.nn.Parameter" title="torch.nn.Parameter"><code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code></a> to add</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyModule</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MyModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ParameterList</span><span class="p">([</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)])</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="c1"># ParameterList can act as an iterable, or be indexed using ints</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">):</span>
            <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">i</span> <span class="o">//</span> <span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">p</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
<dl class="method">
<dt id="torch.nn.ParameterList.append">
<code class="sig-name descname">append</code><span class="sig-paren">(</span><em class="sig-param">parameter</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/container.html#ParameterList.append"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ParameterList.append" title="Permalink to this definition">¶</a></dt>
<dd><p>Appends a given parameter at the end of the list.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>parameter</strong> (<a class="reference internal" href="#torch.nn.Parameter" title="torch.nn.Parameter"><em>nn.Parameter</em></a>) – parameter to append</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch.nn.ParameterList.extend">
<code class="sig-name descname">extend</code><span class="sig-paren">(</span><em class="sig-param">parameters</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/container.html#ParameterList.extend"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ParameterList.extend" title="Permalink to this definition">¶</a></dt>
<dd><p>Appends parameters from a Python iterable to the end of the list.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>parameters</strong> (<em>iterable</em>) – iterable of parameters to append</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="parameterdict">
<h3><span class="hidden-section">ParameterDict</span><a class="headerlink" href="#parameterdict" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.ParameterDict">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">ParameterDict</code><span class="sig-paren">(</span><em class="sig-param">parameters=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/container.html#ParameterDict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ParameterDict" title="Permalink to this definition">¶</a></dt>
<dd><p>Holds parameters in a dictionary.</p>
<p>ParameterDict can be indexed like a regular Python dictionary, but parameters it
contains are properly registered, and will be visible by all Module methods.</p>
<p><a class="reference internal" href="#torch.nn.ParameterDict" title="torch.nn.ParameterDict"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParameterDict</span></code></a> is an <strong>ordered</strong> dictionary that respects</p>
<ul class="simple">
<li><p>the order of insertion, and</p></li>
<li><p>in <a class="reference internal" href="#torch.nn.ParameterDict.update" title="torch.nn.ParameterDict.update"><code class="xref py py-meth docutils literal notranslate"><span class="pre">update()</span></code></a>, the order of the merged <code class="docutils literal notranslate"><span class="pre">OrderedDict</span></code>
or another <a class="reference internal" href="#torch.nn.ParameterDict" title="torch.nn.ParameterDict"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParameterDict</span></code></a> (the argument to
<a class="reference internal" href="#torch.nn.ParameterDict.update" title="torch.nn.ParameterDict.update"><code class="xref py py-meth docutils literal notranslate"><span class="pre">update()</span></code></a>).</p></li>
</ul>
<p>Note that <a class="reference internal" href="#torch.nn.ParameterDict.update" title="torch.nn.ParameterDict.update"><code class="xref py py-meth docutils literal notranslate"><span class="pre">update()</span></code></a> with other unordered mapping
types (e.g., Python’s plain <code class="docutils literal notranslate"><span class="pre">dict</span></code>) does not preserve the order of the
merged mapping.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>parameters</strong> (<em>iterable</em><em>, </em><em>optional</em>) – a mapping (dictionary) of
(string : <a class="reference internal" href="#torch.nn.Parameter" title="torch.nn.Parameter"><code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code></a>) or an iterable of key-value pairs
of type (string, <a class="reference internal" href="#torch.nn.Parameter" title="torch.nn.Parameter"><code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code></a>)</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyModule</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">MyModule</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ParameterDict</span><span class="p">({</span>
                <span class="s1">&#39;left&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">)),</span>
                <span class="s1">&#39;right&#39;</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
        <span class="p">})</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">choice</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">choice</span><span class="p">]</span><span class="o">.</span><span class="n">mm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>
</div>
<dl class="method">
<dt id="torch.nn.ParameterDict.clear">
<code class="sig-name descname">clear</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/container.html#ParameterDict.clear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ParameterDict.clear" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove all items from the ParameterDict.</p>
</dd></dl>

<dl class="method">
<dt id="torch.nn.ParameterDict.items">
<code class="sig-name descname">items</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/container.html#ParameterDict.items"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ParameterDict.items" title="Permalink to this definition">¶</a></dt>
<dd><p>Return an iterable of the ParameterDict key/value pairs.</p>
</dd></dl>

<dl class="method">
<dt id="torch.nn.ParameterDict.keys">
<code class="sig-name descname">keys</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/container.html#ParameterDict.keys"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ParameterDict.keys" title="Permalink to this definition">¶</a></dt>
<dd><p>Return an iterable of the ParameterDict keys.</p>
</dd></dl>

<dl class="method">
<dt id="torch.nn.ParameterDict.pop">
<code class="sig-name descname">pop</code><span class="sig-paren">(</span><em class="sig-param">key</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/container.html#ParameterDict.pop"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ParameterDict.pop" title="Permalink to this definition">¶</a></dt>
<dd><p>Remove key from the ParameterDict and return its parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>key</strong> (<em>string</em>) – key to pop from the ParameterDict</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch.nn.ParameterDict.update">
<code class="sig-name descname">update</code><span class="sig-paren">(</span><em class="sig-param">parameters</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/container.html#ParameterDict.update"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ParameterDict.update" title="Permalink to this definition">¶</a></dt>
<dd><p>Update the <a class="reference internal" href="#torch.nn.ParameterDict" title="torch.nn.ParameterDict"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParameterDict</span></code></a> with the key-value pairs from a
mapping or an iterable, overwriting existing keys.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">parameters</span></code> is an <code class="docutils literal notranslate"><span class="pre">OrderedDict</span></code>, a <a class="reference internal" href="#torch.nn.ParameterDict" title="torch.nn.ParameterDict"><code class="xref py py-class docutils literal notranslate"><span class="pre">ParameterDict</span></code></a>, or
an iterable of key-value pairs, the order of new elements in it is preserved.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>parameters</strong> (<em>iterable</em>) – a mapping (dictionary) from string to
<a class="reference internal" href="#torch.nn.Parameter" title="torch.nn.Parameter"><code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code></a>, or an iterable of
key-value pairs of type (string, <a class="reference internal" href="#torch.nn.Parameter" title="torch.nn.Parameter"><code class="xref py py-class docutils literal notranslate"><span class="pre">Parameter</span></code></a>)</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch.nn.ParameterDict.values">
<code class="sig-name descname">values</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/container.html#ParameterDict.values"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ParameterDict.values" title="Permalink to this definition">¶</a></dt>
<dd><p>Return an iterable of the ParameterDict values.</p>
</dd></dl>

</dd></dl>

</div>
</div>
<div class="section" id="convolution-layers">
<h2>Convolution layers<a class="headerlink" href="#convolution-layers" title="Permalink to this headline">¶</a></h2>
<div class="section" id="conv1d">
<h3><span class="hidden-section">Conv1d</span><a class="headerlink" href="#conv1d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.Conv1d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">Conv1d</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">stride=1</em>, <em class="sig-param">padding=0</em>, <em class="sig-param">dilation=1</em>, <em class="sig-param">groups=1</em>, <em class="sig-param">bias=True</em>, <em class="sig-param">padding_mode='zeros'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/conv.html#Conv1d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Conv1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a 1D convolution over an input signal composed of several input
planes.</p>
<p>In the simplest case, the output value of the layer with input size
<img class="math" src="_images/math/4224788d9fcead1f6dac8b345996b5060ef8950c.svg" alt="(N, C_{\text{in}}, L)"/> and output <img class="math" src="_images/math/2b3ff4ccc4431751109391d182578b7932191733.svg" alt="(N, C_{\text{out}}, L_{\text{out}})"/> can be
precisely described as:</p>
<div class="math">
<p><img src="_images/math/21c429f50330d35ce4cbaa2a9e52c81247ee3b5e.svg" alt="\text{out}(N_i, C_{\text{out}_j}) = \text{bias}(C_{\text{out}_j}) +
\sum_{k = 0}^{C_{in} - 1} \text{weight}(C_{\text{out}_j}, k)
\star \text{input}(N_i, k)"/></p>
</div><p>where <img class="math" src="_images/math/2fca8a9c76b722af50cba036820b68e36c46a4db.svg" alt="\star"/> is the valid <a class="reference external" href="https://en.wikipedia.org/wiki/Cross-correlation">cross-correlation</a> operator,
<img class="math" src="_images/math/3bfb3a64189a14b2704f4610827762d5e3145114.svg" alt="N"/> is a batch size, <img class="math" src="_images/math/4db5b6e16e06f929ce3f675c5e535d06ffb02ff7.svg" alt="C"/> denotes a number of channels,
<img class="math" src="_images/math/19eef1966f7c545af3ac8c0fa486974d873e3c65.svg" alt="L"/> is a length of signal sequence.</p>
<ul>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">stride</span></code> controls the stride for the cross-correlation, a single
number or a one-element tuple.</p></li>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code> controls the amount of implicit zero-paddings on both sides
for <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code> number of points.</p></li>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">dilation</span></code> controls the spacing between the kernel points; also
known as the à trous algorithm. It is harder to describe, but this <a class="reference external" href="https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md">link</a>
has a nice visualization of what <code class="xref py py-attr docutils literal notranslate"><span class="pre">dilation</span></code> does.</p></li>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">groups</span></code> controls the connections between inputs and outputs.
<code class="xref py py-attr docutils literal notranslate"><span class="pre">in_channels</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">out_channels</span></code> must both be divisible by
<code class="xref py py-attr docutils literal notranslate"><span class="pre">groups</span></code>. For example,</p>
<blockquote>
<div><ul class="simple">
<li><p>At groups=1, all inputs are convolved to all outputs.</p></li>
<li><p>At groups=2, the operation becomes equivalent to having two conv
layers side by side, each seeing half the input channels,
and producing half the output channels, and both subsequently
concatenated.</p></li>
<li><p>At groups= <code class="xref py py-attr docutils literal notranslate"><span class="pre">in_channels</span></code>, each input channel is convolved with
its own set of filters,
of size
<img class="math" src="_images/math/5b92cdc3d150fc6be9b65f77b581600c0ac52df4.svg" alt="\left\lfloor\frac{out\_channels}{in\_channels}\right\rfloor"/>.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Depending of the size of your kernel, several (of the last)
columns of the input might be lost, because it is a valid
<a class="reference external" href="https://en.wikipedia.org/wiki/Cross-correlation">cross-correlation</a>, and not a full <a class="reference external" href="https://en.wikipedia.org/wiki/Cross-correlation">cross-correlation</a>.
It is up to the user to add proper padding.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When <cite>groups == in_channels</cite> and <cite>out_channels == K * in_channels</cite>,
where <cite>K</cite> is a positive integer, this operation is also termed in
literature as depthwise convolution.</p>
<p>In other words, for an input of size <img class="math" src="_images/math/ba9d676016927d9f4e3db108ed2621562eedac78.svg" alt="(N, C_{in}, L_{in})"/>,
a depthwise convolution with a depthwise multiplier <cite>K</cite>, can be constructed by arguments
<img class="math" src="_images/math/66a694e8dee2131a2655a653bdee90fa05dc1634.svg" alt="(C_\text{in}=C_{in}, C_\text{out}=C_{in} \times K, ..., \text{groups}=C_{in})"/>.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In some circumstances when using the CUDA backend with CuDNN, this operator
may select a nondeterministic algorithm to increase performance. If this is
undesirable, you can try to make the operation deterministic (potentially at
a performance cost) by setting <code class="docutils literal notranslate"><span class="pre">torch.backends.cudnn.deterministic</span> <span class="pre">=</span>
<span class="pre">True</span></code>.
Please see the notes on <a class="reference internal" href="notes/randomness.html"><span class="doc">Reproducibility</span></a> for background.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Number of channels in the input image</p></li>
<li><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Number of channels produced by the convolution</p></li>
<li><p><strong>kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a>) – Size of the convolving kernel</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a><em>, </em><em>optional</em>) – Stride of the convolution. Default: 1</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a><em>, </em><em>optional</em>) – Zero-padding added to both sides of
the input. Default: 0</p></li>
<li><p><strong>padding_mode</strong> (<em>string</em><em>, </em><em>optional</em>) – <cite>zeros</cite></p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a><em>, </em><em>optional</em>) – Spacing between kernel
elements. Default: 1</p></li>
<li><p><strong>groups</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em>) – Number of blocked connections from input
channels to output channels. Default: 1</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, adds a learnable bias to the output. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><p>Input: <img class="math" src="_images/math/ba9d676016927d9f4e3db108ed2621562eedac78.svg" alt="(N, C_{in}, L_{in})"/></p></li>
<li><p>Output: <img class="math" src="_images/math/a87405c2c728e048f517d666188d7c2c5523f018.svg" alt="(N, C_{out}, L_{out})"/> where</p>
<div class="math">
<p><img src="_images/math/7662a2875854b35dfd0c73afb7436401c6cf9d5f.svg" alt="L_{out} = \left\lfloor\frac{L_{in} + 2 \times \text{padding} - \text{dilation}
          \times (\text{kernel\_size} - 1) - 1}{\text{stride}} + 1\right\rfloor"/></p>
</div></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>~Conv1d.weight</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – the learnable weights of the module of shape
<img class="math" src="_images/math/907cfd3d59f1f2bf3331689c82505e88cb8e72b1.svg" alt="(\text{out\_channels}, \frac{\text{in\_channels}}{\text{groups}}, \text{kernel\_size})"/>.
The values of these weights are sampled from
<img class="math" src="_images/math/c4acd08f3a59fa0f26605b209d8e6882cffb6300.svg" alt="\mathcal{U}(-\sqrt{k}, \sqrt{k})"/> where
<img class="math" src="_images/math/06587b43a42547941f33e78dd8584638f6e768c1.svg" alt="k = \frac{1}{C_\text{in} * \text{kernel\_size}}"/></p></li>
<li><p><strong>~Conv1d.bias</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – the learnable bias of the module of shape
(out_channels). If <code class="xref py py-attr docutils literal notranslate"><span class="pre">bias</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, then the values of these weights are
sampled from <img class="math" src="_images/math/c4acd08f3a59fa0f26605b209d8e6882cffb6300.svg" alt="\mathcal{U}(-\sqrt{k}, \sqrt{k})"/> where
<img class="math" src="_images/math/06587b43a42547941f33e78dd8584638f6e768c1.svg" alt="k = \frac{1}{C_\text{in} * \text{kernel\_size}}"/></p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv1d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="conv2d">
<h3><span class="hidden-section">Conv2d</span><a class="headerlink" href="#conv2d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.Conv2d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">Conv2d</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">stride=1</em>, <em class="sig-param">padding=0</em>, <em class="sig-param">dilation=1</em>, <em class="sig-param">groups=1</em>, <em class="sig-param">bias=True</em>, <em class="sig-param">padding_mode='zeros'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/conv.html#Conv2d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Conv2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a 2D convolution over an input signal composed of several input
planes.</p>
<p>In the simplest case, the output value of the layer with input size
<img class="math" src="_images/math/e781118a905aa3ee17b7fd81ce9877f75401260f.svg" alt="(N, C_{\text{in}}, H, W)"/> and output <img class="math" src="_images/math/9403d89fa274cbc0d634db3236838eb3351951dc.svg" alt="(N, C_{\text{out}}, H_{\text{out}}, W_{\text{out}})"/>
can be precisely described as:</p>
<div class="math">
<p><img src="_images/math/16c4944324fae84c58458d81c9b5274b79bd62a4.svg" alt="\text{out}(N_i, C_{\text{out}_j}) = \text{bias}(C_{\text{out}_j}) +
\sum_{k = 0}^{C_{\text{in}} - 1} \text{weight}(C_{\text{out}_j}, k) \star \text{input}(N_i, k)"/></p>
</div><p>where <img class="math" src="_images/math/2fca8a9c76b722af50cba036820b68e36c46a4db.svg" alt="\star"/> is the valid 2D <a class="reference external" href="https://en.wikipedia.org/wiki/Cross-correlation">cross-correlation</a> operator,
<img class="math" src="_images/math/3bfb3a64189a14b2704f4610827762d5e3145114.svg" alt="N"/> is a batch size, <img class="math" src="_images/math/4db5b6e16e06f929ce3f675c5e535d06ffb02ff7.svg" alt="C"/> denotes a number of channels,
<img class="math" src="_images/math/cb5de54f699cf4b3c7c1a3e87313d11d536c0d88.svg" alt="H"/> is a height of input planes in pixels, and <img class="math" src="_images/math/1fbee781f84569077719a167b64e12064360fac1.svg" alt="W"/> is
width in pixels.</p>
<ul>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">stride</span></code> controls the stride for the cross-correlation, a single
number or a tuple.</p></li>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code> controls the amount of implicit zero-paddings on both
sides for <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code> number of points for each dimension.</p></li>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">dilation</span></code> controls the spacing between the kernel points; also
known as the à trous algorithm. It is harder to describe, but this <a class="reference external" href="https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md">link</a>
has a nice visualization of what <code class="xref py py-attr docutils literal notranslate"><span class="pre">dilation</span></code> does.</p></li>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">groups</span></code> controls the connections between inputs and outputs.
<code class="xref py py-attr docutils literal notranslate"><span class="pre">in_channels</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">out_channels</span></code> must both be divisible by
<code class="xref py py-attr docutils literal notranslate"><span class="pre">groups</span></code>. For example,</p>
<blockquote>
<div><ul class="simple">
<li><p>At groups=1, all inputs are convolved to all outputs.</p></li>
<li><p>At groups=2, the operation becomes equivalent to having two conv
layers side by side, each seeing half the input channels,
and producing half the output channels, and both subsequently
concatenated.</p></li>
<li><p>At groups= <code class="xref py py-attr docutils literal notranslate"><span class="pre">in_channels</span></code>, each input channel is convolved with
its own set of filters, of size:
<img class="math" src="_images/math/5b92cdc3d150fc6be9b65f77b581600c0ac52df4.svg" alt="\left\lfloor\frac{out\_channels}{in\_channels}\right\rfloor"/>.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
<p>The parameters <code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">stride</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">dilation</span></code> can either be:</p>
<blockquote>
<div><ul class="simple">
<li><p>a single <code class="docutils literal notranslate"><span class="pre">int</span></code> – in which case the same value is used for the height and width dimension</p></li>
<li><p>a <code class="docutils literal notranslate"><span class="pre">tuple</span></code> of two ints – in which case, the first <cite>int</cite> is used for the height dimension,
and the second <cite>int</cite> for the width dimension</p></li>
</ul>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Depending of the size of your kernel, several (of the last)
columns of the input might be lost, because it is a valid <a class="reference external" href="https://en.wikipedia.org/wiki/Cross-correlation">cross-correlation</a>,
and not a full <a class="reference external" href="https://en.wikipedia.org/wiki/Cross-correlation">cross-correlation</a>.
It is up to the user to add proper padding.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When <cite>groups == in_channels</cite> and <cite>out_channels == K * in_channels</cite>,
where <cite>K</cite> is a positive integer, this operation is also termed in
literature as depthwise convolution.</p>
<p>In other words, for an input of size <img class="math" src="_images/math/c0cc56295701f42802f20d2bdf887ccc62ec46b0.svg" alt="(N, C_{in}, H_{in}, W_{in})"/>,
a depthwise convolution with a depthwise multiplier <cite>K</cite>, can be constructed by arguments
<img class="math" src="_images/math/df34a0d324207cdbb412833076fdaa8a03ab70f4.svg" alt="(in\_channels=C_{in}, out\_channels=C_{in} \times K, ..., groups=C_{in})"/>.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In some circumstances when using the CUDA backend with CuDNN, this operator
may select a nondeterministic algorithm to increase performance. If this is
undesirable, you can try to make the operation deterministic (potentially at
a performance cost) by setting <code class="docutils literal notranslate"><span class="pre">torch.backends.cudnn.deterministic</span> <span class="pre">=</span>
<span class="pre">True</span></code>.
Please see the notes on <a class="reference internal" href="notes/randomness.html"><span class="doc">Reproducibility</span></a> for background.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Number of channels in the input image</p></li>
<li><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Number of channels produced by the convolution</p></li>
<li><p><strong>kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a>) – Size of the convolving kernel</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a><em>, </em><em>optional</em>) – Stride of the convolution. Default: 1</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a><em>, </em><em>optional</em>) – Zero-padding added to both sides of the input. Default: 0</p></li>
<li><p><strong>padding_mode</strong> (<em>string</em><em>, </em><em>optional</em>) – <cite>zeros</cite></p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a><em>, </em><em>optional</em>) – Spacing between kernel elements. Default: 1</p></li>
<li><p><strong>groups</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em>) – Number of blocked connections from input channels to output channels. Default: 1</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, adds a learnable bias to the output. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><p>Input: <img class="math" src="_images/math/c0cc56295701f42802f20d2bdf887ccc62ec46b0.svg" alt="(N, C_{in}, H_{in}, W_{in})"/></p></li>
<li><p>Output: <img class="math" src="_images/math/31082b446078c7104cc6cbf38999e900e6e7af7a.svg" alt="(N, C_{out}, H_{out}, W_{out})"/> where</p>
<div class="math">
<p><img src="_images/math/8b63df452672967f158b1ac13d623cf2dd1bf258.svg" alt="H_{out} = \left\lfloor\frac{H_{in}  + 2 \times \text{padding}[0] - \text{dilation}[0]
          \times (\text{kernel\_size}[0] - 1) - 1}{\text{stride}[0]} + 1\right\rfloor"/></p>
</div><div class="math">
<p><img src="_images/math/dc1db663c9a71bfbe2411ed219e4d82e807c724b.svg" alt="W_{out} = \left\lfloor\frac{W_{in}  + 2 \times \text{padding}[1] - \text{dilation}[1]
          \times (\text{kernel\_size}[1] - 1) - 1}{\text{stride}[1]} + 1\right\rfloor"/></p>
</div></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>~Conv2d.weight</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – the learnable weights of the module of shape
<img class="math" src="_images/math/493a6729ed163c6bd8b4ce87f1d8b97921b6126b.svg" alt="(\text{out\_channels}, \frac{\text{in\_channels}}{\text{groups}},"/>
<img class="math" src="_images/math/e208f2735483d72ea8954b1eb27fc28d8e5b869e.svg" alt="\text{kernel\_size[0]}, \text{kernel\_size[1]})"/>.
The values of these weights are sampled from
<img class="math" src="_images/math/c4acd08f3a59fa0f26605b209d8e6882cffb6300.svg" alt="\mathcal{U}(-\sqrt{k}, \sqrt{k})"/> where
<img class="math" src="_images/math/8ffd283c65a22625c6ff647f6b2d3e871266a00d.svg" alt="k = \frac{1}{C_\text{in} * \prod_{i=0}^{1}\text{kernel\_size}[i]}"/></p></li>
<li><p><strong>~Conv2d.bias</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – the learnable bias of the module of shape (out_channels). If <code class="xref py py-attr docutils literal notranslate"><span class="pre">bias</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>,
then the values of these weights are
sampled from <img class="math" src="_images/math/c4acd08f3a59fa0f26605b209d8e6882cffb6300.svg" alt="\mathcal{U}(-\sqrt{k}, \sqrt{k})"/> where
<img class="math" src="_images/math/8ffd283c65a22625c6ff647f6b2d3e871266a00d.svg" alt="k = \frac{1}{C_\text{in} * \prod_{i=0}^{1}\text{kernel\_size}[i]}"/></p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># With square kernels and equal stride</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># non-square kernels and unequal stride and with padding</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># non-square kernels and unequal stride and with padding and dilation</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">dilation</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="conv3d">
<h3><span class="hidden-section">Conv3d</span><a class="headerlink" href="#conv3d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.Conv3d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">Conv3d</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">stride=1</em>, <em class="sig-param">padding=0</em>, <em class="sig-param">dilation=1</em>, <em class="sig-param">groups=1</em>, <em class="sig-param">bias=True</em>, <em class="sig-param">padding_mode='zeros'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/conv.html#Conv3d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Conv3d" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a 3D convolution over an input signal composed of several input
planes.</p>
<p>In the simplest case, the output value of the layer with input size <img class="math" src="_images/math/e0aabcff0d280e1fb716a24b17b90d7bf6fc4bd3.svg" alt="(N, C_{in}, D, H, W)"/>
and output <img class="math" src="_images/math/748cbb70f0586cafc4561c15425a065bb0506c4b.svg" alt="(N, C_{out}, D_{out}, H_{out}, W_{out})"/> can be precisely described as:</p>
<div class="math">
<p><img src="_images/math/34e8840766f31d2fde507ac443ff17005f399a9d.svg" alt="out(N_i, C_{out_j}) = bias(C_{out_j}) +
                        \sum_{k = 0}^{C_{in} - 1} weight(C_{out_j}, k) \star input(N_i, k)"/></p>
</div><p>where <img class="math" src="_images/math/2fca8a9c76b722af50cba036820b68e36c46a4db.svg" alt="\star"/> is the valid 3D <a class="reference external" href="https://en.wikipedia.org/wiki/Cross-correlation">cross-correlation</a> operator</p>
<ul>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">stride</span></code> controls the stride for the cross-correlation.</p></li>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code> controls the amount of implicit zero-paddings on both
sides for <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code> number of points for each dimension.</p></li>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">dilation</span></code> controls the spacing between the kernel points; also known as the à trous algorithm.
It is harder to describe, but this <a class="reference external" href="https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md">link</a> has a nice visualization of what <code class="xref py py-attr docutils literal notranslate"><span class="pre">dilation</span></code> does.</p></li>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">groups</span></code> controls the connections between inputs and outputs.
<code class="xref py py-attr docutils literal notranslate"><span class="pre">in_channels</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">out_channels</span></code> must both be divisible by
<code class="xref py py-attr docutils literal notranslate"><span class="pre">groups</span></code>. For example,</p>
<blockquote>
<div><ul class="simple">
<li><p>At groups=1, all inputs are convolved to all outputs.</p></li>
<li><p>At groups=2, the operation becomes equivalent to having two conv
layers side by side, each seeing half the input channels,
and producing half the output channels, and both subsequently
concatenated.</p></li>
<li><p>At groups= <code class="xref py py-attr docutils literal notranslate"><span class="pre">in_channels</span></code>, each input channel is convolved with
its own set of filters, of size
<img class="math" src="_images/math/5b92cdc3d150fc6be9b65f77b581600c0ac52df4.svg" alt="\left\lfloor\frac{out\_channels}{in\_channels}\right\rfloor"/>.</p></li>
</ul>
</div></blockquote>
</li>
</ul>
<p>The parameters <code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">stride</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">dilation</span></code> can either be:</p>
<blockquote>
<div><ul class="simple">
<li><p>a single <code class="docutils literal notranslate"><span class="pre">int</span></code> – in which case the same value is used for the depth, height and width dimension</p></li>
<li><p>a <code class="docutils literal notranslate"><span class="pre">tuple</span></code> of three ints – in which case, the first <cite>int</cite> is used for the depth dimension,
the second <cite>int</cite> for the height dimension and the third <cite>int</cite> for the width dimension</p></li>
</ul>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Depending of the size of your kernel, several (of the last)
columns of the input might be lost, because it is a valid <a class="reference external" href="https://en.wikipedia.org/wiki/Cross-correlation">cross-correlation</a>,
and not a full <a class="reference external" href="https://en.wikipedia.org/wiki/Cross-correlation">cross-correlation</a>.
It is up to the user to add proper padding.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When <cite>groups == in_channels</cite> and <cite>out_channels == K * in_channels</cite>,
where <cite>K</cite> is a positive integer, this operation is also termed in
literature as depthwise convolution.</p>
<p>In other words, for an input of size <img class="math" src="_images/math/b4584b987e05b58f4ebbe801f0fc7e18d9ed475e.svg" alt="(N, C_{in}, D_{in}, H_{in}, W_{in})"/>,
a depthwise convolution with a depthwise multiplier <cite>K</cite>, can be constructed by arguments
<img class="math" src="_images/math/df34a0d324207cdbb412833076fdaa8a03ab70f4.svg" alt="(in\_channels=C_{in}, out\_channels=C_{in} \times K, ..., groups=C_{in})"/>.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In some circumstances when using the CUDA backend with CuDNN, this operator
may select a nondeterministic algorithm to increase performance. If this is
undesirable, you can try to make the operation deterministic (potentially at
a performance cost) by setting <code class="docutils literal notranslate"><span class="pre">torch.backends.cudnn.deterministic</span> <span class="pre">=</span>
<span class="pre">True</span></code>.
Please see the notes on <a class="reference internal" href="notes/randomness.html"><span class="doc">Reproducibility</span></a> for background.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Number of channels in the input image</p></li>
<li><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Number of channels produced by the convolution</p></li>
<li><p><strong>kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a>) – Size of the convolving kernel</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a><em>, </em><em>optional</em>) – Stride of the convolution. Default: 1</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a><em>, </em><em>optional</em>) – Zero-padding added to all three sides of the input. Default: 0</p></li>
<li><p><strong>padding_mode</strong> (<em>string</em><em>, </em><em>optional</em>) – <cite>zeros</cite></p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a><em>, </em><em>optional</em>) – Spacing between kernel elements. Default: 1</p></li>
<li><p><strong>groups</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em>) – Number of blocked connections from input channels to output channels. Default: 1</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, adds a learnable bias to the output. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><p>Input: <img class="math" src="_images/math/b4584b987e05b58f4ebbe801f0fc7e18d9ed475e.svg" alt="(N, C_{in}, D_{in}, H_{in}, W_{in})"/></p></li>
<li><p>Output: <img class="math" src="_images/math/748cbb70f0586cafc4561c15425a065bb0506c4b.svg" alt="(N, C_{out}, D_{out}, H_{out}, W_{out})"/> where</p>
<div class="math">
<p><img src="_images/math/99fdea641ddcf0ccce3013e1ba461b5e8372b074.svg" alt="D_{out} = \left\lfloor\frac{D_{in} + 2 \times \text{padding}[0] - \text{dilation}[0]
      \times (\text{kernel\_size}[0] - 1) - 1}{\text{stride}[0]} + 1\right\rfloor"/></p>
</div><div class="math">
<p><img src="_images/math/4252e22e7e28fe4bf319a5776c9a0598602925b2.svg" alt="H_{out} = \left\lfloor\frac{H_{in} + 2 \times \text{padding}[1] - \text{dilation}[1]
      \times (\text{kernel\_size}[1] - 1) - 1}{\text{stride}[1]} + 1\right\rfloor"/></p>
</div><div class="math">
<p><img src="_images/math/81b6ae166f56488521d915fd1680aa3bf8e83705.svg" alt="W_{out} = \left\lfloor\frac{W_{in} + 2 \times \text{padding}[2] - \text{dilation}[2]
      \times (\text{kernel\_size}[2] - 1) - 1}{\text{stride}[2]} + 1\right\rfloor"/></p>
</div></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>~Conv3d.weight</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – the learnable weights of the module of shape
<img class="math" src="_images/math/493a6729ed163c6bd8b4ce87f1d8b97921b6126b.svg" alt="(\text{out\_channels}, \frac{\text{in\_channels}}{\text{groups}},"/>
<img class="math" src="_images/math/ca70e34b69f87dfc804a8d16561c4667b05913be.svg" alt="\text{kernel\_size[0]}, \text{kernel\_size[1]}, \text{kernel\_size[2]})"/>.
The values of these weights are sampled from
<img class="math" src="_images/math/c4acd08f3a59fa0f26605b209d8e6882cffb6300.svg" alt="\mathcal{U}(-\sqrt{k}, \sqrt{k})"/> where
<img class="math" src="_images/math/312282962fae5c354d52351698a4905f642edf31.svg" alt="k = \frac{1}{C_\text{in} * \prod_{i=0}^{2}\text{kernel\_size}[i]}"/></p></li>
<li><p><strong>~Conv3d.bias</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – the learnable bias of the module of shape (out_channels). If <code class="xref py py-attr docutils literal notranslate"><span class="pre">bias</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>,
then the values of these weights are
sampled from <img class="math" src="_images/math/c4acd08f3a59fa0f26605b209d8e6882cffb6300.svg" alt="\mathcal{U}(-\sqrt{k}, \sqrt{k})"/> where
<img class="math" src="_images/math/312282962fae5c354d52351698a4905f642edf31.svg" alt="k = \frac{1}{C_\text{in} * \prod_{i=0}^{2}\text{kernel\_size}[i]}"/></p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># With square kernels and equal stride</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># non-square kernels and unequal stride and with padding</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv3d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="convtranspose1d">
<h3><span class="hidden-section">ConvTranspose1d</span><a class="headerlink" href="#convtranspose1d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.ConvTranspose1d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">ConvTranspose1d</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">stride=1</em>, <em class="sig-param">padding=0</em>, <em class="sig-param">output_padding=0</em>, <em class="sig-param">groups=1</em>, <em class="sig-param">bias=True</em>, <em class="sig-param">dilation=1</em>, <em class="sig-param">padding_mode='zeros'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/conv.html#ConvTranspose1d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ConvTranspose1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a 1D transposed convolution operator over an input image
composed of several input planes.</p>
<p>This module can be seen as the gradient of Conv1d with respect to its input.
It is also known as a fractionally-strided convolution or
a deconvolution (although it is not an actual deconvolution operation).</p>
<ul>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">stride</span></code> controls the stride for the cross-correlation.</p></li>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code> controls the amount of implicit zero-paddings on both
sides for <code class="docutils literal notranslate"><span class="pre">dilation</span> <span class="pre">*</span> <span class="pre">(kernel_size</span> <span class="pre">-</span> <span class="pre">1)</span> <span class="pre">-</span> <span class="pre">padding</span></code> number of points. See note
below for details.</p></li>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">output_padding</span></code> controls the additional size added to one side
of the output shape. See note below for details.</p></li>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">dilation</span></code> controls the spacing between the kernel points; also known as the à trous algorithm.
It is harder to describe, but this <a class="reference external" href="https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md">link</a> has a nice visualization of what <code class="xref py py-attr docutils literal notranslate"><span class="pre">dilation</span></code> does.</p></li>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">groups</span></code> controls the connections between inputs and outputs.
<code class="xref py py-attr docutils literal notranslate"><span class="pre">in_channels</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">out_channels</span></code> must both be divisible by
<code class="xref py py-attr docutils literal notranslate"><span class="pre">groups</span></code>. For example,</p>
<blockquote>
<div><ul class="simple">
<li><p>At groups=1, all inputs are convolved to all outputs.</p></li>
<li><p>At groups=2, the operation becomes equivalent to having two conv
layers side by side, each seeing half the input channels,
and producing half the output channels, and both subsequently
concatenated.</p></li>
<li><p>At groups= <code class="xref py py-attr docutils literal notranslate"><span class="pre">in_channels</span></code>, each input channel is convolved with
its own set of filters (of size
<img class="math" src="_images/math/5b92cdc3d150fc6be9b65f77b581600c0ac52df4.svg" alt="\left\lfloor\frac{out\_channels}{in\_channels}\right\rfloor"/>).</p></li>
</ul>
</div></blockquote>
</li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Depending of the size of your kernel, several (of the last)
columns of the input might be lost, because it is a valid <a class="reference external" href="https://en.wikipedia.org/wiki/Cross-correlation">cross-correlation</a>,
and not a full <a class="reference external" href="https://en.wikipedia.org/wiki/Cross-correlation">cross-correlation</a>.
It is up to the user to add proper padding.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code> argument effectively adds <code class="docutils literal notranslate"><span class="pre">dilation</span> <span class="pre">*</span> <span class="pre">(kernel_size</span> <span class="pre">-</span> <span class="pre">1)</span> <span class="pre">-</span> <span class="pre">padding</span></code>
amount of zero padding to both sizes of the input. This is set so that
when a <a class="reference internal" href="#torch.nn.Conv1d" title="torch.nn.Conv1d"><code class="xref py py-class docutils literal notranslate"><span class="pre">Conv1d</span></code></a> and a <a class="reference internal" href="#torch.nn.ConvTranspose1d" title="torch.nn.ConvTranspose1d"><code class="xref py py-class docutils literal notranslate"><span class="pre">ConvTranspose1d</span></code></a>
are initialized with same parameters, they are inverses of each other in
regard to the input and output shapes. However, when <code class="docutils literal notranslate"><span class="pre">stride</span> <span class="pre">&gt;</span> <span class="pre">1</span></code>,
<a class="reference internal" href="#torch.nn.Conv1d" title="torch.nn.Conv1d"><code class="xref py py-class docutils literal notranslate"><span class="pre">Conv1d</span></code></a> maps multiple input shapes to the same output
shape. <code class="xref py py-attr docutils literal notranslate"><span class="pre">output_padding</span></code> is provided to resolve this ambiguity by
effectively increasing the calculated output shape on one side. Note
that <code class="xref py py-attr docutils literal notranslate"><span class="pre">output_padding</span></code> is only used to find output shape, but does
not actually add zero-padding to output.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In some circumstances when using the CUDA backend with CuDNN, this operator
may select a nondeterministic algorithm to increase performance. If this is
undesirable, you can try to make the operation deterministic (potentially at
a performance cost) by setting <code class="docutils literal notranslate"><span class="pre">torch.backends.cudnn.deterministic</span> <span class="pre">=</span>
<span class="pre">True</span></code>.
Please see the notes on <a class="reference internal" href="notes/randomness.html"><span class="doc">Reproducibility</span></a> for background.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Number of channels in the input image</p></li>
<li><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Number of channels produced by the convolution</p></li>
<li><p><strong>kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a>) – Size of the convolving kernel</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a><em>, </em><em>optional</em>) – Stride of the convolution. Default: 1</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a><em>, </em><em>optional</em>) – <code class="docutils literal notranslate"><span class="pre">dilation</span> <span class="pre">*</span> <span class="pre">(kernel_size</span> <span class="pre">-</span> <span class="pre">1)</span> <span class="pre">-</span> <span class="pre">padding</span></code> zero-padding
will be added to both sides of the input. Default: 0</p></li>
<li><p><strong>output_padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a><em>, </em><em>optional</em>) – Additional size added to one side
of the output shape. Default: 0</p></li>
<li><p><strong>groups</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em>) – Number of blocked connections from input channels to output channels. Default: 1</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, adds a learnable bias to the output. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a><em>, </em><em>optional</em>) – Spacing between kernel elements. Default: 1</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><p>Input: <img class="math" src="_images/math/ba9d676016927d9f4e3db108ed2621562eedac78.svg" alt="(N, C_{in}, L_{in})"/></p></li>
<li><p>Output: <img class="math" src="_images/math/a87405c2c728e048f517d666188d7c2c5523f018.svg" alt="(N, C_{out}, L_{out})"/> where</p>
<div class="math">
<p><img src="_images/math/97dd769525e152e7e5c3fdd81112b6446fede847.svg" alt="L_{out} = (L_{in} - 1) \times \text{stride} - 2 \times \text{padding} + \text{dilation}
          \times (\text{kernel\_size} - 1) + \text{output\_padding} + 1"/></p>
</div></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>~ConvTranspose1d.weight</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – the learnable weights of the module of shape
<img class="math" src="_images/math/ff8b792801149234e3f783fb1882aa89a448a554.svg" alt="(\text{in\_channels}, \frac{\text{out\_channels}}{\text{groups}},"/>
<img class="math" src="_images/math/305ea7e4b9535c51ebe79cb950100c9b049fded0.svg" alt="\text{kernel\_size})"/>.
The values of these weights are sampled from
<img class="math" src="_images/math/c4acd08f3a59fa0f26605b209d8e6882cffb6300.svg" alt="\mathcal{U}(-\sqrt{k}, \sqrt{k})"/> where
<img class="math" src="_images/math/06587b43a42547941f33e78dd8584638f6e768c1.svg" alt="k = \frac{1}{C_\text{in} * \text{kernel\_size}}"/></p></li>
<li><p><strong>~ConvTranspose1d.bias</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – the learnable bias of the module of shape (out_channels).
If <code class="xref py py-attr docutils literal notranslate"><span class="pre">bias</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, then the values of these weights are
sampled from <img class="math" src="_images/math/c4acd08f3a59fa0f26605b209d8e6882cffb6300.svg" alt="\mathcal{U}(-\sqrt{k}, \sqrt{k})"/> where
<img class="math" src="_images/math/06587b43a42547941f33e78dd8584638f6e768c1.svg" alt="k = \frac{1}{C_\text{in} * \text{kernel\_size}}"/></p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="convtranspose2d">
<h3><span class="hidden-section">ConvTranspose2d</span><a class="headerlink" href="#convtranspose2d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.ConvTranspose2d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">ConvTranspose2d</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">stride=1</em>, <em class="sig-param">padding=0</em>, <em class="sig-param">output_padding=0</em>, <em class="sig-param">groups=1</em>, <em class="sig-param">bias=True</em>, <em class="sig-param">dilation=1</em>, <em class="sig-param">padding_mode='zeros'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/conv.html#ConvTranspose2d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ConvTranspose2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a 2D transposed convolution operator over an input image
composed of several input planes.</p>
<p>This module can be seen as the gradient of Conv2d with respect to its input.
It is also known as a fractionally-strided convolution or
a deconvolution (although it is not an actual deconvolution operation).</p>
<ul>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">stride</span></code> controls the stride for the cross-correlation.</p></li>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code> controls the amount of implicit zero-paddings on both
sides for <code class="docutils literal notranslate"><span class="pre">dilation</span> <span class="pre">*</span> <span class="pre">(kernel_size</span> <span class="pre">-</span> <span class="pre">1)</span> <span class="pre">-</span> <span class="pre">padding</span></code> number of points. See note
below for details.</p></li>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">output_padding</span></code> controls the additional size added to one side
of the output shape. See note below for details.</p></li>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">dilation</span></code> controls the spacing between the kernel points; also known as the à trous algorithm.
It is harder to describe, but this <a class="reference external" href="https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md">link</a> has a nice visualization of what <code class="xref py py-attr docutils literal notranslate"><span class="pre">dilation</span></code> does.</p></li>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">groups</span></code> controls the connections between inputs and outputs.
<code class="xref py py-attr docutils literal notranslate"><span class="pre">in_channels</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">out_channels</span></code> must both be divisible by
<code class="xref py py-attr docutils literal notranslate"><span class="pre">groups</span></code>. For example,</p>
<blockquote>
<div><ul class="simple">
<li><p>At groups=1, all inputs are convolved to all outputs.</p></li>
<li><p>At groups=2, the operation becomes equivalent to having two conv
layers side by side, each seeing half the input channels,
and producing half the output channels, and both subsequently
concatenated.</p></li>
<li><p>At groups= <code class="xref py py-attr docutils literal notranslate"><span class="pre">in_channels</span></code>, each input channel is convolved with
its own set of filters (of size
<img class="math" src="_images/math/5b92cdc3d150fc6be9b65f77b581600c0ac52df4.svg" alt="\left\lfloor\frac{out\_channels}{in\_channels}\right\rfloor"/>).</p></li>
</ul>
</div></blockquote>
</li>
</ul>
<p>The parameters <code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">stride</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">output_padding</span></code>
can either be:</p>
<blockquote>
<div><ul class="simple">
<li><p>a single <code class="docutils literal notranslate"><span class="pre">int</span></code> – in which case the same value is used for the height and width dimensions</p></li>
<li><p>a <code class="docutils literal notranslate"><span class="pre">tuple</span></code> of two ints – in which case, the first <cite>int</cite> is used for the height dimension,
and the second <cite>int</cite> for the width dimension</p></li>
</ul>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Depending of the size of your kernel, several (of the last)
columns of the input might be lost, because it is a valid <a class="reference external" href="https://en.wikipedia.org/wiki/Cross-correlation">cross-correlation</a>,
and not a full <a class="reference external" href="https://en.wikipedia.org/wiki/Cross-correlation">cross-correlation</a>.
It is up to the user to add proper padding.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code> argument effectively adds <code class="docutils literal notranslate"><span class="pre">dilation</span> <span class="pre">*</span> <span class="pre">(kernel_size</span> <span class="pre">-</span> <span class="pre">1)</span> <span class="pre">-</span> <span class="pre">padding</span></code>
amount of zero padding to both sizes of the input. This is set so that
when a <a class="reference internal" href="#torch.nn.Conv2d" title="torch.nn.Conv2d"><code class="xref py py-class docutils literal notranslate"><span class="pre">Conv2d</span></code></a> and a <a class="reference internal" href="#torch.nn.ConvTranspose2d" title="torch.nn.ConvTranspose2d"><code class="xref py py-class docutils literal notranslate"><span class="pre">ConvTranspose2d</span></code></a>
are initialized with same parameters, they are inverses of each other in
regard to the input and output shapes. However, when <code class="docutils literal notranslate"><span class="pre">stride</span> <span class="pre">&gt;</span> <span class="pre">1</span></code>,
<a class="reference internal" href="#torch.nn.Conv2d" title="torch.nn.Conv2d"><code class="xref py py-class docutils literal notranslate"><span class="pre">Conv2d</span></code></a> maps multiple input shapes to the same output
shape. <code class="xref py py-attr docutils literal notranslate"><span class="pre">output_padding</span></code> is provided to resolve this ambiguity by
effectively increasing the calculated output shape on one side. Note
that <code class="xref py py-attr docutils literal notranslate"><span class="pre">output_padding</span></code> is only used to find output shape, but does
not actually add zero-padding to output.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In some circumstances when using the CUDA backend with CuDNN, this operator
may select a nondeterministic algorithm to increase performance. If this is
undesirable, you can try to make the operation deterministic (potentially at
a performance cost) by setting <code class="docutils literal notranslate"><span class="pre">torch.backends.cudnn.deterministic</span> <span class="pre">=</span>
<span class="pre">True</span></code>.
Please see the notes on <a class="reference internal" href="notes/randomness.html"><span class="doc">Reproducibility</span></a> for background.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Number of channels in the input image</p></li>
<li><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Number of channels produced by the convolution</p></li>
<li><p><strong>kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a>) – Size of the convolving kernel</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a><em>, </em><em>optional</em>) – Stride of the convolution. Default: 1</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a><em>, </em><em>optional</em>) – <code class="docutils literal notranslate"><span class="pre">dilation</span> <span class="pre">*</span> <span class="pre">(kernel_size</span> <span class="pre">-</span> <span class="pre">1)</span> <span class="pre">-</span> <span class="pre">padding</span></code> zero-padding
will be added to both sides of each dimension in the input. Default: 0</p></li>
<li><p><strong>output_padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a><em>, </em><em>optional</em>) – Additional size added to one side
of each dimension in the output shape. Default: 0</p></li>
<li><p><strong>groups</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em>) – Number of blocked connections from input channels to output channels. Default: 1</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, adds a learnable bias to the output. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a><em>, </em><em>optional</em>) – Spacing between kernel elements. Default: 1</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/c0cc56295701f42802f20d2bdf887ccc62ec46b0.svg" alt="(N, C_{in}, H_{in}, W_{in})"/></p></li>
<li><p>Output: <img class="math" src="_images/math/31082b446078c7104cc6cbf38999e900e6e7af7a.svg" alt="(N, C_{out}, H_{out}, W_{out})"/> where</p></li>
</ul>
<div class="math">
<p><img src="_images/math/779b8025e6f7ebf6895636823f357f39c4acc4ff.svg" alt="H_{out} = (H_{in} - 1) \times \text{stride}[0] - 2 \times \text{padding}[0] + \text{dilation}[0]
          \times (\text{kernel\_size}[0] - 1) + \text{output\_padding}[0] + 1"/></p>
</div><div class="math">
<p><img src="_images/math/aa59bbd3506237419d547142dedae85050f5af45.svg" alt="W_{out} = (W_{in} - 1) \times \text{stride}[1] - 2 \times \text{padding}[1] + \text{dilation}[1]
          \times (\text{kernel\_size}[1] - 1) + \text{output\_padding}[1] + 1"/></p>
</div></dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>~ConvTranspose2d.weight</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – the learnable weights of the module of shape
<img class="math" src="_images/math/ff8b792801149234e3f783fb1882aa89a448a554.svg" alt="(\text{in\_channels}, \frac{\text{out\_channels}}{\text{groups}},"/>
<img class="math" src="_images/math/e208f2735483d72ea8954b1eb27fc28d8e5b869e.svg" alt="\text{kernel\_size[0]}, \text{kernel\_size[1]})"/>.
The values of these weights are sampled from
<img class="math" src="_images/math/c4acd08f3a59fa0f26605b209d8e6882cffb6300.svg" alt="\mathcal{U}(-\sqrt{k}, \sqrt{k})"/> where
<img class="math" src="_images/math/8ffd283c65a22625c6ff647f6b2d3e871266a00d.svg" alt="k = \frac{1}{C_\text{in} * \prod_{i=0}^{1}\text{kernel\_size}[i]}"/></p></li>
<li><p><strong>~ConvTranspose2d.bias</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – the learnable bias of the module of shape (out_channels)
If <code class="xref py py-attr docutils literal notranslate"><span class="pre">bias</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, then the values of these weights are
sampled from <img class="math" src="_images/math/c4acd08f3a59fa0f26605b209d8e6882cffb6300.svg" alt="\mathcal{U}(-\sqrt{k}, \sqrt{k})"/> where
<img class="math" src="_images/math/8ffd283c65a22625c6ff647f6b2d3e871266a00d.svg" alt="k = \frac{1}{C_\text{in} * \prod_{i=0}^{1}\text{kernel\_size}[i]}"/></p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># With square kernels and equal stride</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># non-square kernels and unequal stride and with padding</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># exact output size can be also specified as an argument</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">downsample</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">upsample</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">h</span> <span class="o">=</span> <span class="n">downsample</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">h</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<span class="go">torch.Size([1, 16, 6, 6])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">upsample</span><span class="p">(</span><span class="n">h</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="nb">input</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<span class="go">torch.Size([1, 16, 12, 12])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="convtranspose3d">
<h3><span class="hidden-section">ConvTranspose3d</span><a class="headerlink" href="#convtranspose3d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.ConvTranspose3d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">ConvTranspose3d</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">stride=1</em>, <em class="sig-param">padding=0</em>, <em class="sig-param">output_padding=0</em>, <em class="sig-param">groups=1</em>, <em class="sig-param">bias=True</em>, <em class="sig-param">dilation=1</em>, <em class="sig-param">padding_mode='zeros'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/conv.html#ConvTranspose3d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ConvTranspose3d" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a 3D transposed convolution operator over an input image composed of several input
planes.
The transposed convolution operator multiplies each input value element-wise by a learnable kernel,
and sums over the outputs from all input feature planes.</p>
<p>This module can be seen as the gradient of Conv3d with respect to its input.
It is also known as a fractionally-strided convolution or
a deconvolution (although it is not an actual deconvolution operation).</p>
<ul>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">stride</span></code> controls the stride for the cross-correlation.</p></li>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code> controls the amount of implicit zero-paddings on both
sides for <code class="docutils literal notranslate"><span class="pre">dilation</span> <span class="pre">*</span> <span class="pre">(kernel_size</span> <span class="pre">-</span> <span class="pre">1)</span> <span class="pre">-</span> <span class="pre">padding</span></code> number of points. See note
below for details.</p></li>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">output_padding</span></code> controls the additional size added to one side
of the output shape. See note below for details.</p></li>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">dilation</span></code> controls the spacing between the kernel points; also known as the à trous algorithm.
It is harder to describe, but this <a class="reference external" href="https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md">link</a> has a nice visualization of what <code class="xref py py-attr docutils literal notranslate"><span class="pre">dilation</span></code> does.</p></li>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">groups</span></code> controls the connections between inputs and outputs.
<code class="xref py py-attr docutils literal notranslate"><span class="pre">in_channels</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">out_channels</span></code> must both be divisible by
<code class="xref py py-attr docutils literal notranslate"><span class="pre">groups</span></code>. For example,</p>
<blockquote>
<div><ul class="simple">
<li><p>At groups=1, all inputs are convolved to all outputs.</p></li>
<li><p>At groups=2, the operation becomes equivalent to having two conv
layers side by side, each seeing half the input channels,
and producing half the output channels, and both subsequently
concatenated.</p></li>
<li><p>At groups= <code class="xref py py-attr docutils literal notranslate"><span class="pre">in_channels</span></code>, each input channel is convolved with
its own set of filters (of size
<img class="math" src="_images/math/5b92cdc3d150fc6be9b65f77b581600c0ac52df4.svg" alt="\left\lfloor\frac{out\_channels}{in\_channels}\right\rfloor"/>).</p></li>
</ul>
</div></blockquote>
</li>
</ul>
<p>The parameters <code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">stride</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">output_padding</span></code>
can either be:</p>
<blockquote>
<div><ul class="simple">
<li><p>a single <code class="docutils literal notranslate"><span class="pre">int</span></code> – in which case the same value is used for the depth, height and width dimensions</p></li>
<li><p>a <code class="docutils literal notranslate"><span class="pre">tuple</span></code> of three ints – in which case, the first <cite>int</cite> is used for the depth dimension,
the second <cite>int</cite> for the height dimension and the third <cite>int</cite> for the width dimension</p></li>
</ul>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Depending of the size of your kernel, several (of the last)
columns of the input might be lost, because it is a valid <a class="reference external" href="https://en.wikipedia.org/wiki/Cross-correlation">cross-correlation</a>,
and not a full <a class="reference external" href="https://en.wikipedia.org/wiki/Cross-correlation">cross-correlation</a>.
It is up to the user to add proper padding.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code> argument effectively adds <code class="docutils literal notranslate"><span class="pre">dilation</span> <span class="pre">*</span> <span class="pre">(kernel_size</span> <span class="pre">-</span> <span class="pre">1)</span> <span class="pre">-</span> <span class="pre">padding</span></code>
amount of zero padding to both sizes of the input. This is set so that
when a <a class="reference internal" href="#torch.nn.Conv3d" title="torch.nn.Conv3d"><code class="xref py py-class docutils literal notranslate"><span class="pre">Conv3d</span></code></a> and a <a class="reference internal" href="#torch.nn.ConvTranspose3d" title="torch.nn.ConvTranspose3d"><code class="xref py py-class docutils literal notranslate"><span class="pre">ConvTranspose3d</span></code></a>
are initialized with same parameters, they are inverses of each other in
regard to the input and output shapes. However, when <code class="docutils literal notranslate"><span class="pre">stride</span> <span class="pre">&gt;</span> <span class="pre">1</span></code>,
<a class="reference internal" href="#torch.nn.Conv3d" title="torch.nn.Conv3d"><code class="xref py py-class docutils literal notranslate"><span class="pre">Conv3d</span></code></a> maps multiple input shapes to the same output
shape. <code class="xref py py-attr docutils literal notranslate"><span class="pre">output_padding</span></code> is provided to resolve this ambiguity by
effectively increasing the calculated output shape on one side. Note
that <code class="xref py py-attr docutils literal notranslate"><span class="pre">output_padding</span></code> is only used to find output shape, but does
not actually add zero-padding to output.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In some circumstances when using the CUDA backend with CuDNN, this operator
may select a nondeterministic algorithm to increase performance. If this is
undesirable, you can try to make the operation deterministic (potentially at
a performance cost) by setting <code class="docutils literal notranslate"><span class="pre">torch.backends.cudnn.deterministic</span> <span class="pre">=</span>
<span class="pre">True</span></code>.
Please see the notes on <a class="reference internal" href="notes/randomness.html"><span class="doc">Reproducibility</span></a> for background.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Number of channels in the input image</p></li>
<li><p><strong>out_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Number of channels produced by the convolution</p></li>
<li><p><strong>kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a>) – Size of the convolving kernel</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a><em>, </em><em>optional</em>) – Stride of the convolution. Default: 1</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a><em>, </em><em>optional</em>) – <code class="docutils literal notranslate"><span class="pre">dilation</span> <span class="pre">*</span> <span class="pre">(kernel_size</span> <span class="pre">-</span> <span class="pre">1)</span> <span class="pre">-</span> <span class="pre">padding</span></code> zero-padding
will be added to both sides of each dimension in the input. Default: 0</p></li>
<li><p><strong>output_padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a><em>, </em><em>optional</em>) – Additional size added to one side
of each dimension in the output shape. Default: 0</p></li>
<li><p><strong>groups</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em>) – Number of blocked connections from input channels to output channels. Default: 1</p></li>
<li><p><strong>bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, adds a learnable bias to the output. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a><em>, </em><em>optional</em>) – Spacing between kernel elements. Default: 1</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/b4584b987e05b58f4ebbe801f0fc7e18d9ed475e.svg" alt="(N, C_{in}, D_{in}, H_{in}, W_{in})"/></p></li>
<li><p>Output: <img class="math" src="_images/math/748cbb70f0586cafc4561c15425a065bb0506c4b.svg" alt="(N, C_{out}, D_{out}, H_{out}, W_{out})"/> where</p></li>
</ul>
<div class="math">
<p><img src="_images/math/129aa1e5e6a8e46bcdc6df4d90996f8af41a6395.svg" alt="D_{out} = (D_{in} - 1) \times \text{stride}[0] - 2 \times \text{padding}[0] + \text{dilation}[0]
          \times (\text{kernel\_size}[0] - 1) + \text{output\_padding}[0] + 1"/></p>
</div><div class="math">
<p><img src="_images/math/9bea7b336eaa4d0977b10db3280702ee96637e88.svg" alt="H_{out} = (H_{in} - 1) \times \text{stride}[1] - 2 \times \text{padding}[1] + \text{dilation}[1]
          \times (\text{kernel\_size}[1] - 1) + \text{output\_padding}[1] + 1"/></p>
</div><div class="math">
<p><img src="_images/math/44192fc7ee563e885c8e0cb51414019f6aa3456b.svg" alt="W_{out} = (W_{in} - 1) \times \text{stride}[2] - 2 \times \text{padding}[2] + \text{dilation}[2]
          \times (\text{kernel\_size}[2] - 1) + \text{output\_padding}[2] + 1"/></p>
</div></dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>~ConvTranspose3d.weight</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – the learnable weights of the module of shape
<img class="math" src="_images/math/ff8b792801149234e3f783fb1882aa89a448a554.svg" alt="(\text{in\_channels}, \frac{\text{out\_channels}}{\text{groups}},"/>
<img class="math" src="_images/math/ca70e34b69f87dfc804a8d16561c4667b05913be.svg" alt="\text{kernel\_size[0]}, \text{kernel\_size[1]}, \text{kernel\_size[2]})"/>.
The values of these weights are sampled from
<img class="math" src="_images/math/c4acd08f3a59fa0f26605b209d8e6882cffb6300.svg" alt="\mathcal{U}(-\sqrt{k}, \sqrt{k})"/> where
<img class="math" src="_images/math/312282962fae5c354d52351698a4905f642edf31.svg" alt="k = \frac{1}{C_\text{in} * \prod_{i=0}^{2}\text{kernel\_size}[i]}"/></p></li>
<li><p><strong>~ConvTranspose3d.bias</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – the learnable bias of the module of shape (out_channels)
If <code class="xref py py-attr docutils literal notranslate"><span class="pre">bias</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, then the values of these weights are
sampled from <img class="math" src="_images/math/c4acd08f3a59fa0f26605b209d8e6882cffb6300.svg" alt="\mathcal{U}(-\sqrt{k}, \sqrt{k})"/> where
<img class="math" src="_images/math/312282962fae5c354d52351698a4905f642edf31.svg" alt="k = \frac{1}{C_\text{in} * \prod_{i=0}^{2}\text{kernel\_size}[i]}"/></p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># With square kernels and equal stride</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose3d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># non-square kernels and unequal stride and with padding</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose3d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="unfold">
<h3><span class="hidden-section">Unfold</span><a class="headerlink" href="#unfold" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.Unfold">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">Unfold</code><span class="sig-paren">(</span><em class="sig-param">kernel_size</em>, <em class="sig-param">dilation=1</em>, <em class="sig-param">padding=0</em>, <em class="sig-param">stride=1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/fold.html#Unfold"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Unfold" title="Permalink to this definition">¶</a></dt>
<dd><p>Extracts sliding local blocks from a batched input tensor.</p>
<p>Consider an batched <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> tensor of shape <img class="math" src="_images/math/075615abf7466dfa600630602ad19a424154bc93.svg" alt="(N, C, *)"/>,
where <img class="math" src="_images/math/3bfb3a64189a14b2704f4610827762d5e3145114.svg" alt="N"/> is the batch dimension, <img class="math" src="_images/math/4db5b6e16e06f929ce3f675c5e535d06ffb02ff7.svg" alt="C"/> is the channel dimension,
and <img class="math" src="_images/math/520a99913b8ff14daccff07aa63cdb8d6583e0fc.svg" alt="*"/> represent arbitrary spatial dimensions. This operation flattens
each sliding <code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code>-sized block within the spatial dimensions
of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> into a column (i.e., last dimension) of a 3-D <code class="xref py py-attr docutils literal notranslate"><span class="pre">output</span></code>
tensor of shape <img class="math" src="_images/math/eb783d7dc44940d3d9c1803a1c96cb2bb63e1ab5.svg" alt="(N, C \times \prod(\text{kernel\_size}), L)"/>, where
<img class="math" src="_images/math/329b4e2c99aee5f303bd2f34fa442b8b0d665b70.svg" alt="C \times \prod(\text{kernel\_size})"/> is the total number of values
within each block (a block has <img class="math" src="_images/math/0d74d24e89362428ee063e5edd47ded8fdeb2b5e.svg" alt="\prod(\text{kernel\_size})"/> spatial
locations each containing a <img class="math" src="_images/math/4db5b6e16e06f929ce3f675c5e535d06ffb02ff7.svg" alt="C"/>-channeled vector), and <img class="math" src="_images/math/19eef1966f7c545af3ac8c0fa486974d873e3c65.svg" alt="L"/> is
the total number of such blocks:</p>
<div class="math">
<p><img src="_images/math/ccb7812728b1bc54e3379494e5a6811cd9a6f751.svg" alt="L = \prod_d \left\lfloor\frac{\text{spatial\_size}[d] + 2 \times \text{padding}[d] %
    - \text{dilation}[d] \times (\text{kernel\_size}[d] - 1) - 1}{\text{stride}[d]} + 1\right\rfloor,"/></p>
</div><p>where <img class="math" src="_images/math/fdb669720779166cca25553ab03770dc5a6cba2d.svg" alt="\text{spatial\_size}"/> is formed by the spatial dimensions
of <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> (<img class="math" src="_images/math/520a99913b8ff14daccff07aa63cdb8d6583e0fc.svg" alt="*"/> above), and <img class="math" src="_images/math/badad346f6fbe2e237af99bfbd9a93a4da53a3da.svg" alt="d"/> is over all spatial
dimensions.</p>
<p>Therefore, indexing <code class="xref py py-attr docutils literal notranslate"><span class="pre">output</span></code> at the last dimension (column dimension)
gives all values within a certain block.</p>
<p>The <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">stride</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">dilation</span></code> arguments specify
how the sliding blocks are retrieved.</p>
<ul class="simple">
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">stride</span></code> controls the stride for the sliding blocks.</p></li>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code> controls the amount of implicit zero-paddings on both
sides for <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code> number of points for each dimension before
reshaping.</p></li>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">dilation</span></code> controls the spacing between the kernel points; also known as the à trous algorithm.
It is harder to describe, but this <a class="reference external" href="https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md">link</a> has a nice visualization of what <code class="xref py py-attr docutils literal notranslate"><span class="pre">dilation</span></code> does.</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a>) – the size of the sliding blocks</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a><em>, </em><em>optional</em>) – the stride of the sliding blocks in the input
spatial dimensions. Default: 1</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a><em>, </em><em>optional</em>) – implicit zero padding to be added on
both sides of input. Default: 0</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a><em>, </em><em>optional</em>) – a parameter that controls the
stride of elements within the
neighborhood. Default: 1</p></li>
</ul>
</dd>
</dl>
<ul class="simple">
<li><p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">dilation</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code> or
<code class="xref py py-attr docutils literal notranslate"><span class="pre">stride</span></code> is an int or a tuple of length 1, their values will be
replicated across all spatial dimensions.</p></li>
<li><p>For the case of two input spatial dimensions this operation is sometimes
called <code class="docutils literal notranslate"><span class="pre">im2col</span></code>.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#torch.nn.Fold" title="torch.nn.Fold"><code class="xref py py-class docutils literal notranslate"><span class="pre">Fold</span></code></a> calculates each combined value in the resulting
large tensor by summing all values from all containing blocks.
<a class="reference internal" href="#torch.nn.Unfold" title="torch.nn.Unfold"><code class="xref py py-class docutils literal notranslate"><span class="pre">Unfold</span></code></a> extracts the values in the local blocks by
copying from the large tensor. So, if the blocks overlap, they are not
inverses of each other.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Currently, only 4-D input tensors (batched image-like tensors) are
supported.</p>
</div>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/075615abf7466dfa600630602ad19a424154bc93.svg" alt="(N, C, *)"/></p></li>
<li><p>Output: <img class="math" src="_images/math/eb783d7dc44940d3d9c1803a1c96cb2bb63e1ab5.svg" alt="(N, C \times \prod(\text{kernel\_size}), L)"/> as described above</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">unfold</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Unfold</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">unfold</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># each patch contains 30 values (2x3=6 vectors, each of 5 channels)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 4 blocks (2x3 kernels) in total in the 3x4 input</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<span class="go">torch.Size([2, 30, 4])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Convolution is equivalent with Unfold + Matrix Multiplication + Fold (or view to output shape)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">inp_unf</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">unfold</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out_unf</span> <span class="o">=</span> <span class="n">inp_unf</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">w</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">t</span><span class="p">())</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">fold</span><span class="p">(</span><span class="n">out_unf</span><span class="p">,</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># or equivalently (and avoiding a copy),</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># out = out_unf.view(1, 2, 7, 8)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span> <span class="o">-</span> <span class="n">out</span><span class="p">)</span><span class="o">.</span><span class="n">abs</span><span class="p">()</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
<span class="go">tensor(1.9073e-06)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="fold">
<h3><span class="hidden-section">Fold</span><a class="headerlink" href="#fold" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.Fold">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">Fold</code><span class="sig-paren">(</span><em class="sig-param">output_size</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">dilation=1</em>, <em class="sig-param">padding=0</em>, <em class="sig-param">stride=1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/fold.html#Fold"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Fold" title="Permalink to this definition">¶</a></dt>
<dd><p>Combines an array of sliding local blocks into a large containing
tensor.</p>
<p>Consider a batched <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> tensor containing sliding local blocks,
e.g., patches of images, of shape <img class="math" src="_images/math/e2aba09d392a894d7c8f399b84561b7bb63d3dbd.svg" alt="(N, C \times  \prod(\text{kernel\_size}), L)"/>,
where <img class="math" src="_images/math/3bfb3a64189a14b2704f4610827762d5e3145114.svg" alt="N"/> is batch dimension, <img class="math" src="_images/math/329b4e2c99aee5f303bd2f34fa442b8b0d665b70.svg" alt="C \times \prod(\text{kernel\_size})"/>
is the number of values within a block (a block has <img class="math" src="_images/math/0d74d24e89362428ee063e5edd47ded8fdeb2b5e.svg" alt="\prod(\text{kernel\_size})"/>
spatial locations each containing a <img class="math" src="_images/math/4db5b6e16e06f929ce3f675c5e535d06ffb02ff7.svg" alt="C"/>-channeled vector), and
<img class="math" src="_images/math/19eef1966f7c545af3ac8c0fa486974d873e3c65.svg" alt="L"/> is the total number of blocks. (This is exactly the
same specification as the output shape of <a class="reference internal" href="#torch.nn.Unfold" title="torch.nn.Unfold"><code class="xref py py-class docutils literal notranslate"><span class="pre">Unfold</span></code></a>.) This
operation combines these local blocks into the large <code class="xref py py-attr docutils literal notranslate"><span class="pre">output</span></code> tensor
of shape <img class="math" src="_images/math/6a8b062bcc62099c03fd65296262d5faa1555789.svg" alt="(N, C, \text{output\_size}[0], \text{output\_size}[1], \dots)"/>
by summing the overlapping values. Similar to <a class="reference internal" href="#torch.nn.Unfold" title="torch.nn.Unfold"><code class="xref py py-class docutils literal notranslate"><span class="pre">Unfold</span></code></a>, the
arguments must satisfy</p>
<div class="math">
<p><img src="_images/math/6ce9fff7f4e4f4e60ed92907288893a6c9f1f8e7.svg" alt="L = \prod_d \left\lfloor\frac{\text{output\_size}[d] + 2 \times \text{padding}[d] %
    - \text{dilation}[d] \times (\text{kernel\_size}[d] - 1) - 1}{\text{stride}[d]} + 1\right\rfloor,"/></p>
</div><p>where <img class="math" src="_images/math/badad346f6fbe2e237af99bfbd9a93a4da53a3da.svg" alt="d"/> is over all spatial dimensions.</p>
<ul class="simple">
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">output_size</span></code> describes the spatial shape of the large containing
tensor of the sliding local blocks. It is useful to resolve the ambiguity
when multiple input shapes map to same number of sliding blocks, e.g.,
with <code class="docutils literal notranslate"><span class="pre">stride</span> <span class="pre">&gt;</span> <span class="pre">0</span></code>.</p></li>
</ul>
<p>The <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">stride</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">dilation</span></code> arguments specify
how the sliding blocks are retrieved.</p>
<ul class="simple">
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">stride</span></code> controls the stride for the sliding blocks.</p></li>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code> controls the amount of implicit zero-paddings on both
sides for <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code> number of points for each dimension before
reshaping.</p></li>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">dilation</span></code> controls the spacing between the kernel points; also known as the à trous algorithm.
It is harder to describe, but this <a class="reference external" href="https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md">link</a> has a nice visualization of what <code class="xref py py-attr docutils literal notranslate"><span class="pre">dilation</span></code> does.</p></li>
</ul>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>output_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a>) – the shape of the spatial dimensions of the
output (i.e., <code class="docutils literal notranslate"><span class="pre">output.sizes()[2:]</span></code>)</p></li>
<li><p><strong>kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a>) – the size of the sliding blocks</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a>) – the stride of the sliding blocks in the input
spatial dimensions. Default: 1</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a><em>, </em><em>optional</em>) – implicit zero padding to be added on
both sides of input. Default: 0</p></li>
<li><p><strong>dilation</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a><em>, </em><em>optional</em>) – a parameter that controls the
stride of elements within the
neighborhood. Default: 1</p></li>
</ul>
</dd>
</dl>
<ul class="simple">
<li><p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">output_size</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">dilation</span></code>,
<code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code> or <code class="xref py py-attr docutils literal notranslate"><span class="pre">stride</span></code> is an int or a tuple of length 1 then
their values will be replicated across all spatial dimensions.</p></li>
<li><p>For the case of two output spatial dimensions this operation is sometimes
called <code class="docutils literal notranslate"><span class="pre">col2im</span></code>.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#torch.nn.Fold" title="torch.nn.Fold"><code class="xref py py-class docutils literal notranslate"><span class="pre">Fold</span></code></a> calculates each combined value in the resulting
large tensor by summing all values from all containing blocks.
<a class="reference internal" href="#torch.nn.Unfold" title="torch.nn.Unfold"><code class="xref py py-class docutils literal notranslate"><span class="pre">Unfold</span></code></a> extracts the values in the local blocks by
copying from the large tensor. So, if the blocks overlap, they are not
inverses of each other.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Currently, only 4-D output tensors (batched image-like tensors) are
supported.</p>
</div>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/eb783d7dc44940d3d9c1803a1c96cb2bb63e1ab5.svg" alt="(N, C \times \prod(\text{kernel\_size}), L)"/></p></li>
<li><p>Output: <img class="math" src="_images/math/6a8b062bcc62099c03fd65296262d5faa1555789.svg" alt="(N, C, \text{output\_size}[0], \text{output\_size}[1], \dots)"/> as described above</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">fold</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Fold</span><span class="p">(</span><span class="n">output_size</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">),</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">12</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">fold</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<span class="go">torch.Size([1, 3, 4, 5])</span>
</pre></div>
</div>
</dd></dl>

</div>
</div>
<div class="section" id="pooling-layers">
<h2>Pooling layers<a class="headerlink" href="#pooling-layers" title="Permalink to this headline">¶</a></h2>
<div class="section" id="maxpool1d">
<h3><span class="hidden-section">MaxPool1d</span><a class="headerlink" href="#maxpool1d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.MaxPool1d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">MaxPool1d</code><span class="sig-paren">(</span><em class="sig-param">kernel_size</em>, <em class="sig-param">stride=None</em>, <em class="sig-param">padding=0</em>, <em class="sig-param">dilation=1</em>, <em class="sig-param">return_indices=False</em>, <em class="sig-param">ceil_mode=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/pooling.html#MaxPool1d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.MaxPool1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a 1D max pooling over an input signal composed of several input
planes.</p>
<p>In the simplest case, the output value of the layer with input size <img class="math" src="_images/math/8d4eab9abe2fd5aeffd8210c4059fb7b01be90fb.svg" alt="(N, C, L)"/>
and output <img class="math" src="_images/math/76c56af52c19043f5561254f7555a535f3012cd2.svg" alt="(N, C, L_{out})"/> can be precisely described as:</p>
<div class="math">
<p><img src="_images/math/41b0f9827692cec7e11476e0c87dc13f0eba5869.svg" alt="out(N_i, C_j, k) = \max_{m=0, \ldots, \text{kernel\_size} - 1}
        input(N_i, C_j, stride \times k + m)"/></p>
</div><p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code> is non-zero, then the input is implicitly zero-padded on both sides
for <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code> number of points. <code class="xref py py-attr docutils literal notranslate"><span class="pre">dilation</span></code> controls the spacing between the kernel points.
It is harder to describe, but this <a class="reference external" href="https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md">link</a> has a nice visualization of what <code class="xref py py-attr docutils literal notranslate"><span class="pre">dilation</span></code> does.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> – the size of the window to take a max over</p></li>
<li><p><strong>stride</strong> – the stride of the window. Default value is <code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code></p></li>
<li><p><strong>padding</strong> – implicit zero padding to be added on both sides</p></li>
<li><p><strong>dilation</strong> – a parameter that controls the stride of elements in the window</p></li>
<li><p><strong>return_indices</strong> – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, will return the max indices along with the outputs.
Useful for <a class="reference internal" href="#torch.nn.MaxUnpool1d" title="torch.nn.MaxUnpool1d"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.MaxUnpool1d</span></code></a> later</p></li>
<li><p><strong>ceil_mode</strong> – when True, will use <cite>ceil</cite> instead of <cite>floor</cite> to compute the output shape</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><p>Input: <img class="math" src="_images/math/e76c4ba68d941ce8b248b7dddbd4d71890b1df9b.svg" alt="(N, C, L_{in})"/></p></li>
<li><p>Output: <img class="math" src="_images/math/76c56af52c19043f5561254f7555a535f3012cd2.svg" alt="(N, C, L_{out})"/>, where</p>
<div class="math">
<p><img src="_images/math/1299f05c0bfdadbc36d2cd6d47ed57c4a7309ca8.svg" alt="L_{out} = \left\lfloor \frac{L_{in} + 2 \times \text{padding} - \text{dilation}
      \times (\text{kernel\_size} - 1) - 1}{\text{stride}} + 1\right\rfloor"/></p>
</div></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># pool of size=3, stride=2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool1d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="maxpool2d">
<h3><span class="hidden-section">MaxPool2d</span><a class="headerlink" href="#maxpool2d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.MaxPool2d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">MaxPool2d</code><span class="sig-paren">(</span><em class="sig-param">kernel_size</em>, <em class="sig-param">stride=None</em>, <em class="sig-param">padding=0</em>, <em class="sig-param">dilation=1</em>, <em class="sig-param">return_indices=False</em>, <em class="sig-param">ceil_mode=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/pooling.html#MaxPool2d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.MaxPool2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a 2D max pooling over an input signal composed of several input
planes.</p>
<p>In the simplest case, the output value of the layer with input size <img class="math" src="_images/math/682f63eaded2237f913167b337a56425e537bdb3.svg" alt="(N, C, H, W)"/>,
output <img class="math" src="_images/math/4026633441f65aa86208d4b12337149db951eab6.svg" alt="(N, C, H_{out}, W_{out})"/> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code> <img class="math" src="_images/math/a264d6151a064db459d93118627ad63cf44f7878.svg" alt="(kH, kW)"/>
can be precisely described as:</p>
<div class="math">
<p><img src="_images/math/21f541c645c8bf2ad26468860b7db2e0c079fe48.svg" alt="\begin{aligned}
    out(N_i, C_j, h, w) ={} &amp; \max_{m=0, \ldots, kH-1} \max_{n=0, \ldots, kW-1} \\
                            &amp; \text{input}(N_i, C_j, \text{stride[0]} \times h + m,
                                           \text{stride[1]} \times w + n)
\end{aligned}"/></p>
</div><p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code> is non-zero, then the input is implicitly zero-padded on both sides
for <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code> number of points. <code class="xref py py-attr docutils literal notranslate"><span class="pre">dilation</span></code> controls the spacing between the kernel points.
It is harder to describe, but this <a class="reference external" href="https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md">link</a> has a nice visualization of what <code class="xref py py-attr docutils literal notranslate"><span class="pre">dilation</span></code> does.</p>
<p>The parameters <code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">stride</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">dilation</span></code> can either be:</p>
<blockquote>
<div><ul class="simple">
<li><p>a single <code class="docutils literal notranslate"><span class="pre">int</span></code> – in which case the same value is used for the height and width dimension</p></li>
<li><p>a <code class="docutils literal notranslate"><span class="pre">tuple</span></code> of two ints – in which case, the first <cite>int</cite> is used for the height dimension,
and the second <cite>int</cite> for the width dimension</p></li>
</ul>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> – the size of the window to take a max over</p></li>
<li><p><strong>stride</strong> – the stride of the window. Default value is <code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code></p></li>
<li><p><strong>padding</strong> – implicit zero padding to be added on both sides</p></li>
<li><p><strong>dilation</strong> – a parameter that controls the stride of elements in the window</p></li>
<li><p><strong>return_indices</strong> – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, will return the max indices along with the outputs.
Useful for <a class="reference internal" href="#torch.nn.MaxUnpool2d" title="torch.nn.MaxUnpool2d"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.MaxUnpool2d</span></code></a> later</p></li>
<li><p><strong>ceil_mode</strong> – when True, will use <cite>ceil</cite> instead of <cite>floor</cite> to compute the output shape</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><p>Input: <img class="math" src="_images/math/b7920897893b3a5399125387ef94f5084ff3d283.svg" alt="(N, C, H_{in}, W_{in})"/></p></li>
<li><p>Output: <img class="math" src="_images/math/4026633441f65aa86208d4b12337149db951eab6.svg" alt="(N, C, H_{out}, W_{out})"/>, where</p>
<div class="math">
<p><img src="_images/math/00b3df8aa45c41ab69e4f7ca5a1cda3eae66d023.svg" alt="H_{out} = \left\lfloor\frac{H_{in} + 2 * \text{padding[0]} - \text{dilation[0]}
      \times (\text{kernel\_size[0]} - 1) - 1}{\text{stride[0]}} + 1\right\rfloor"/></p>
</div><div class="math">
<p><img src="_images/math/43e49392dc6be1814545359ff3f5a0d46743e855.svg" alt="W_{out} = \left\lfloor\frac{W_{in} + 2 * \text{padding[1]} - \text{dilation[1]}
      \times (\text{kernel\_size[1]} - 1) - 1}{\text{stride[1]}} + 1\right\rfloor"/></p>
</div></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># pool of square window of size=3, stride=2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># pool of non-square window</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="maxpool3d">
<h3><span class="hidden-section">MaxPool3d</span><a class="headerlink" href="#maxpool3d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.MaxPool3d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">MaxPool3d</code><span class="sig-paren">(</span><em class="sig-param">kernel_size</em>, <em class="sig-param">stride=None</em>, <em class="sig-param">padding=0</em>, <em class="sig-param">dilation=1</em>, <em class="sig-param">return_indices=False</em>, <em class="sig-param">ceil_mode=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/pooling.html#MaxPool3d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.MaxPool3d" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a 3D max pooling over an input signal composed of several input
planes.</p>
<p>In the simplest case, the output value of the layer with input size <img class="math" src="_images/math/98ea75cf626098a1b65ba3d34a365f6b32e5f8a8.svg" alt="(N, C, D, H, W)"/>,
output <img class="math" src="_images/math/c01ac11b86bf5ae0b82c88e6bec50ac4ab4a8c15.svg" alt="(N, C, D_{out}, H_{out}, W_{out})"/> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code> <img class="math" src="_images/math/8d13faa72114cf25e993ed0eb4e737f638f54e91.svg" alt="(kD, kH, kW)"/>
can be precisely described as:</p>
<div class="math">
<p><img src="_images/math/1c5834f91a0f81f802de7d6172ba40aecde65bd1.svg" alt="\begin{aligned}
    \text{out}(N_i, C_j, d, h, w) ={} &amp; \max_{k=0, \ldots, kD-1} \max_{m=0, \ldots, kH-1} \max_{n=0, \ldots, kW-1} \\
                                      &amp; \text{input}(N_i, C_j, \text{stride[0]} \times d + k,
                                                     \text{stride[1]} \times h + m, \text{stride[2]} \times w + n)
\end{aligned}"/></p>
</div><p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code> is non-zero, then the input is implicitly zero-padded on both sides
for <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code> number of points. <code class="xref py py-attr docutils literal notranslate"><span class="pre">dilation</span></code> controls the spacing between the kernel points.
It is harder to describe, but this <a class="reference external" href="https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md">link</a> has a nice visualization of what <code class="xref py py-attr docutils literal notranslate"><span class="pre">dilation</span></code> does.</p>
<p>The parameters <code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">stride</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">dilation</span></code> can either be:</p>
<blockquote>
<div><ul class="simple">
<li><p>a single <code class="docutils literal notranslate"><span class="pre">int</span></code> – in which case the same value is used for the depth, height and width dimension</p></li>
<li><p>a <code class="docutils literal notranslate"><span class="pre">tuple</span></code> of three ints – in which case, the first <cite>int</cite> is used for the depth dimension,
the second <cite>int</cite> for the height dimension and the third <cite>int</cite> for the width dimension</p></li>
</ul>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> – the size of the window to take a max over</p></li>
<li><p><strong>stride</strong> – the stride of the window. Default value is <code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code></p></li>
<li><p><strong>padding</strong> – implicit zero padding to be added on all three sides</p></li>
<li><p><strong>dilation</strong> – a parameter that controls the stride of elements in the window</p></li>
<li><p><strong>return_indices</strong> – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, will return the max indices along with the outputs.
Useful for <a class="reference internal" href="#torch.nn.MaxUnpool3d" title="torch.nn.MaxUnpool3d"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.MaxUnpool3d</span></code></a> later</p></li>
<li><p><strong>ceil_mode</strong> – when True, will use <cite>ceil</cite> instead of <cite>floor</cite> to compute the output shape</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><p>Input: <img class="math" src="_images/math/4b57572f196d556e35bdc4edfa15573c3c68b667.svg" alt="(N, C, D_{in}, H_{in}, W_{in})"/></p></li>
<li><p>Output: <img class="math" src="_images/math/c01ac11b86bf5ae0b82c88e6bec50ac4ab4a8c15.svg" alt="(N, C, D_{out}, H_{out}, W_{out})"/>, where</p>
<div class="math">
<p><img src="_images/math/86781c53cd1740462a4f4ee3a90fb448e8661dc3.svg" alt="D_{out} = \left\lfloor\frac{D_{in} + 2 \times \text{padding}[0] - \text{dilation}[0] \times
  (\text{kernel\_size}[0] - 1) - 1}{\text{stride}[0]} + 1\right\rfloor"/></p>
</div><div class="math">
<p><img src="_images/math/16e86ab0cc9bc832ec78809e60a85fa820bd7e54.svg" alt="H_{out} = \left\lfloor\frac{H_{in} + 2 \times \text{padding}[1] - \text{dilation}[1] \times
  (\text{kernel\_size}[1] - 1) - 1}{\text{stride}[1]} + 1\right\rfloor"/></p>
</div><div class="math">
<p><img src="_images/math/7c38c6b70ed348e2e1ad157480f5456474e61558.svg" alt="W_{out} = \left\lfloor\frac{W_{in} + 2 \times \text{padding}[2] - \text{dilation}[2] \times
  (\text{kernel\_size}[2] - 1) - 1}{\text{stride}[2]} + 1\right\rfloor"/></p>
</div></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># pool of square window of size=3, stride=2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool3d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># pool of non-square window</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool3d</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span><span class="mi">44</span><span class="p">,</span> <span class="mi">31</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="maxunpool1d">
<h3><span class="hidden-section">MaxUnpool1d</span><a class="headerlink" href="#maxunpool1d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.MaxUnpool1d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">MaxUnpool1d</code><span class="sig-paren">(</span><em class="sig-param">kernel_size</em>, <em class="sig-param">stride=None</em>, <em class="sig-param">padding=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/pooling.html#MaxUnpool1d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.MaxUnpool1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes a partial inverse of <a class="reference internal" href="#torch.nn.MaxPool1d" title="torch.nn.MaxPool1d"><code class="xref py py-class docutils literal notranslate"><span class="pre">MaxPool1d</span></code></a>.</p>
<p><a class="reference internal" href="#torch.nn.MaxPool1d" title="torch.nn.MaxPool1d"><code class="xref py py-class docutils literal notranslate"><span class="pre">MaxPool1d</span></code></a> is not fully invertible, since the non-maximal values are lost.</p>
<p><a class="reference internal" href="#torch.nn.MaxUnpool1d" title="torch.nn.MaxUnpool1d"><code class="xref py py-class docutils literal notranslate"><span class="pre">MaxUnpool1d</span></code></a> takes in as input the output of <a class="reference internal" href="#torch.nn.MaxPool1d" title="torch.nn.MaxPool1d"><code class="xref py py-class docutils literal notranslate"><span class="pre">MaxPool1d</span></code></a>
including the indices of the maximal values and computes a partial inverse
in which all non-maximal values are set to zero.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#torch.nn.MaxPool1d" title="torch.nn.MaxPool1d"><code class="xref py py-class docutils literal notranslate"><span class="pre">MaxPool1d</span></code></a> can map several input sizes to the same output
sizes. Hence, the inversion process can get ambiguous.
To accommodate this, you can provide the needed output size
as an additional argument <code class="xref py py-attr docutils literal notranslate"><span class="pre">output_size</span></code> in the forward call.
See the Inputs and Example below.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a>) – Size of the max pooling window.</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a>) – Stride of the max pooling window.
It is set to <code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code> by default.</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a>) – Padding that was added to the input</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><cite>input</cite>: the input Tensor to invert</p></li>
<li><p><cite>indices</cite>: the indices given out by <a class="reference internal" href="#torch.nn.MaxPool1d" title="torch.nn.MaxPool1d"><code class="xref py py-class docutils literal notranslate"><span class="pre">MaxPool1d</span></code></a></p></li>
<li><p><cite>output_size</cite> (optional): the targeted output size</p></li>
</ul>
</dd>
<dt>Shape:</dt><dd><ul>
<li><p>Input: <img class="math" src="_images/math/28678329c51195b47e4168ed49092dba64e52ad3.svg" alt="(N, C, H_{in})"/></p></li>
<li><p>Output: <img class="math" src="_images/math/c1f2f11ccfa8d6e55d2f72615b502e0938ecafa2.svg" alt="(N, C, H_{out})"/>, where</p>
<div class="math">
<p><img src="_images/math/42fbaea4bb7fee6498a01bbe17077b0700afb221.svg" alt="H_{out} = (H_{in} - 1) \times \text{stride}[0] - 2 \times \text{padding}[0] + \text{kernel\_size}[0]"/></p>
</div><p>or as given by <code class="xref py py-attr docutils literal notranslate"><span class="pre">output_size</span></code> in the call operator</p>
</li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool1d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">return_indices</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">unpool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxUnpool1d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">pool</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">unpool</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>
<span class="go">tensor([[[ 0.,  2.,  0.,  4.,  0.,  6.,  0., 8.]]])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Example showcasing the use of output_size</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[[</span><span class="mf">1.</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">pool</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">unpool</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="nb">input</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">tensor([[[ 0.,  2.,  0.,  4.,  0.,  6.,  0., 8.,  0.]]])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">unpool</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>
<span class="go">tensor([[[ 0.,  2.,  0.,  4.,  0.,  6.,  0., 8.]]])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="maxunpool2d">
<h3><span class="hidden-section">MaxUnpool2d</span><a class="headerlink" href="#maxunpool2d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.MaxUnpool2d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">MaxUnpool2d</code><span class="sig-paren">(</span><em class="sig-param">kernel_size</em>, <em class="sig-param">stride=None</em>, <em class="sig-param">padding=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/pooling.html#MaxUnpool2d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.MaxUnpool2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes a partial inverse of <a class="reference internal" href="#torch.nn.MaxPool2d" title="torch.nn.MaxPool2d"><code class="xref py py-class docutils literal notranslate"><span class="pre">MaxPool2d</span></code></a>.</p>
<p><a class="reference internal" href="#torch.nn.MaxPool2d" title="torch.nn.MaxPool2d"><code class="xref py py-class docutils literal notranslate"><span class="pre">MaxPool2d</span></code></a> is not fully invertible, since the non-maximal values are lost.</p>
<p><a class="reference internal" href="#torch.nn.MaxUnpool2d" title="torch.nn.MaxUnpool2d"><code class="xref py py-class docutils literal notranslate"><span class="pre">MaxUnpool2d</span></code></a> takes in as input the output of <a class="reference internal" href="#torch.nn.MaxPool2d" title="torch.nn.MaxPool2d"><code class="xref py py-class docutils literal notranslate"><span class="pre">MaxPool2d</span></code></a>
including the indices of the maximal values and computes a partial inverse
in which all non-maximal values are set to zero.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#torch.nn.MaxPool2d" title="torch.nn.MaxPool2d"><code class="xref py py-class docutils literal notranslate"><span class="pre">MaxPool2d</span></code></a> can map several input sizes to the same output
sizes. Hence, the inversion process can get ambiguous.
To accommodate this, you can provide the needed output size
as an additional argument <code class="xref py py-attr docutils literal notranslate"><span class="pre">output_size</span></code> in the forward call.
See the Inputs and Example below.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a>) – Size of the max pooling window.</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a>) – Stride of the max pooling window.
It is set to <code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code> by default.</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a>) – Padding that was added to the input</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><cite>input</cite>: the input Tensor to invert</p></li>
<li><p><cite>indices</cite>: the indices given out by <a class="reference internal" href="#torch.nn.MaxPool2d" title="torch.nn.MaxPool2d"><code class="xref py py-class docutils literal notranslate"><span class="pre">MaxPool2d</span></code></a></p></li>
<li><p><cite>output_size</cite> (optional): the targeted output size</p></li>
</ul>
</dd>
<dt>Shape:</dt><dd><ul>
<li><p>Input: <img class="math" src="_images/math/b7920897893b3a5399125387ef94f5084ff3d283.svg" alt="(N, C, H_{in}, W_{in})"/></p></li>
<li><p>Output: <img class="math" src="_images/math/4026633441f65aa86208d4b12337149db951eab6.svg" alt="(N, C, H_{out}, W_{out})"/>, where</p>
<div class="math">
<p><img src="_images/math/e127c55b863dfaf16c606b530595d400f8ee22b8.svg" alt="H_{out} = (H_{in} - 1) \times \text{stride[0]} - 2 \times \text{padding[0]} + \text{kernel\_size[0]}"/></p>
</div><div class="math">
<p><img src="_images/math/1aa872fc803342fa4de4ae3633e220812e642272.svg" alt="W_{out} = (W_{in} - 1) \times \text{stride[1]} - 2 \times \text{padding[1]} + \text{kernel\_size[1]}"/></p>
</div><p>or as given by <code class="xref py py-attr docutils literal notranslate"><span class="pre">output_size</span></code> in the call operator</p>
</li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">return_indices</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">unpool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxUnpool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[[[</span> <span class="mf">1.</span><span class="p">,</span>  <span class="mi">2</span><span class="p">,</span>  <span class="mi">3</span><span class="p">,</span>  <span class="mi">4</span><span class="p">],</span>
<span class="go">                            [ 5,  6,  7,  8],</span>
<span class="go">                            [ 9, 10, 11, 12],</span>
<span class="go">                            [13, 14, 15, 16]]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">pool</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">unpool</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>
<span class="go">tensor([[[[  0.,   0.,   0.,   0.],</span>
<span class="go">          [  0.,   6.,   0.,   8.],</span>
<span class="go">          [  0.,   0.,   0.,   0.],</span>
<span class="go">          [  0.,  14.,   0.,  16.]]]])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># specify a different output size than input size</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">unpool</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">Size</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">]))</span>
<span class="go">tensor([[[[  0.,   0.,   0.,   0.,   0.],</span>
<span class="go">          [  6.,   0.,   8.,   0.,   0.],</span>
<span class="go">          [  0.,   0.,   0.,  14.,   0.],</span>
<span class="go">          [ 16.,   0.,   0.,   0.,   0.],</span>
<span class="go">          [  0.,   0.,   0.,   0.,   0.]]]])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="maxunpool3d">
<h3><span class="hidden-section">MaxUnpool3d</span><a class="headerlink" href="#maxunpool3d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.MaxUnpool3d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">MaxUnpool3d</code><span class="sig-paren">(</span><em class="sig-param">kernel_size</em>, <em class="sig-param">stride=None</em>, <em class="sig-param">padding=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/pooling.html#MaxUnpool3d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.MaxUnpool3d" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes a partial inverse of <a class="reference internal" href="#torch.nn.MaxPool3d" title="torch.nn.MaxPool3d"><code class="xref py py-class docutils literal notranslate"><span class="pre">MaxPool3d</span></code></a>.</p>
<p><a class="reference internal" href="#torch.nn.MaxPool3d" title="torch.nn.MaxPool3d"><code class="xref py py-class docutils literal notranslate"><span class="pre">MaxPool3d</span></code></a> is not fully invertible, since the non-maximal values are lost.
<a class="reference internal" href="#torch.nn.MaxUnpool3d" title="torch.nn.MaxUnpool3d"><code class="xref py py-class docutils literal notranslate"><span class="pre">MaxUnpool3d</span></code></a> takes in as input the output of <a class="reference internal" href="#torch.nn.MaxPool3d" title="torch.nn.MaxPool3d"><code class="xref py py-class docutils literal notranslate"><span class="pre">MaxPool3d</span></code></a>
including the indices of the maximal values and computes a partial inverse
in which all non-maximal values are set to zero.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#torch.nn.MaxPool3d" title="torch.nn.MaxPool3d"><code class="xref py py-class docutils literal notranslate"><span class="pre">MaxPool3d</span></code></a> can map several input sizes to the same output
sizes. Hence, the inversion process can get ambiguous.
To accommodate this, you can provide the needed output size
as an additional argument <code class="xref py py-attr docutils literal notranslate"><span class="pre">output_size</span></code> in the forward call.
See the Inputs section below.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a>) – Size of the max pooling window.</p></li>
<li><p><strong>stride</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a>) – Stride of the max pooling window.
It is set to <code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code> by default.</p></li>
<li><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a>) – Padding that was added to the input</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Inputs:</dt><dd><ul class="simple">
<li><p><cite>input</cite>: the input Tensor to invert</p></li>
<li><p><cite>indices</cite>: the indices given out by <a class="reference internal" href="#torch.nn.MaxPool3d" title="torch.nn.MaxPool3d"><code class="xref py py-class docutils literal notranslate"><span class="pre">MaxPool3d</span></code></a></p></li>
<li><p><cite>output_size</cite> (optional): the targeted output size</p></li>
</ul>
</dd>
<dt>Shape:</dt><dd><ul>
<li><p>Input: <img class="math" src="_images/math/4b57572f196d556e35bdc4edfa15573c3c68b667.svg" alt="(N, C, D_{in}, H_{in}, W_{in})"/></p></li>
<li><p>Output: <img class="math" src="_images/math/c01ac11b86bf5ae0b82c88e6bec50ac4ab4a8c15.svg" alt="(N, C, D_{out}, H_{out}, W_{out})"/>, where</p>
<div class="math">
<p><img src="_images/math/e949beff007ffc63f5d0d7a4743b0022b3b5c9f8.svg" alt="D_{out} = (D_{in} - 1) \times \text{stride[0]} - 2 \times \text{padding[0]} + \text{kernel\_size[0]}"/></p>
</div><div class="math">
<p><img src="_images/math/2a5ac99845ed1da4a82bbe2b40f9f24e215fd6dc.svg" alt="H_{out} = (H_{in} - 1) \times \text{stride[1]} - 2 \times \text{padding[1]} + \text{kernel\_size[1]}"/></p>
</div><div class="math">
<p><img src="_images/math/32931017b78195f5ccb940664755aa8965893144.svg" alt="W_{out} = (W_{in} - 1) \times \text{stride[2]} - 2 \times \text{padding[2]} + \text{kernel\_size[2]}"/></p>
</div><p>or as given by <code class="xref py py-attr docutils literal notranslate"><span class="pre">output_size</span></code> in the call operator</p>
</li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># pool of square window of size=3, stride=2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool3d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">return_indices</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">unpool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxUnpool3d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">indices</span> <span class="o">=</span> <span class="n">pool</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">51</span><span class="p">,</span> <span class="mi">33</span><span class="p">,</span> <span class="mi">15</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">unpooled_output</span> <span class="o">=</span> <span class="n">unpool</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">indices</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">unpooled_output</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<span class="go">torch.Size([20, 16, 51, 33, 15])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="avgpool1d">
<h3><span class="hidden-section">AvgPool1d</span><a class="headerlink" href="#avgpool1d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.AvgPool1d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">AvgPool1d</code><span class="sig-paren">(</span><em class="sig-param">kernel_size</em>, <em class="sig-param">stride=None</em>, <em class="sig-param">padding=0</em>, <em class="sig-param">ceil_mode=False</em>, <em class="sig-param">count_include_pad=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/pooling.html#AvgPool1d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.AvgPool1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a 1D average pooling over an input signal composed of several
input planes.</p>
<p>In the simplest case, the output value of the layer with input size <img class="math" src="_images/math/8d4eab9abe2fd5aeffd8210c4059fb7b01be90fb.svg" alt="(N, C, L)"/>,
output <img class="math" src="_images/math/76c56af52c19043f5561254f7555a535f3012cd2.svg" alt="(N, C, L_{out})"/> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code> <img class="math" src="_images/math/9630132210b904754c9ab272b61cb527d12263ca.svg" alt="k"/>
can be precisely described as:</p>
<div class="math">
<p><img src="_images/math/3106d52991474f92078449d2d26628a400cb69e1.svg" alt="\text{out}(N_i, C_j, l) = \frac{1}{k} \sum_{m=0}^{k-1}
                       \text{input}(N_i, C_j, \text{stride} \times l + m)"/></p>
</div><p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code> is non-zero, then the input is implicitly zero-padded on both sides
for <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code> number of points.</p>
<p>The parameters <code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">stride</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code> can each be
an <code class="docutils literal notranslate"><span class="pre">int</span></code> or a one-element tuple.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> – the size of the window</p></li>
<li><p><strong>stride</strong> – the stride of the window. Default value is <code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code></p></li>
<li><p><strong>padding</strong> – implicit zero padding to be added on both sides</p></li>
<li><p><strong>ceil_mode</strong> – when True, will use <cite>ceil</cite> instead of <cite>floor</cite> to compute the output shape</p></li>
<li><p><strong>count_include_pad</strong> – when True, will include the zero-padding in the averaging calculation</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><p>Input: <img class="math" src="_images/math/e76c4ba68d941ce8b248b7dddbd4d71890b1df9b.svg" alt="(N, C, L_{in})"/></p></li>
<li><p>Output: <img class="math" src="_images/math/76c56af52c19043f5561254f7555a535f3012cd2.svg" alt="(N, C, L_{out})"/>, where</p>
<div class="math">
<p><img src="_images/math/b846aee28eb260d30c034222daa0adbeca9cd3b7.svg" alt="L_{out} = \left\lfloor \frac{L_{in} +
2 \times \text{padding} - \text{kernel\_size}}{\text{stride}} + 1\right\rfloor"/></p>
</div></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># pool with window of size=3, stride=2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool1d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[[</span><span class="mf">1.</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">]]]))</span>
<span class="go">tensor([[[ 2.,  4.,  6.]]])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="avgpool2d">
<h3><span class="hidden-section">AvgPool2d</span><a class="headerlink" href="#avgpool2d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.AvgPool2d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">AvgPool2d</code><span class="sig-paren">(</span><em class="sig-param">kernel_size</em>, <em class="sig-param">stride=None</em>, <em class="sig-param">padding=0</em>, <em class="sig-param">ceil_mode=False</em>, <em class="sig-param">count_include_pad=True</em>, <em class="sig-param">divisor_override=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/pooling.html#AvgPool2d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.AvgPool2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a 2D average pooling over an input signal composed of several input
planes.</p>
<p>In the simplest case, the output value of the layer with input size <img class="math" src="_images/math/682f63eaded2237f913167b337a56425e537bdb3.svg" alt="(N, C, H, W)"/>,
output <img class="math" src="_images/math/4026633441f65aa86208d4b12337149db951eab6.svg" alt="(N, C, H_{out}, W_{out})"/> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code> <img class="math" src="_images/math/a264d6151a064db459d93118627ad63cf44f7878.svg" alt="(kH, kW)"/>
can be precisely described as:</p>
<div class="math">
<p><img src="_images/math/36e069352de24b52ca0011853c7965714d4e32df.svg" alt="out(N_i, C_j, h, w)  = \frac{1}{kH * kW} \sum_{m=0}^{kH-1} \sum_{n=0}^{kW-1}
                       input(N_i, C_j, stride[0] \times h + m, stride[1] \times w + n)"/></p>
</div><p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code> is non-zero, then the input is implicitly zero-padded on both sides
for <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code> number of points.</p>
<p>The parameters <code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">stride</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code> can either be:</p>
<blockquote>
<div><ul class="simple">
<li><p>a single <code class="docutils literal notranslate"><span class="pre">int</span></code> – in which case the same value is used for the height and width dimension</p></li>
<li><p>a <code class="docutils literal notranslate"><span class="pre">tuple</span></code> of two ints – in which case, the first <cite>int</cite> is used for the height dimension,
and the second <cite>int</cite> for the width dimension</p></li>
</ul>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> – the size of the window</p></li>
<li><p><strong>stride</strong> – the stride of the window. Default value is <code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code></p></li>
<li><p><strong>padding</strong> – implicit zero padding to be added on both sides</p></li>
<li><p><strong>ceil_mode</strong> – when True, will use <cite>ceil</cite> instead of <cite>floor</cite> to compute the output shape</p></li>
<li><p><strong>count_include_pad</strong> – when True, will include the zero-padding in the averaging calculation</p></li>
<li><p><strong>divisor_override</strong> – if specified, it will be used as divisor, otherwise attr:<cite>kernel_size</cite> will be used</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><p>Input: <img class="math" src="_images/math/b7920897893b3a5399125387ef94f5084ff3d283.svg" alt="(N, C, H_{in}, W_{in})"/></p></li>
<li><p>Output: <img class="math" src="_images/math/4026633441f65aa86208d4b12337149db951eab6.svg" alt="(N, C, H_{out}, W_{out})"/>, where</p>
<div class="math">
<p><img src="_images/math/055ab8e83af7358795a860c4b2b3ab7c16158e8d.svg" alt="H_{out} = \left\lfloor\frac{H_{in}  + 2 \times \text{padding}[0] -
  \text{kernel\_size}[0]}{\text{stride}[0]} + 1\right\rfloor"/></p>
</div><div class="math">
<p><img src="_images/math/e490230d33770c0d6bde050bcabd90c7d3a95fb9.svg" alt="W_{out} = \left\lfloor\frac{W_{in}  + 2 \times \text{padding}[1] -
  \text{kernel\_size}[1]}{\text{stride}[1]} + 1\right\rfloor"/></p>
</div></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># pool of square window of size=3, stride=2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># pool of non-square window</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool2d</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="avgpool3d">
<h3><span class="hidden-section">AvgPool3d</span><a class="headerlink" href="#avgpool3d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.AvgPool3d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">AvgPool3d</code><span class="sig-paren">(</span><em class="sig-param">kernel_size</em>, <em class="sig-param">stride=None</em>, <em class="sig-param">padding=0</em>, <em class="sig-param">ceil_mode=False</em>, <em class="sig-param">count_include_pad=True</em>, <em class="sig-param">divisor_override=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/pooling.html#AvgPool3d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.AvgPool3d" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a 3D average pooling over an input signal composed of several input
planes.</p>
<p>In the simplest case, the output value of the layer with input size <img class="math" src="_images/math/98ea75cf626098a1b65ba3d34a365f6b32e5f8a8.svg" alt="(N, C, D, H, W)"/>,
output <img class="math" src="_images/math/c01ac11b86bf5ae0b82c88e6bec50ac4ab4a8c15.svg" alt="(N, C, D_{out}, H_{out}, W_{out})"/> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code> <img class="math" src="_images/math/8d13faa72114cf25e993ed0eb4e737f638f54e91.svg" alt="(kD, kH, kW)"/>
can be precisely described as:</p>
<div class="math">
<p><img src="_images/math/6ffa73daf232e7600df0c86cc8337312a536cb42.svg" alt="\begin{aligned}
    \text{out}(N_i, C_j, d, h, w) ={} &amp; \sum_{k=0}^{kD-1} \sum_{m=0}^{kH-1} \sum_{n=0}^{kW-1} \\
                                      &amp; \frac{\text{input}(N_i, C_j, \text{stride}[0] \times d + k,
                                              \text{stride}[1] \times h + m, \text{stride}[2] \times w + n)}
                                             {kD \times kH \times kW}
\end{aligned}"/></p>
</div><p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code> is non-zero, then the input is implicitly zero-padded on all three sides
for <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding</span></code> number of points.</p>
<p>The parameters <code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">stride</span></code> can either be:</p>
<blockquote>
<div><ul class="simple">
<li><p>a single <code class="docutils literal notranslate"><span class="pre">int</span></code> – in which case the same value is used for the depth, height and width dimension</p></li>
<li><p>a <code class="docutils literal notranslate"><span class="pre">tuple</span></code> of three ints – in which case, the first <cite>int</cite> is used for the depth dimension,
the second <cite>int</cite> for the height dimension and the third <cite>int</cite> for the width dimension</p></li>
</ul>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> – the size of the window</p></li>
<li><p><strong>stride</strong> – the stride of the window. Default value is <code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code></p></li>
<li><p><strong>padding</strong> – implicit zero padding to be added on all three sides</p></li>
<li><p><strong>ceil_mode</strong> – when True, will use <cite>ceil</cite> instead of <cite>floor</cite> to compute the output shape</p></li>
<li><p><strong>count_include_pad</strong> – when True, will include the zero-padding in the averaging calculation</p></li>
<li><p><strong>divisor_override</strong> – if specified, it will be used as divisor, otherwise attr:<cite>kernel_size</cite> will be used</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><p>Input: <img class="math" src="_images/math/4b57572f196d556e35bdc4edfa15573c3c68b667.svg" alt="(N, C, D_{in}, H_{in}, W_{in})"/></p></li>
<li><p>Output: <img class="math" src="_images/math/c01ac11b86bf5ae0b82c88e6bec50ac4ab4a8c15.svg" alt="(N, C, D_{out}, H_{out}, W_{out})"/>, where</p>
<div class="math">
<p><img src="_images/math/069b97a3df50e2a2b5a84623a5279c2e4e855d0c.svg" alt="D_{out} = \left\lfloor\frac{D_{in} + 2 \times \text{padding}[0] -
      \text{kernel\_size}[0]}{\text{stride}[0]} + 1\right\rfloor"/></p>
</div><div class="math">
<p><img src="_images/math/f1ab26c7ea340fb7b46a189a359cc80254edca73.svg" alt="H_{out} = \left\lfloor\frac{H_{in} + 2 \times \text{padding}[1] -
      \text{kernel\_size}[1]}{\text{stride}[1]} + 1\right\rfloor"/></p>
</div><div class="math">
<p><img src="_images/math/ac7a90ca7d19d5ed9b5840cd03b613c1e387a8f3.svg" alt="W_{out} = \left\lfloor\frac{W_{in} + 2 \times \text{padding}[2] -
      \text{kernel\_size}[2]}{\text{stride}[2]} + 1\right\rfloor"/></p>
</div></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># pool of square window of size=3, stride=2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool3d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># pool of non-square window</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AvgPool3d</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span><span class="mi">44</span><span class="p">,</span> <span class="mi">31</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="fractionalmaxpool2d">
<h3><span class="hidden-section">FractionalMaxPool2d</span><a class="headerlink" href="#fractionalmaxpool2d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.FractionalMaxPool2d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">FractionalMaxPool2d</code><span class="sig-paren">(</span><em class="sig-param">kernel_size</em>, <em class="sig-param">output_size=None</em>, <em class="sig-param">output_ratio=None</em>, <em class="sig-param">return_indices=False</em>, <em class="sig-param">_random_samples=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/pooling.html#FractionalMaxPool2d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.FractionalMaxPool2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a 2D fractional max pooling over an input signal composed of several input planes.</p>
<p>Fractional MaxPooling is described in detail in the paper <a class="reference external" href="http://arxiv.org/abs/1412.6071">Fractional MaxPooling</a> by Ben Graham</p>
<p>The max-pooling operation is applied in <img class="math" src="_images/math/e1f7181c9a3caad8b0e0a53e776a823aed86e0d8.svg" alt="kH \times kW"/> regions by a stochastic
step size determined by the target output size.
The number of output features is equal to the number of input planes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> – the size of the window to take a max over.
Can be a single number k (for a square kernel of k x k) or a tuple <cite>(kh, kw)</cite></p></li>
<li><p><strong>output_size</strong> – the target output size of the image of the form <cite>oH x oW</cite>.
Can be a tuple <cite>(oH, oW)</cite> or a single number oH for a square image <cite>oH x oH</cite></p></li>
<li><p><strong>output_ratio</strong> – If one wants to have an output size as a ratio of the input size, this option can be given.
This has to be a number or tuple in the range (0, 1)</p></li>
<li><p><strong>return_indices</strong> – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, will return the indices along with the outputs.
Useful to pass to <code class="xref py py-meth docutils literal notranslate"><span class="pre">nn.MaxUnpool2d()</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># pool of square window of size=3, and target output size 13x12</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">FractionalMaxPool2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="p">(</span><span class="mi">13</span><span class="p">,</span> <span class="mi">12</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># pool of square window and target output size being half of input image size</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">FractionalMaxPool2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">output_ratio</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="lppool1d">
<h3><span class="hidden-section">LPPool1d</span><a class="headerlink" href="#lppool1d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.LPPool1d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">LPPool1d</code><span class="sig-paren">(</span><em class="sig-param">norm_type</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">stride=None</em>, <em class="sig-param">ceil_mode=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/pooling.html#LPPool1d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.LPPool1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a 1D power-average pooling over an input signal composed of several input
planes.</p>
<p>On each window, the function computed is:</p>
<div class="math">
<p><img src="_images/math/a24bb2b68ab3b673026a32a603dcae991d3c87d5.svg" alt="f(X) = \sqrt[p]{\sum_{x \in X} x^{p}}"/></p>
</div><ul class="simple">
<li><p>At p = <img class="math" src="_images/math/bc77ef1d57e976aaf1df2652d6a847961be9fdfc.svg" alt="\infty"/>, one gets Max Pooling</p></li>
<li><p>At p = 1, one gets Sum Pooling (which is proportional to Average Pooling)</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the sum to the power of <cite>p</cite> is zero, the gradient of this function is
not defined. This implementation will set the gradient to zero in this case.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> – a single int, the size of the window</p></li>
<li><p><strong>stride</strong> – a single int, the stride of the window. Default value is <code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code></p></li>
<li><p><strong>ceil_mode</strong> – when True, will use <cite>ceil</cite> instead of <cite>floor</cite> to compute the output shape</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><p>Input: <img class="math" src="_images/math/e76c4ba68d941ce8b248b7dddbd4d71890b1df9b.svg" alt="(N, C, L_{in})"/></p></li>
<li><p>Output: <img class="math" src="_images/math/76c56af52c19043f5561254f7555a535f3012cd2.svg" alt="(N, C, L_{out})"/>, where</p>
<div class="math">
<p><img src="_images/math/a76bcd3819b192249d6514731545d971f03efcc5.svg" alt="L_{out} = \left\lfloor\frac{L_{in} +
2 \times \text{padding} - \text{kernel\_size}}{\text{stride}} + 1\right\rfloor"/></p>
</div></li>
</ul>
</dd>
<dt>Examples::</dt><dd><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># power-2 pool of window of length 3, with stride 2.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LPPool1d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="lppool2d">
<h3><span class="hidden-section">LPPool2d</span><a class="headerlink" href="#lppool2d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.LPPool2d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">LPPool2d</code><span class="sig-paren">(</span><em class="sig-param">norm_type</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">stride=None</em>, <em class="sig-param">ceil_mode=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/pooling.html#LPPool2d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.LPPool2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a 2D power-average pooling over an input signal composed of several input
planes.</p>
<p>On each window, the function computed is:</p>
<div class="math">
<p><img src="_images/math/a24bb2b68ab3b673026a32a603dcae991d3c87d5.svg" alt="f(X) = \sqrt[p]{\sum_{x \in X} x^{p}}"/></p>
</div><ul class="simple">
<li><p>At p = <img class="math" src="_images/math/bc77ef1d57e976aaf1df2652d6a847961be9fdfc.svg" alt="\infty"/>, one gets Max Pooling</p></li>
<li><p>At p = 1, one gets Sum Pooling (which is proportional to average pooling)</p></li>
</ul>
<p>The parameters <code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">stride</span></code> can either be:</p>
<blockquote>
<div><ul class="simple">
<li><p>a single <code class="docutils literal notranslate"><span class="pre">int</span></code> – in which case the same value is used for the height and width dimension</p></li>
<li><p>a <code class="docutils literal notranslate"><span class="pre">tuple</span></code> of two ints – in which case, the first <cite>int</cite> is used for the height dimension,
and the second <cite>int</cite> for the width dimension</p></li>
</ul>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the sum to the power of <cite>p</cite> is zero, the gradient of this function is
not defined. This implementation will set the gradient to zero in this case.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>kernel_size</strong> – the size of the window</p></li>
<li><p><strong>stride</strong> – the stride of the window. Default value is <code class="xref py py-attr docutils literal notranslate"><span class="pre">kernel_size</span></code></p></li>
<li><p><strong>ceil_mode</strong> – when True, will use <cite>ceil</cite> instead of <cite>floor</cite> to compute the output shape</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><p>Input: <img class="math" src="_images/math/b7920897893b3a5399125387ef94f5084ff3d283.svg" alt="(N, C, H_{in}, W_{in})"/></p></li>
<li><p>Output: <img class="math" src="_images/math/4026633441f65aa86208d4b12337149db951eab6.svg" alt="(N, C, H_{out}, W_{out})"/>, where</p>
<div class="math">
<p><img src="_images/math/ab3af753c68f385d8be617eaa12b3fd8a769c467.svg" alt="H_{out} = \left\lfloor\frac{H_{in}  + 2 \times \text{padding}[0] - \text{dilation}[0] \times
      (\text{kernel\_size}[0] - 1) - 1}{\text{stride}[0]} + 1\right\rfloor"/></p>
</div><div class="math">
<p><img src="_images/math/25ce54fda9629778ef16bf48e8d20516fa9cb1d1.svg" alt="W_{out} = \left\lfloor\frac{W_{in}  + 2 \times \text{padding}[1] - \text{dilation}[1] \times
      (\text{kernel\_size}[1] - 1) - 1}{\text{stride}[1]} + 1\right\rfloor"/></p>
</div></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># power-2 pool of square window of size=3, stride=2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LPPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># pool of non-square window of power 1.2</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LPPool2d</span><span class="p">(</span><span class="mf">1.2</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="adaptivemaxpool1d">
<h3><span class="hidden-section">AdaptiveMaxPool1d</span><a class="headerlink" href="#adaptivemaxpool1d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.AdaptiveMaxPool1d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">AdaptiveMaxPool1d</code><span class="sig-paren">(</span><em class="sig-param">output_size</em>, <em class="sig-param">return_indices=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/pooling.html#AdaptiveMaxPool1d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.AdaptiveMaxPool1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a 1D adaptive max pooling over an input signal composed of several input planes.</p>
<p>The output size is H, for any input size.
The number of output features is equal to the number of input planes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>output_size</strong> – the target output size H</p></li>
<li><p><strong>return_indices</strong> – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, will return the indices along with the outputs.
Useful to pass to nn.MaxUnpool1d. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># target output size of 5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveMaxPool1d</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="adaptivemaxpool2d">
<h3><span class="hidden-section">AdaptiveMaxPool2d</span><a class="headerlink" href="#adaptivemaxpool2d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.AdaptiveMaxPool2d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">AdaptiveMaxPool2d</code><span class="sig-paren">(</span><em class="sig-param">output_size</em>, <em class="sig-param">return_indices=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/pooling.html#AdaptiveMaxPool2d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.AdaptiveMaxPool2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a 2D adaptive max pooling over an input signal composed of several input planes.</p>
<p>The output is of size H x W, for any input size.
The number of output features is equal to the number of input planes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>output_size</strong> – the target output size of the image of the form H x W.
Can be a tuple (H, W) or a single H for a square image H x H.
H and W can be either a <code class="docutils literal notranslate"><span class="pre">int</span></code>, or <code class="docutils literal notranslate"><span class="pre">None</span></code> which means the size will
be the same as that of the input.</p></li>
<li><p><strong>return_indices</strong> – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, will return the indices along with the outputs.
Useful to pass to nn.MaxUnpool2d. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># target output size of 5x7</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveMaxPool2d</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># target output size of 7x7 (square)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveMaxPool2d</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># target output size of 10x7</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveMaxPool2d</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="adaptivemaxpool3d">
<h3><span class="hidden-section">AdaptiveMaxPool3d</span><a class="headerlink" href="#adaptivemaxpool3d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.AdaptiveMaxPool3d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">AdaptiveMaxPool3d</code><span class="sig-paren">(</span><em class="sig-param">output_size</em>, <em class="sig-param">return_indices=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/pooling.html#AdaptiveMaxPool3d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.AdaptiveMaxPool3d" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a 3D adaptive max pooling over an input signal composed of several input planes.</p>
<p>The output is of size D x H x W, for any input size.
The number of output features is equal to the number of input planes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>output_size</strong> – the target output size of the image of the form D x H x W.
Can be a tuple (D, H, W) or a single D for a cube D x D x D.
D, H and W can be either a <code class="docutils literal notranslate"><span class="pre">int</span></code>, or <code class="docutils literal notranslate"><span class="pre">None</span></code> which means the size will
be the same as that of the input.</p></li>
<li><p><strong>return_indices</strong> – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, will return the indices along with the outputs.
Useful to pass to nn.MaxUnpool3d. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># target output size of 5x7x9</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveMaxPool3d</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">9</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># target output size of 7x7x7 (cube)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveMaxPool3d</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># target output size of 7x9x8</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveMaxPool3d</span><span class="p">((</span><span class="mi">7</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="adaptiveavgpool1d">
<h3><span class="hidden-section">AdaptiveAvgPool1d</span><a class="headerlink" href="#adaptiveavgpool1d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.AdaptiveAvgPool1d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">AdaptiveAvgPool1d</code><span class="sig-paren">(</span><em class="sig-param">output_size</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/pooling.html#AdaptiveAvgPool1d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.AdaptiveAvgPool1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a 1D adaptive average pooling over an input signal composed of several input planes.</p>
<p>The output size is H, for any input size.
The number of output features is equal to the number of input planes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>output_size</strong> – the target output size H</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># target output size of 5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool1d</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="adaptiveavgpool2d">
<h3><span class="hidden-section">AdaptiveAvgPool2d</span><a class="headerlink" href="#adaptiveavgpool2d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.AdaptiveAvgPool2d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">AdaptiveAvgPool2d</code><span class="sig-paren">(</span><em class="sig-param">output_size</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/pooling.html#AdaptiveAvgPool2d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.AdaptiveAvgPool2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a 2D adaptive average pooling over an input signal composed of several input planes.</p>
<p>The output is of size H x W, for any input size.
The number of output features is equal to the number of input planes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>output_size</strong> – the target output size of the image of the form H x W.
Can be a tuple (H, W) or a single H for a square image H x H.
H and W can be either a <code class="docutils literal notranslate"><span class="pre">int</span></code>, or <code class="docutils literal notranslate"><span class="pre">None</span></code> which means the size will
be the same as that of the input.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># target output size of 5x7</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># target output size of 7x7 (square)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># target output size of 10x7</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveMaxPool2d</span><span class="p">((</span><span class="kc">None</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="adaptiveavgpool3d">
<h3><span class="hidden-section">AdaptiveAvgPool3d</span><a class="headerlink" href="#adaptiveavgpool3d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.AdaptiveAvgPool3d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">AdaptiveAvgPool3d</code><span class="sig-paren">(</span><em class="sig-param">output_size</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/pooling.html#AdaptiveAvgPool3d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.AdaptiveAvgPool3d" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a 3D adaptive average pooling over an input signal composed of several input planes.</p>
<p>The output is of size D x H x W, for any input size.
The number of output features is equal to the number of input planes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>output_size</strong> – the target output size of the form D x H x W.
Can be a tuple (D, H, W) or a single number D for a cube D x D x D.
D, H and W can be either a <code class="docutils literal notranslate"><span class="pre">int</span></code>, or <code class="docutils literal notranslate"><span class="pre">None</span></code> which means the size will
be the same as that of the input.</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># target output size of 5x7x9</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool3d</span><span class="p">((</span><span class="mi">5</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">9</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># target output size of 7x7x7 (cube)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool3d</span><span class="p">(</span><span class="mi">7</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># target output size of 7x9x8</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveMaxPool3d</span><span class="p">((</span><span class="mi">7</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
</div>
<div class="section" id="padding-layers">
<h2>Padding layers<a class="headerlink" href="#padding-layers" title="Permalink to this headline">¶</a></h2>
<div class="section" id="reflectionpad1d">
<h3><span class="hidden-section">ReflectionPad1d</span><a class="headerlink" href="#reflectionpad1d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.ReflectionPad1d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">ReflectionPad1d</code><span class="sig-paren">(</span><em class="sig-param">padding</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/padding.html#ReflectionPad1d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ReflectionPad1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Pads the input tensor using the reflection of the input boundary.</p>
<p>For <cite>N</cite>-dimensional padding, use <a class="reference internal" href="nn.functional.html#torch.nn.functional.pad" title="torch.nn.functional.pad"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.nn.functional.pad()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a>) – the size of the padding. If is <cite>int</cite>, uses the same
padding in all boundaries. If a 2-<cite>tuple</cite>, uses
(<img class="math" src="_images/math/bca257e149f9e8b1df03c0a6a2c37a7f5aa5e7f4.svg" alt="\text{padding\_left}"/>, <img class="math" src="_images/math/16e1d69af21eb518812263d45072b41656e0f432.svg" alt="\text{padding\_right}"/>)</p>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><p>Input: <img class="math" src="_images/math/09563747a48925dba1e37d3eb2a1b97f9bdfb2ed.svg" alt="(N, C, W_{in})"/></p></li>
<li><p>Output: <img class="math" src="_images/math/f68d1c24a459d81e851e068bc3107f13193c4362.svg" alt="(N, C, W_{out})"/> where</p>
<p><img class="math" src="_images/math/64a94ade42499a566249eeadb10594ef24a85ed1.svg" alt="W_{out} = W_{in} + \text{padding\_left} + \text{padding\_right}"/></p>
</li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReflectionPad1d</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span>
<span class="go">tensor([[[0., 1., 2., 3.],</span>
<span class="go">         [4., 5., 6., 7.]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[2., 1., 0., 1., 2., 3., 2., 1.],</span>
<span class="go">         [6., 5., 4., 5., 6., 7., 6., 5.]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># using different paddings for different sides</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReflectionPad1d</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[3., 2., 1., 0., 1., 2., 3., 2.],</span>
<span class="go">         [7., 6., 5., 4., 5., 6., 7., 6.]]])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="reflectionpad2d">
<h3><span class="hidden-section">ReflectionPad2d</span><a class="headerlink" href="#reflectionpad2d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.ReflectionPad2d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">ReflectionPad2d</code><span class="sig-paren">(</span><em class="sig-param">padding</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/padding.html#ReflectionPad2d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ReflectionPad2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Pads the input tensor using the reflection of the input boundary.</p>
<p>For <cite>N</cite>-dimensional padding, use <a class="reference internal" href="nn.functional.html#torch.nn.functional.pad" title="torch.nn.functional.pad"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.nn.functional.pad()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a>) – the size of the padding. If is <cite>int</cite>, uses the same
padding in all boundaries. If a 4-<cite>tuple</cite>, uses (<img class="math" src="_images/math/bca257e149f9e8b1df03c0a6a2c37a7f5aa5e7f4.svg" alt="\text{padding\_left}"/>,
<img class="math" src="_images/math/16e1d69af21eb518812263d45072b41656e0f432.svg" alt="\text{padding\_right}"/>, <img class="math" src="_images/math/09ee2ecdb74488fd4f86d1752bdc8ea8cd1f6632.svg" alt="\text{padding\_top}"/>, <img class="math" src="_images/math/37b933e0b1543fdb2c9d8662edb731b865c8d8cb.svg" alt="\text{padding\_bottom}"/>)</p>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><p>Input: <img class="math" src="_images/math/b7920897893b3a5399125387ef94f5084ff3d283.svg" alt="(N, C, H_{in}, W_{in})"/></p></li>
<li><p>Output: <img class="math" src="_images/math/4026633441f65aa86208d4b12337149db951eab6.svg" alt="(N, C, H_{out}, W_{out})"/> where</p>
<p><img class="math" src="_images/math/1ad985920776b80b284baa336ef6974ff0683186.svg" alt="H_{out} = H_{in} + \text{padding\_top} + \text{padding\_bottom}"/></p>
<p><img class="math" src="_images/math/64a94ade42499a566249eeadb10594ef24a85ed1.svg" alt="W_{out} = W_{in} + \text{padding\_left} + \text{padding\_right}"/></p>
</li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReflectionPad2d</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span>
<span class="go">tensor([[[[0., 1., 2.],</span>
<span class="go">          [3., 4., 5.],</span>
<span class="go">          [6., 7., 8.]]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[[8., 7., 6., 7., 8., 7., 6.],</span>
<span class="go">          [5., 4., 3., 4., 5., 4., 3.],</span>
<span class="go">          [2., 1., 0., 1., 2., 1., 0.],</span>
<span class="go">          [5., 4., 3., 4., 5., 4., 3.],</span>
<span class="go">          [8., 7., 6., 7., 8., 7., 6.],</span>
<span class="go">          [5., 4., 3., 4., 5., 4., 3.],</span>
<span class="go">          [2., 1., 0., 1., 2., 1., 0.]]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># using different paddings for different sides</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReflectionPad2d</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[[7., 6., 7., 8., 7.],</span>
<span class="go">          [4., 3., 4., 5., 4.],</span>
<span class="go">          [1., 0., 1., 2., 1.],</span>
<span class="go">          [4., 3., 4., 5., 4.],</span>
<span class="go">          [7., 6., 7., 8., 7.]]]])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="replicationpad1d">
<h3><span class="hidden-section">ReplicationPad1d</span><a class="headerlink" href="#replicationpad1d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.ReplicationPad1d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">ReplicationPad1d</code><span class="sig-paren">(</span><em class="sig-param">padding</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/padding.html#ReplicationPad1d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ReplicationPad1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Pads the input tensor using replication of the input boundary.</p>
<p>For <cite>N</cite>-dimensional padding, use <a class="reference internal" href="nn.functional.html#torch.nn.functional.pad" title="torch.nn.functional.pad"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.nn.functional.pad()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a>) – the size of the padding. If is <cite>int</cite>, uses the same
padding in all boundaries. If a 2-<cite>tuple</cite>, uses
(<img class="math" src="_images/math/bca257e149f9e8b1df03c0a6a2c37a7f5aa5e7f4.svg" alt="\text{padding\_left}"/>, <img class="math" src="_images/math/16e1d69af21eb518812263d45072b41656e0f432.svg" alt="\text{padding\_right}"/>)</p>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><p>Input: <img class="math" src="_images/math/09563747a48925dba1e37d3eb2a1b97f9bdfb2ed.svg" alt="(N, C, W_{in})"/></p></li>
<li><p>Output: <img class="math" src="_images/math/f68d1c24a459d81e851e068bc3107f13193c4362.svg" alt="(N, C, W_{out})"/> where</p>
<p><img class="math" src="_images/math/64a94ade42499a566249eeadb10594ef24a85ed1.svg" alt="W_{out} = W_{in} + \text{padding\_left} + \text{padding\_right}"/></p>
</li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReplicationPad1d</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span>
<span class="go">tensor([[[0., 1., 2., 3.],</span>
<span class="go">         [4., 5., 6., 7.]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[0., 0., 0., 1., 2., 3., 3., 3.],</span>
<span class="go">         [4., 4., 4., 5., 6., 7., 7., 7.]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># using different paddings for different sides</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReplicationPad1d</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[0., 0., 0., 0., 1., 2., 3., 3.],</span>
<span class="go">         [4., 4., 4., 4., 5., 6., 7., 7.]]])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="replicationpad2d">
<h3><span class="hidden-section">ReplicationPad2d</span><a class="headerlink" href="#replicationpad2d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.ReplicationPad2d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">ReplicationPad2d</code><span class="sig-paren">(</span><em class="sig-param">padding</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/padding.html#ReplicationPad2d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ReplicationPad2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Pads the input tensor using replication of the input boundary.</p>
<p>For <cite>N</cite>-dimensional padding, use <a class="reference internal" href="nn.functional.html#torch.nn.functional.pad" title="torch.nn.functional.pad"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.nn.functional.pad()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a>) – the size of the padding. If is <cite>int</cite>, uses the same
padding in all boundaries. If a 4-<cite>tuple</cite>, uses (<img class="math" src="_images/math/bca257e149f9e8b1df03c0a6a2c37a7f5aa5e7f4.svg" alt="\text{padding\_left}"/>,
<img class="math" src="_images/math/16e1d69af21eb518812263d45072b41656e0f432.svg" alt="\text{padding\_right}"/>, <img class="math" src="_images/math/09ee2ecdb74488fd4f86d1752bdc8ea8cd1f6632.svg" alt="\text{padding\_top}"/>, <img class="math" src="_images/math/37b933e0b1543fdb2c9d8662edb731b865c8d8cb.svg" alt="\text{padding\_bottom}"/>)</p>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><p>Input: <img class="math" src="_images/math/b7920897893b3a5399125387ef94f5084ff3d283.svg" alt="(N, C, H_{in}, W_{in})"/></p></li>
<li><p>Output: <img class="math" src="_images/math/4026633441f65aa86208d4b12337149db951eab6.svg" alt="(N, C, H_{out}, W_{out})"/> where</p>
<p><img class="math" src="_images/math/1ad985920776b80b284baa336ef6974ff0683186.svg" alt="H_{out} = H_{in} + \text{padding\_top} + \text{padding\_bottom}"/></p>
<p><img class="math" src="_images/math/64a94ade42499a566249eeadb10594ef24a85ed1.svg" alt="W_{out} = W_{in} + \text{padding\_left} + \text{padding\_right}"/></p>
</li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReplicationPad2d</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span>
<span class="go">tensor([[[[0., 1., 2.],</span>
<span class="go">          [3., 4., 5.],</span>
<span class="go">          [6., 7., 8.]]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[[0., 0., 0., 1., 2., 2., 2.],</span>
<span class="go">          [0., 0., 0., 1., 2., 2., 2.],</span>
<span class="go">          [0., 0., 0., 1., 2., 2., 2.],</span>
<span class="go">          [3., 3., 3., 4., 5., 5., 5.],</span>
<span class="go">          [6., 6., 6., 7., 8., 8., 8.],</span>
<span class="go">          [6., 6., 6., 7., 8., 8., 8.],</span>
<span class="go">          [6., 6., 6., 7., 8., 8., 8.]]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># using different paddings for different sides</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReplicationPad2d</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[[0., 0., 1., 2., 2.],</span>
<span class="go">          [0., 0., 1., 2., 2.],</span>
<span class="go">          [0., 0., 1., 2., 2.],</span>
<span class="go">          [3., 3., 4., 5., 5.],</span>
<span class="go">          [6., 6., 7., 8., 8.]]]])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="replicationpad3d">
<h3><span class="hidden-section">ReplicationPad3d</span><a class="headerlink" href="#replicationpad3d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.ReplicationPad3d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">ReplicationPad3d</code><span class="sig-paren">(</span><em class="sig-param">padding</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/padding.html#ReplicationPad3d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ReplicationPad3d" title="Permalink to this definition">¶</a></dt>
<dd><p>Pads the input tensor using replication of the input boundary.</p>
<p>For <cite>N</cite>-dimensional padding, use <a class="reference internal" href="nn.functional.html#torch.nn.functional.pad" title="torch.nn.functional.pad"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.nn.functional.pad()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a>) – the size of the padding. If is <cite>int</cite>, uses the same
padding in all boundaries. If a 6-<cite>tuple</cite>, uses
(<img class="math" src="_images/math/bca257e149f9e8b1df03c0a6a2c37a7f5aa5e7f4.svg" alt="\text{padding\_left}"/>, <img class="math" src="_images/math/16e1d69af21eb518812263d45072b41656e0f432.svg" alt="\text{padding\_right}"/>,
<img class="math" src="_images/math/09ee2ecdb74488fd4f86d1752bdc8ea8cd1f6632.svg" alt="\text{padding\_top}"/>, <img class="math" src="_images/math/37b933e0b1543fdb2c9d8662edb731b865c8d8cb.svg" alt="\text{padding\_bottom}"/>,
<img class="math" src="_images/math/89d4e059c80b8b97e7b6a220ff5d4af7ccbcc576.svg" alt="\text{padding\_front}"/>, <img class="math" src="_images/math/6b659b5e6d1664f80cd407dbf220f11e340452a0.svg" alt="\text{padding\_back}"/>)</p>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><p>Input: <img class="math" src="_images/math/4b57572f196d556e35bdc4edfa15573c3c68b667.svg" alt="(N, C, D_{in}, H_{in}, W_{in})"/></p></li>
<li><p>Output: <img class="math" src="_images/math/c01ac11b86bf5ae0b82c88e6bec50ac4ab4a8c15.svg" alt="(N, C, D_{out}, H_{out}, W_{out})"/> where</p>
<p><img class="math" src="_images/math/40bab4c27c5a33a6b6956bc0470733cca8366200.svg" alt="D_{out} = D_{in} + \text{padding\_front} + \text{padding\_back}"/></p>
<p><img class="math" src="_images/math/1ad985920776b80b284baa336ef6974ff0683186.svg" alt="H_{out} = H_{in} + \text{padding\_top} + \text{padding\_bottom}"/></p>
<p><img class="math" src="_images/math/64a94ade42499a566249eeadb10594ef24a85ed1.svg" alt="W_{out} = W_{in} + \text{padding\_left} + \text{padding\_right}"/></p>
</li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReplicationPad3d</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">320</span><span class="p">,</span> <span class="mi">480</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># using different paddings for different sides</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReplicationPad3d</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="zeropad2d">
<h3><span class="hidden-section">ZeroPad2d</span><a class="headerlink" href="#zeropad2d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.ZeroPad2d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">ZeroPad2d</code><span class="sig-paren">(</span><em class="sig-param">padding</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/padding.html#ZeroPad2d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ZeroPad2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Pads the input tensor boundaries with zero.</p>
<p>For <cite>N</cite>-dimensional padding, use <a class="reference internal" href="nn.functional.html#torch.nn.functional.pad" title="torch.nn.functional.pad"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.nn.functional.pad()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a>) – the size of the padding. If is <cite>int</cite>, uses the same
padding in all boundaries. If a 4-<cite>tuple</cite>, uses (<img class="math" src="_images/math/bca257e149f9e8b1df03c0a6a2c37a7f5aa5e7f4.svg" alt="\text{padding\_left}"/>,
<img class="math" src="_images/math/16e1d69af21eb518812263d45072b41656e0f432.svg" alt="\text{padding\_right}"/>, <img class="math" src="_images/math/09ee2ecdb74488fd4f86d1752bdc8ea8cd1f6632.svg" alt="\text{padding\_top}"/>, <img class="math" src="_images/math/37b933e0b1543fdb2c9d8662edb731b865c8d8cb.svg" alt="\text{padding\_bottom}"/>)</p>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><p>Input: <img class="math" src="_images/math/b7920897893b3a5399125387ef94f5084ff3d283.svg" alt="(N, C, H_{in}, W_{in})"/></p></li>
<li><p>Output: <img class="math" src="_images/math/4026633441f65aa86208d4b12337149db951eab6.svg" alt="(N, C, H_{out}, W_{out})"/> where</p>
<p><img class="math" src="_images/math/1ad985920776b80b284baa336ef6974ff0683186.svg" alt="H_{out} = H_{in} + \text{padding\_top} + \text{padding\_bottom}"/></p>
<p><img class="math" src="_images/math/64a94ade42499a566249eeadb10594ef24a85ed1.svg" alt="W_{out} = W_{in} + \text{padding\_left} + \text{padding\_right}"/></p>
</li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ZeroPad2d</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span>
<span class="go">tensor([[[[-0.1678, -0.4418,  1.9466],</span>
<span class="go">          [ 0.9604, -0.4219, -0.5241],</span>
<span class="go">          [-0.9162, -0.5436, -0.6446]]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],</span>
<span class="go">          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],</span>
<span class="go">          [ 0.0000,  0.0000, -0.1678, -0.4418,  1.9466,  0.0000,  0.0000],</span>
<span class="go">          [ 0.0000,  0.0000,  0.9604, -0.4219, -0.5241,  0.0000,  0.0000],</span>
<span class="go">          [ 0.0000,  0.0000, -0.9162, -0.5436, -0.6446,  0.0000,  0.0000],</span>
<span class="go">          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],</span>
<span class="go">          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># using different paddings for different sides</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ZeroPad2d</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],</span>
<span class="go">          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],</span>
<span class="go">          [ 0.0000, -0.1678, -0.4418,  1.9466,  0.0000],</span>
<span class="go">          [ 0.0000,  0.9604, -0.4219, -0.5241,  0.0000],</span>
<span class="go">          [ 0.0000, -0.9162, -0.5436, -0.6446,  0.0000]]]])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="constantpad1d">
<h3><span class="hidden-section">ConstantPad1d</span><a class="headerlink" href="#constantpad1d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.ConstantPad1d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">ConstantPad1d</code><span class="sig-paren">(</span><em class="sig-param">padding</em>, <em class="sig-param">value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/padding.html#ConstantPad1d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ConstantPad1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Pads the input tensor boundaries with a constant value.</p>
<p>For <cite>N</cite>-dimensional padding, use <a class="reference internal" href="nn.functional.html#torch.nn.functional.pad" title="torch.nn.functional.pad"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.nn.functional.pad()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a>) – the size of the padding. If is <cite>int</cite>, uses the same
padding in both boundaries. If a 2-<cite>tuple</cite>, uses
(<img class="math" src="_images/math/bca257e149f9e8b1df03c0a6a2c37a7f5aa5e7f4.svg" alt="\text{padding\_left}"/>, <img class="math" src="_images/math/16e1d69af21eb518812263d45072b41656e0f432.svg" alt="\text{padding\_right}"/>)</p>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><p>Input: <img class="math" src="_images/math/09563747a48925dba1e37d3eb2a1b97f9bdfb2ed.svg" alt="(N, C, W_{in})"/></p></li>
<li><p>Output: <img class="math" src="_images/math/f68d1c24a459d81e851e068bc3107f13193c4362.svg" alt="(N, C, W_{out})"/> where</p>
<p><img class="math" src="_images/math/64a94ade42499a566249eeadb10594ef24a85ed1.svg" alt="W_{out} = W_{in} + \text{padding\_left} + \text{padding\_right}"/></p>
</li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConstantPad1d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span>
<span class="go">tensor([[[-1.0491, -0.7152, -0.0749,  0.8530],</span>
<span class="go">         [-1.3287,  1.8966,  0.1466, -0.2771]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[ 3.5000,  3.5000, -1.0491, -0.7152, -0.0749,  0.8530,  3.5000,</span>
<span class="go">           3.5000],</span>
<span class="go">         [ 3.5000,  3.5000, -1.3287,  1.8966,  0.1466, -0.2771,  3.5000,</span>
<span class="go">           3.5000]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConstantPad1d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span>
<span class="go">tensor([[[ 1.6616,  1.4523, -1.1255],</span>
<span class="go">         [-3.6372,  0.1182, -1.8652]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[ 3.5000,  3.5000,  1.6616,  1.4523, -1.1255,  3.5000,  3.5000],</span>
<span class="go">         [ 3.5000,  3.5000, -3.6372,  0.1182, -1.8652,  3.5000,  3.5000]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># using different paddings for different sides</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConstantPad1d</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="mf">3.5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[ 3.5000,  3.5000,  3.5000,  1.6616,  1.4523, -1.1255,  3.5000],</span>
<span class="go">         [ 3.5000,  3.5000,  3.5000, -3.6372,  0.1182, -1.8652,  3.5000]]])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="constantpad2d">
<h3><span class="hidden-section">ConstantPad2d</span><a class="headerlink" href="#constantpad2d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.ConstantPad2d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">ConstantPad2d</code><span class="sig-paren">(</span><em class="sig-param">padding</em>, <em class="sig-param">value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/padding.html#ConstantPad2d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ConstantPad2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Pads the input tensor boundaries with a constant value.</p>
<p>For <cite>N</cite>-dimensional padding, use <a class="reference internal" href="nn.functional.html#torch.nn.functional.pad" title="torch.nn.functional.pad"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.nn.functional.pad()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a>) – the size of the padding. If is <cite>int</cite>, uses the same
padding in all boundaries. If a 4-<cite>tuple</cite>, uses (<img class="math" src="_images/math/bca257e149f9e8b1df03c0a6a2c37a7f5aa5e7f4.svg" alt="\text{padding\_left}"/>,
<img class="math" src="_images/math/16e1d69af21eb518812263d45072b41656e0f432.svg" alt="\text{padding\_right}"/>, <img class="math" src="_images/math/09ee2ecdb74488fd4f86d1752bdc8ea8cd1f6632.svg" alt="\text{padding\_top}"/>, <img class="math" src="_images/math/37b933e0b1543fdb2c9d8662edb731b865c8d8cb.svg" alt="\text{padding\_bottom}"/>)</p>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><p>Input: <img class="math" src="_images/math/b7920897893b3a5399125387ef94f5084ff3d283.svg" alt="(N, C, H_{in}, W_{in})"/></p></li>
<li><p>Output: <img class="math" src="_images/math/4026633441f65aa86208d4b12337149db951eab6.svg" alt="(N, C, H_{out}, W_{out})"/> where</p>
<p><img class="math" src="_images/math/1ad985920776b80b284baa336ef6974ff0683186.svg" alt="H_{out} = H_{in} + \text{padding\_top} + \text{padding\_bottom}"/></p>
<p><img class="math" src="_images/math/64a94ade42499a566249eeadb10594ef24a85ed1.svg" alt="W_{out} = W_{in} + \text{padding\_left} + \text{padding\_right}"/></p>
</li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConstantPad2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span>
<span class="go">tensor([[[ 1.6585,  0.4320],</span>
<span class="go">         [-0.8701, -0.4649]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000,  3.5000],</span>
<span class="go">         [ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000,  3.5000],</span>
<span class="go">         [ 3.5000,  3.5000,  1.6585,  0.4320,  3.5000,  3.5000],</span>
<span class="go">         [ 3.5000,  3.5000, -0.8701, -0.4649,  3.5000,  3.5000],</span>
<span class="go">         [ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000,  3.5000],</span>
<span class="go">         [ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000,  3.5000]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># using different paddings for different sides</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConstantPad2d</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="mf">3.5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000],</span>
<span class="go">         [ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000],</span>
<span class="go">         [ 3.5000,  3.5000,  3.5000,  1.6585,  0.4320],</span>
<span class="go">         [ 3.5000,  3.5000,  3.5000, -0.8701, -0.4649],</span>
<span class="go">         [ 3.5000,  3.5000,  3.5000,  3.5000,  3.5000]]])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="constantpad3d">
<h3><span class="hidden-section">ConstantPad3d</span><a class="headerlink" href="#constantpad3d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.ConstantPad3d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">ConstantPad3d</code><span class="sig-paren">(</span><em class="sig-param">padding</em>, <em class="sig-param">value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/padding.html#ConstantPad3d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ConstantPad3d" title="Permalink to this definition">¶</a></dt>
<dd><p>Pads the input tensor boundaries with a constant value.</p>
<p>For <cite>N</cite>-dimensional padding, use <a class="reference internal" href="nn.functional.html#torch.nn.functional.pad" title="torch.nn.functional.pad"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.nn.functional.pad()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a>) – the size of the padding. If is <cite>int</cite>, uses the same
padding in all boundaries. If a 6-<cite>tuple</cite>, uses
(<img class="math" src="_images/math/bca257e149f9e8b1df03c0a6a2c37a7f5aa5e7f4.svg" alt="\text{padding\_left}"/>, <img class="math" src="_images/math/16e1d69af21eb518812263d45072b41656e0f432.svg" alt="\text{padding\_right}"/>,
<img class="math" src="_images/math/09ee2ecdb74488fd4f86d1752bdc8ea8cd1f6632.svg" alt="\text{padding\_top}"/>, <img class="math" src="_images/math/37b933e0b1543fdb2c9d8662edb731b865c8d8cb.svg" alt="\text{padding\_bottom}"/>,
<img class="math" src="_images/math/89d4e059c80b8b97e7b6a220ff5d4af7ccbcc576.svg" alt="\text{padding\_front}"/>, <img class="math" src="_images/math/6b659b5e6d1664f80cd407dbf220f11e340452a0.svg" alt="\text{padding\_back}"/>)</p>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul>
<li><p>Input: <img class="math" src="_images/math/4b57572f196d556e35bdc4edfa15573c3c68b667.svg" alt="(N, C, D_{in}, H_{in}, W_{in})"/></p></li>
<li><p>Output: <img class="math" src="_images/math/c01ac11b86bf5ae0b82c88e6bec50ac4ab4a8c15.svg" alt="(N, C, D_{out}, H_{out}, W_{out})"/> where</p>
<p><img class="math" src="_images/math/40bab4c27c5a33a6b6956bc0470733cca8366200.svg" alt="D_{out} = D_{in} + \text{padding\_front} + \text{padding\_back}"/></p>
<p><img class="math" src="_images/math/1ad985920776b80b284baa336ef6974ff0683186.svg" alt="H_{out} = H_{in} + \text{padding\_top} + \text{padding\_bottom}"/></p>
<p><img class="math" src="_images/math/64a94ade42499a566249eeadb10594ef24a85ed1.svg" alt="W_{out} = W_{in} + \text{padding\_left} + \text{padding\_right}"/></p>
</li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConstantPad3d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># using different paddings for different sides</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConstantPad3d</span><span class="p">((</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="mf">3.5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
</div>
<div class="section" id="non-linear-activations-weighted-sum-nonlinearity">
<h2>Non-linear activations (weighted sum, nonlinearity)<a class="headerlink" href="#non-linear-activations-weighted-sum-nonlinearity" title="Permalink to this headline">¶</a></h2>
<div class="section" id="elu">
<h3><span class="hidden-section">ELU</span><a class="headerlink" href="#elu" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.ELU">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">ELU</code><span class="sig-paren">(</span><em class="sig-param">alpha=1.0</em>, <em class="sig-param">inplace=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/activation.html#ELU"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ELU" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the element-wise function:</p>
<div class="math">
<p><img src="_images/math/0c00de479ea779128df5a729017d75c821a595f4.svg" alt="\text{ELU}(x) = \max(0,x) + \min(0, \alpha * (\exp(x) - 1))"/></p>
</div><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>alpha</strong> – the <img class="math" src="_images/math/2f5aa019312e1bbc969deab8dca8b00f76025404.svg" alt="\alpha"/> value for the ELU formulation. Default: 1.0</p></li>
<li><p><strong>inplace</strong> – can optionally do the operation in-place. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/> where <cite>*</cite> means, any number of additional
dimensions</p></li>
<li><p>Output: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/>, same shape as the input</p></li>
</ul>
</dd>
</dl>
<img alt="_images/ELU.png" src="_images/ELU.png" />
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="hardshrink">
<h3><span class="hidden-section">Hardshrink</span><a class="headerlink" href="#hardshrink" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.Hardshrink">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">Hardshrink</code><span class="sig-paren">(</span><em class="sig-param">lambd=0.5</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/activation.html#Hardshrink"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Hardshrink" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the hard shrinkage function element-wise:</p>
<div class="math">
<p><img src="_images/math/5cd9a3343573aec20b74b9830b86ad0a14f63418.svg" alt="\text{HardShrink}(x) =
\begin{cases}
x, &amp; \text{ if } x &gt; \lambda \\
x, &amp; \text{ if } x &lt; -\lambda \\
0, &amp; \text{ otherwise }
\end{cases}"/></p>
</div><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>lambd</strong> – the <img class="math" src="_images/math/cefc603e5658facb747581f9567192993f21c7ab.svg" alt="\lambda"/> value for the Hardshrink formulation. Default: 0.5</p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/> where <cite>*</cite> means, any number of additional
dimensions</p></li>
<li><p>Output: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/>, same shape as the input</p></li>
</ul>
</dd>
</dl>
<img alt="_images/Hardshrink.png" src="_images/Hardshrink.png" />
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Hardshrink</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="hardtanh">
<h3><span class="hidden-section">Hardtanh</span><a class="headerlink" href="#hardtanh" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.Hardtanh">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">Hardtanh</code><span class="sig-paren">(</span><em class="sig-param">min_val=-1.0</em>, <em class="sig-param">max_val=1.0</em>, <em class="sig-param">inplace=False</em>, <em class="sig-param">min_value=None</em>, <em class="sig-param">max_value=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/activation.html#Hardtanh"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Hardtanh" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the HardTanh function element-wise</p>
<p>HardTanh is defined as:</p>
<div class="math">
<p><img src="_images/math/cd689da989af0035864cbf1049ac7cd640c40fd7.svg" alt="\text{HardTanh}(x) = \begin{cases}
    1 &amp; \text{ if } x &gt; 1 \\
    -1 &amp; \text{ if } x &lt; -1 \\
    x &amp; \text{ otherwise } \\
\end{cases}"/></p>
</div><p>The range of the linear region <img class="math" src="_images/math/92b4b754966e4a581f924d4bfd1b0db7ab47c886.svg" alt="[-1, 1]"/> can be adjusted using
<code class="xref py py-attr docutils literal notranslate"><span class="pre">min_val</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">max_val</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>min_val</strong> – minimum value of the linear region range. Default: -1</p></li>
<li><p><strong>max_val</strong> – maximum value of the linear region range. Default: 1</p></li>
<li><p><strong>inplace</strong> – can optionally do the operation in-place. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<p>Keyword arguments <code class="xref py py-attr docutils literal notranslate"><span class="pre">min_value</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">max_value</span></code>
have been deprecated in favor of <code class="xref py py-attr docutils literal notranslate"><span class="pre">min_val</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">max_val</span></code>.</p>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/> where <cite>*</cite> means, any number of additional
dimensions</p></li>
<li><p>Output: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/>, same shape as the input</p></li>
</ul>
</dd>
</dl>
<img alt="_images/Hardtanh.png" src="_images/Hardtanh.png" />
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Hardtanh</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="leakyrelu">
<h3><span class="hidden-section">LeakyReLU</span><a class="headerlink" href="#leakyrelu" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.LeakyReLU">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">LeakyReLU</code><span class="sig-paren">(</span><em class="sig-param">negative_slope=0.01</em>, <em class="sig-param">inplace=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/activation.html#LeakyReLU"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.LeakyReLU" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the element-wise function:</p>
<div class="math">
<p><img src="_images/math/a2558ba917c9aa801b657e23a8003daa08ae41d2.svg" alt="\text{LeakyReLU}(x) = \max(0, x) + \text{negative\_slope} * \min(0, x)"/></p>
</div><p>or</p>
<div class="math">
<p><img src="_images/math/bcfbd7929e866f1f207fd455fa69eeab36c41220.svg" alt="\text{LeakyRELU}(x) =
\begin{cases}
x, &amp; \text{ if } x \geq 0 \\
\text{negative\_slope} \times x, &amp; \text{ otherwise }
\end{cases}"/></p>
</div><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>negative_slope</strong> – Controls the angle of the negative slope. Default: 1e-2</p></li>
<li><p><strong>inplace</strong> – can optionally do the operation in-place. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/> where <cite>*</cite> means, any number of additional
dimensions</p></li>
<li><p>Output: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/>, same shape as the input</p></li>
</ul>
</dd>
</dl>
<img alt="_images/LeakyReLU.png" src="_images/LeakyReLU.png" />
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="mf">0.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="logsigmoid">
<h3><span class="hidden-section">LogSigmoid</span><a class="headerlink" href="#logsigmoid" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.LogSigmoid">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">LogSigmoid</code><a class="reference internal" href="_modules/torch/nn/modules/activation.html#LogSigmoid"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.LogSigmoid" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the element-wise function:</p>
<div class="math">
<p><img src="_images/math/241d19063a75a646df9f5ba034c0c1636395d87b.svg" alt="\text{LogSigmoid}(x) = \log\left(\frac{ 1 }{ 1 + \exp(-x)}\right)"/></p>
</div><dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/> where <cite>*</cite> means, any number of additional
dimensions</p></li>
<li><p>Output: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/>, same shape as the input</p></li>
</ul>
</dd>
</dl>
<img alt="_images/LogSigmoid.png" src="_images/LogSigmoid.png" />
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LogSigmoid</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="multiheadattention">
<h3><span class="hidden-section">MultiheadAttention</span><a class="headerlink" href="#multiheadattention" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.MultiheadAttention">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">MultiheadAttention</code><span class="sig-paren">(</span><em class="sig-param">embed_dim</em>, <em class="sig-param">num_heads</em>, <em class="sig-param">dropout=0.0</em>, <em class="sig-param">bias=True</em>, <em class="sig-param">add_bias_kv=False</em>, <em class="sig-param">add_zero_attn=False</em>, <em class="sig-param">kdim=None</em>, <em class="sig-param">vdim=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/activation.html#MultiheadAttention"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.MultiheadAttention" title="Permalink to this definition">¶</a></dt>
<dd><p>Allows the model to jointly attend to information
from different representation subspaces.
See reference: Attention Is All You Need</p>
<div class="math">
<p><img src="_images/math/cfae8cb7e3234e089c9e460ecc51fc6bb605a1ca.svg" alt="\text{MultiHead}(Q, K, V) = \text{Concat}(head_1,\dots,head_h)W^O
\text{where} head_i = \text{Attention}(QW_i^Q, KW_i^K, VW_i^V)"/></p>
</div><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>embed_dim</strong> – total dimension of the model.</p></li>
<li><p><strong>num_heads</strong> – parallel attention heads.</p></li>
<li><p><strong>dropout</strong> – a Dropout layer on attn_output_weights. Default: 0.0.</p></li>
<li><p><strong>bias</strong> – add bias as module parameter. Default: True.</p></li>
<li><p><strong>add_bias_kv</strong> – add bias to the key and value sequences at dim=0.</p></li>
<li><p><strong>add_zero_attn</strong> – add a new batch of zeros to the key and
value sequences at dim=1.</p></li>
<li><p><strong>kdim</strong> – total number of features in key. Default: None.</p></li>
<li><p><strong>vdim</strong> – total number of features in key. Default: None.</p></li>
<li><p><strong>Note</strong> – if kdim and vdim are None, they will be set to embed_dim such that</p></li>
<li><p><strong>key, and value have the same number of features.</strong> (<em>query</em><em>,</em>) – </p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">multihead_attn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MultiheadAttention</span><span class="p">(</span><span class="n">embed_dim</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">attn_output</span><span class="p">,</span> <span class="n">attn_output_weights</span> <span class="o">=</span> <span class="n">multihead_attn</span><span class="p">(</span><span class="n">query</span><span class="p">,</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="torch.nn.MultiheadAttention.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">query</em>, <em class="sig-param">key</em>, <em class="sig-param">value</em>, <em class="sig-param">key_padding_mask=None</em>, <em class="sig-param">need_weights=True</em>, <em class="sig-param">attn_mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/activation.html#MultiheadAttention.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.MultiheadAttention.forward" title="Permalink to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>key, value</strong> (<em>query</em><em>,</em>) – map a query and a set of key-value pairs to an output.
See “Attention Is All You Need” for more details.</p></li>
<li><p><strong>key_padding_mask</strong> – if provided, specified padding elements in the key will
be ignored by the attention. This is an binary mask. When the value is True,
the corresponding value on the attention layer will be filled with -inf.</p></li>
<li><p><strong>need_weights</strong> – output attn_output_weights.</p></li>
<li><p><strong>attn_mask</strong> – mask that prevents attention to certain positions. This is an additive mask
(i.e. the values will be added to the attention layer).</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Inputs:</p></li>
<li><p>query: <img class="math" src="_images/math/b60553e5804b7155e4ee1e4eb1e27f2f54d48876.svg" alt="(L, N, E)"/> where L is the target sequence length, N is the batch size, E is
the embedding dimension.</p></li>
<li><p>key: <img class="math" src="_images/math/903cf91d206b99e3970dd2b86697540b33f96d28.svg" alt="(S, N, E)"/>, where S is the source sequence length, N is the batch size, E is
the embedding dimension.</p></li>
<li><p>value: <img class="math" src="_images/math/903cf91d206b99e3970dd2b86697540b33f96d28.svg" alt="(S, N, E)"/> where S is the source sequence length, N is the batch size, E is
the embedding dimension.</p></li>
<li><p>key_padding_mask: <img class="math" src="_images/math/086c186c4e24812b2ff657326cc5cddbe7f879a3.svg" alt="(N, S)"/>, ByteTensor, where N is the batch size, S is the source sequence length.</p></li>
<li><p>attn_mask: <img class="math" src="_images/math/33569b8f05a3a11c35b54758a2f44c52997acae4.svg" alt="(L, S)"/> where L is the target sequence length, S is the source sequence length.</p></li>
<li><p>Outputs:</p></li>
<li><p>attn_output: <img class="math" src="_images/math/b60553e5804b7155e4ee1e4eb1e27f2f54d48876.svg" alt="(L, N, E)"/> where L is the target sequence length, N is the batch size,
E is the embedding dimension.</p></li>
<li><p>attn_output_weights: <img class="math" src="_images/math/67876fa24935f156234c2dec23147478d92906a2.svg" alt="(N, L, S)"/> where N is the batch size,
L is the target sequence length, S is the source sequence length.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="prelu">
<h3><span class="hidden-section">PReLU</span><a class="headerlink" href="#prelu" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.PReLU">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">PReLU</code><span class="sig-paren">(</span><em class="sig-param">num_parameters=1</em>, <em class="sig-param">init=0.25</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/activation.html#PReLU"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.PReLU" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the element-wise function:</p>
<div class="math">
<p><img src="_images/math/3e324a215fbe7c9ae84ca3f0b901b42844fb7c87.svg" alt="\text{PReLU}(x) = \max(0,x) + a * \min(0,x)"/></p>
</div><p>or</p>
<div class="math">
<p><img src="_images/math/bfdd04922c7724e200254d2791762ae4e4849a4d.svg" alt="\text{PReLU}(x) =
\begin{cases}
x, &amp; \text{ if } x \geq 0 \\
ax, &amp; \text{ otherwise }
\end{cases}"/></p>
</div><p>Here <img class="math" src="_images/math/b3e65e3b6408fcfa00452530b73f55d1755f9965.svg" alt="a"/> is a learnable parameter. When called without arguments, <cite>nn.PReLU()</cite> uses a single
parameter <img class="math" src="_images/math/b3e65e3b6408fcfa00452530b73f55d1755f9965.svg" alt="a"/> across all input channels. If called with <cite>nn.PReLU(nChannels)</cite>,
a separate <img class="math" src="_images/math/b3e65e3b6408fcfa00452530b73f55d1755f9965.svg" alt="a"/> is used for each input channel.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>weight decay should not be used when learning <img class="math" src="_images/math/b3e65e3b6408fcfa00452530b73f55d1755f9965.svg" alt="a"/> for good performance.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Channel dim is the 2nd dim of input. When input has dims &lt; 2, then there is
no channel dim and the number of channels = 1.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_parameters</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – number of <img class="math" src="_images/math/b3e65e3b6408fcfa00452530b73f55d1755f9965.svg" alt="a"/> to learn.
Although it takes an int as input, there is only two values are legitimate:
1, or the number of channels at input. Default: 1</p></li>
<li><p><strong>init</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – the initial value of <img class="math" src="_images/math/b3e65e3b6408fcfa00452530b73f55d1755f9965.svg" alt="a"/>. Default: 0.25</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/> where <cite>*</cite> means, any number of additional
dimensions</p></li>
<li><p>Output: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/>, same shape as the input</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><p><strong>~PReLU.weight</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – the learnable weights of shape (<code class="xref py py-attr docutils literal notranslate"><span class="pre">num_parameters</span></code>).</p>
</dd>
</dl>
<img alt="_images/PReLU.png" src="_images/PReLU.png" />
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="relu">
<h3><span class="hidden-section">ReLU</span><a class="headerlink" href="#relu" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.ReLU">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">ReLU</code><span class="sig-paren">(</span><em class="sig-param">inplace=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/activation.html#ReLU"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ReLU" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the rectified linear unit function element-wise:</p>
<p><img class="math" src="_images/math/e5e399ae418ca430452908937abb0e83b5de6b0d.svg" alt="\text{ReLU}(x)= \max(0, x)"/></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inplace</strong> – can optionally do the operation in-place. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/> where <cite>*</cite> means, any number of additional
dimensions</p></li>
<li><p>Output: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/>, same shape as the input</p></li>
</ul>
</dd>
</dl>
<img alt="_images/ReLU.png" src="_images/ReLU.png" />
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>  <span class="o">&gt;&gt;&gt;</span> <span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
  <span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
  <span class="o">&gt;&gt;&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>


<span class="n">An</span> <span class="n">implementation</span> <span class="n">of</span> <span class="n">CReLU</span> <span class="o">-</span> <span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">arxiv</span><span class="o">.</span><span class="n">org</span><span class="o">/</span><span class="nb">abs</span><span class="o">/</span><span class="mf">1603.05201</span>

  <span class="o">&gt;&gt;&gt;</span> <span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
  <span class="o">&gt;&gt;&gt;</span> <span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
  <span class="o">&gt;&gt;&gt;</span> <span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">),</span><span class="n">m</span><span class="p">(</span><span class="o">-</span><span class="nb">input</span><span class="p">)))</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="relu6">
<h3><span class="hidden-section">ReLU6</span><a class="headerlink" href="#relu6" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.ReLU6">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">ReLU6</code><span class="sig-paren">(</span><em class="sig-param">inplace=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/activation.html#ReLU6"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.ReLU6" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the element-wise function:</p>
<div class="math">
<p><img src="_images/math/bdb5a89663ed2daccf2ba51278c455b8a5e22cae.svg" alt="\text{ReLU6}(x) = \min(\max(0,x), 6)"/></p>
</div><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inplace</strong> – can optionally do the operation in-place. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/> where <cite>*</cite> means, any number of additional
dimensions</p></li>
<li><p>Output: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/>, same shape as the input</p></li>
</ul>
</dd>
</dl>
<img alt="_images/ReLU6.png" src="_images/ReLU6.png" />
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU6</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="rrelu">
<h3><span class="hidden-section">RReLU</span><a class="headerlink" href="#rrelu" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.RReLU">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">RReLU</code><span class="sig-paren">(</span><em class="sig-param">lower=0.125</em>, <em class="sig-param">upper=0.3333333333333333</em>, <em class="sig-param">inplace=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/activation.html#RReLU"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.RReLU" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the randomized leaky rectified liner unit function, element-wise,
as described in the paper:</p>
<p><a class="reference external" href="https://arxiv.org/abs/1505.00853">Empirical Evaluation of Rectified Activations in Convolutional Network</a>.</p>
<p>The function is defined as:</p>
<div class="math">
<p><img src="_images/math/61280c91a170cb6b132a475205b7a6af987db292.svg" alt="\text{RReLU}(x) =
\begin{cases}
    x &amp; \text{if } x \geq 0 \\
    ax &amp; \text{ otherwise }
\end{cases}"/></p>
</div><p>where <img class="math" src="_images/math/b3e65e3b6408fcfa00452530b73f55d1755f9965.svg" alt="a"/> is randomly sampled from uniform distribution
<img class="math" src="_images/math/c87df019e181cbfc8c42ba7f21755ce14d75c931.svg" alt="\mathcal{U}(\text{lower}, \text{upper})"/>.</p>
<blockquote>
<div><p>See: <a class="reference external" href="https://arxiv.org/pdf/1505.00853.pdf">https://arxiv.org/pdf/1505.00853.pdf</a></p>
</div></blockquote>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lower</strong> – lower bound of the uniform distribution. Default: <img class="math" src="_images/math/f3e8add8ec45f07d97e5235ba8a9c91e4cd4b7d9.svg" alt="\frac{1}{8}"/></p></li>
<li><p><strong>upper</strong> – upper bound of the uniform distribution. Default: <img class="math" src="_images/math/5b3fb883abde11598470aae9cf788056d51b7ac9.svg" alt="\frac{1}{3}"/></p></li>
<li><p><strong>inplace</strong> – can optionally do the operation in-place. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/> where <cite>*</cite> means, any number of additional
dimensions</p></li>
<li><p>Output: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/>, same shape as the input</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">RReLU</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="selu">
<h3><span class="hidden-section">SELU</span><a class="headerlink" href="#selu" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.SELU">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">SELU</code><span class="sig-paren">(</span><em class="sig-param">inplace=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/activation.html#SELU"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.SELU" title="Permalink to this definition">¶</a></dt>
<dd><p>Applied element-wise, as:</p>
<div class="math">
<p><img src="_images/math/15d32eaacab106524a364b55513e42c68516c26b.svg" alt="\text{SELU}(x) = \text{scale} * (\max(0,x) + \min(0, \alpha * (\exp(x) - 1)))"/></p>
</div><p>with <img class="math" src="_images/math/407b03edf8cf1f6cc10d643517da874b4940d573.svg" alt="\alpha = 1.6732632423543772848170429916717"/> and
<img class="math" src="_images/math/c8614d79859e0a251253117999a51396a20f764d.svg" alt="\text{scale} = 1.0507009873554804934193349852946"/>.</p>
<p>More details can be found in the paper <a class="reference external" href="https://arxiv.org/abs/1706.02515">Self-Normalizing Neural Networks</a> .</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>inplace</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – can optionally do the operation in-place. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/> where <cite>*</cite> means, any number of additional
dimensions</p></li>
<li><p>Output: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/>, same shape as the input</p></li>
</ul>
</dd>
</dl>
<img alt="_images/SELU.png" src="_images/SELU.png" />
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SELU</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="celu">
<h3><span class="hidden-section">CELU</span><a class="headerlink" href="#celu" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.CELU">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">CELU</code><span class="sig-paren">(</span><em class="sig-param">alpha=1.0</em>, <em class="sig-param">inplace=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/activation.html#CELU"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.CELU" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the element-wise function:</p>
<div class="math">
<p><img src="_images/math/53874560bb033ad3b64b7b2c9f2892aa43aae231.svg" alt="\text{CELU}(x) = \max(0,x) + \min(0, \alpha * (\exp(x/\alpha) - 1))"/></p>
</div><p>More details can be found in the paper <a class="reference external" href="https://arxiv.org/abs/1704.07483">Continuously Differentiable Exponential Linear Units</a> .</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>alpha</strong> – the <img class="math" src="_images/math/2f5aa019312e1bbc969deab8dca8b00f76025404.svg" alt="\alpha"/> value for the CELU formulation. Default: 1.0</p></li>
<li><p><strong>inplace</strong> – can optionally do the operation in-place. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/> where <cite>*</cite> means, any number of additional
dimensions</p></li>
<li><p>Output: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/>, same shape as the input</p></li>
</ul>
</dd>
</dl>
<img alt="_images/CELU.png" src="_images/CELU.png" />
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CELU</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="sigmoid">
<h3><span class="hidden-section">Sigmoid</span><a class="headerlink" href="#sigmoid" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.Sigmoid">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">Sigmoid</code><a class="reference internal" href="_modules/torch/nn/modules/activation.html#Sigmoid"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Sigmoid" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the element-wise function:</p>
<div class="math">
<p><img src="_images/math/699a42ee64e339e2837484ee8d27c1474e03383f.svg" alt="\text{Sigmoid}(x) = \frac{1}{1 + \exp(-x)}"/></p>
</div><dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/> where <cite>*</cite> means, any number of additional
dimensions</p></li>
<li><p>Output: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/>, same shape as the input</p></li>
</ul>
</dd>
</dl>
<img alt="_images/Sigmoid.png" src="_images/Sigmoid.png" />
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="softplus">
<h3><span class="hidden-section">Softplus</span><a class="headerlink" href="#softplus" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.Softplus">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">Softplus</code><span class="sig-paren">(</span><em class="sig-param">beta=1</em>, <em class="sig-param">threshold=20</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/activation.html#Softplus"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Softplus" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the element-wise function:</p>
<div class="math">
<p><img src="_images/math/b7e016f7b390d3e46638372b615816ba9cac12eb.svg" alt="\text{Softplus}(x) = \frac{1}{\beta} * \log(1 + \exp(\beta * x))"/></p>
</div><p>SoftPlus is a smooth approximation to the ReLU function and can be used
to constrain the output of a machine to always be positive.</p>
<p>For numerical stability the implementation reverts to the linear function
for inputs above a certain value.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>beta</strong> – the <img class="math" src="_images/math/7138dad9ac96835665b17f5817eacfcaa9b834c9.svg" alt="\beta"/> value for the Softplus formulation. Default: 1</p></li>
<li><p><strong>threshold</strong> – values above this revert to a linear function. Default: 20</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/> where <cite>*</cite> means, any number of additional
dimensions</p></li>
<li><p>Output: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/>, same shape as the input</p></li>
</ul>
</dd>
</dl>
<img alt="_images/Softplus.png" src="_images/Softplus.png" />
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softplus</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="softshrink">
<h3><span class="hidden-section">Softshrink</span><a class="headerlink" href="#softshrink" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.Softshrink">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">Softshrink</code><span class="sig-paren">(</span><em class="sig-param">lambd=0.5</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/activation.html#Softshrink"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Softshrink" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the soft shrinkage function elementwise:</p>
<div class="math">
<p><img src="_images/math/537f8060fd8ac8d71145ad3d5fb2be9c794eb595.svg" alt="\text{SoftShrinkage}(x) =
\begin{cases}
x - \lambda, &amp; \text{ if } x &gt; \lambda \\
x + \lambda, &amp; \text{ if } x &lt; -\lambda \\
0, &amp; \text{ otherwise }
\end{cases}"/></p>
</div><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>lambd</strong> – the <img class="math" src="_images/math/cefc603e5658facb747581f9567192993f21c7ab.svg" alt="\lambda"/> value for the Softshrink formulation. Default: 0.5</p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/> where <cite>*</cite> means, any number of additional
dimensions</p></li>
<li><p>Output: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/>, same shape as the input</p></li>
</ul>
</dd>
</dl>
<img alt="_images/Softshrink.png" src="_images/Softshrink.png" />
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softshrink</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="softsign">
<h3><span class="hidden-section">Softsign</span><a class="headerlink" href="#softsign" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.Softsign">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">Softsign</code><a class="reference internal" href="_modules/torch/nn/modules/activation.html#Softsign"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Softsign" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the element-wise function:</p>
<div class="math">
<p><img src="_images/math/604515a7119fdccd2d21fcee22c3a5d882aab2ab.svg" alt="\text{SoftSign}(x) = \frac{x}{ 1 + |x|}"/></p>
</div><dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/> where <cite>*</cite> means, any number of additional
dimensions</p></li>
<li><p>Output: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/>, same shape as the input</p></li>
</ul>
</dd>
</dl>
<img alt="_images/Softsign.png" src="_images/Softsign.png" />
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softsign</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="tanh">
<h3><span class="hidden-section">Tanh</span><a class="headerlink" href="#tanh" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.Tanh">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">Tanh</code><a class="reference internal" href="_modules/torch/nn/modules/activation.html#Tanh"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Tanh" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the element-wise function:</p>
<div class="math">
<p><img src="_images/math/2b75d891b06e293b1f144f9b76934af71996fd8f.svg" alt="\text{Tanh}(x) = \tanh(x) = \frac{e^x - e^{-x}} {e^x + e^{-x}}"/></p>
</div><dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/> where <cite>*</cite> means, any number of additional
dimensions</p></li>
<li><p>Output: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/>, same shape as the input</p></li>
</ul>
</dd>
</dl>
<img alt="_images/Tanh.png" src="_images/Tanh.png" />
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="tanhshrink">
<h3><span class="hidden-section">Tanhshrink</span><a class="headerlink" href="#tanhshrink" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.Tanhshrink">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">Tanhshrink</code><a class="reference internal" href="_modules/torch/nn/modules/activation.html#Tanhshrink"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Tanhshrink" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the element-wise function:</p>
<div class="math">
<p><img src="_images/math/891101d92e2fb3c8decc955bd9dd583f912c8ff5.svg" alt="\text{Tanhshrink}(x) = x - \text{Tanh}(x)"/></p>
</div><dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/> where <cite>*</cite> means, any number of additional
dimensions</p></li>
<li><p>Output: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/>, same shape as the input</p></li>
</ul>
</dd>
</dl>
<img alt="_images/Tanhshrink.png" src="_images/Tanhshrink.png" />
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Tanhshrink</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="threshold">
<h3><span class="hidden-section">Threshold</span><a class="headerlink" href="#threshold" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.Threshold">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">Threshold</code><span class="sig-paren">(</span><em class="sig-param">threshold</em>, <em class="sig-param">value</em>, <em class="sig-param">inplace=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/activation.html#Threshold"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Threshold" title="Permalink to this definition">¶</a></dt>
<dd><p>Thresholds each element of the input Tensor.</p>
<p>Threshold is defined as:</p>
<div class="math">
<p><img src="_images/math/433cbea386e7d4d11fbf2f44aba0b0b6c05bb654.svg" alt="y =
\begin{cases}
x, &amp;\text{ if } x &gt; \text{threshold} \\
\text{value}, &amp;\text{ otherwise }
\end{cases}"/></p>
</div><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>threshold</strong> – The value to threshold at</p></li>
<li><p><strong>value</strong> – The value to replace with</p></li>
<li><p><strong>inplace</strong> – can optionally do the operation in-place. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/> where <cite>*</cite> means, any number of additional
dimensions</p></li>
<li><p>Output: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/>, same shape as the input</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Threshold</span><span class="p">(</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
</div>
<div class="section" id="non-linear-activations-other">
<h2>Non-linear activations (other)<a class="headerlink" href="#non-linear-activations-other" title="Permalink to this headline">¶</a></h2>
<div class="section" id="softmin">
<h3><span class="hidden-section">Softmin</span><a class="headerlink" href="#softmin" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.Softmin">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">Softmin</code><span class="sig-paren">(</span><em class="sig-param">dim=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/activation.html#Softmin"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Softmin" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the Softmin function to an n-dimensional input Tensor
rescaling them so that the elements of the n-dimensional output Tensor
lie in the range <cite>[0, 1]</cite> and sum to 1.</p>
<p>Softmin is defined as:</p>
<div class="math">
<p><img src="_images/math/249d7d5c397a529ffb553891b12f0b284e003302.svg" alt="\text{Softmin}(x_{i}) = \frac{\exp(-x_i)}{\sum_j \exp(-x_j)}"/></p>
</div><dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/2de0f5cf89ef2a5e8bd53fbaca25287a386e0784.svg" alt="(*)"/> where <cite>*</cite> means, any number of additional
dimensions</p></li>
<li><p>Output: <img class="math" src="_images/math/2de0f5cf89ef2a5e8bd53fbaca25287a386e0784.svg" alt="(*)"/>, same shape as the input</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – A dimension along which Softmin will be computed (so every slice
along dim will sum to 1).</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a Tensor of the same dimension and shape as the input, with
values in the range [0, 1]</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmin</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="softmax">
<h3><span class="hidden-section">Softmax</span><a class="headerlink" href="#softmax" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.Softmax">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">Softmax</code><span class="sig-paren">(</span><em class="sig-param">dim=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/activation.html#Softmax"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Softmax" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the Softmax function to an n-dimensional input Tensor
rescaling them so that the elements of the n-dimensional output Tensor
lie in the range [0,1] and sum to 1.</p>
<p>Softmax is defined as:</p>
<div class="math">
<p><img src="_images/math/47488d24bb2d9c1c62d2ac833d8734feb1599a57.svg" alt="\text{Softmax}(x_{i}) = \frac{\exp(x_i)}{\sum_j \exp(x_j)}"/></p>
</div><dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/2de0f5cf89ef2a5e8bd53fbaca25287a386e0784.svg" alt="(*)"/> where <cite>*</cite> means, any number of additional
dimensions</p></li>
<li><p>Output: <img class="math" src="_images/math/2de0f5cf89ef2a5e8bd53fbaca25287a386e0784.svg" alt="(*)"/>, same shape as the input</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a Tensor of the same dimension and shape as the input with
values in the range [0, 1]</p>
</dd>
<dt class="field-even">Parameters</dt>
<dd class="field-even"><p><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – A dimension along which Softmax will be computed (so every slice
along dim will sum to 1).</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This module doesn’t work directly with NLLLoss,
which expects the Log to be computed between the Softmax and itself.
Use <cite>LogSoftmax</cite> instead (it’s faster and has better numerical properties).</p>
</div>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="softmax2d">
<h3><span class="hidden-section">Softmax2d</span><a class="headerlink" href="#softmax2d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.Softmax2d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">Softmax2d</code><a class="reference internal" href="_modules/torch/nn/modules/activation.html#Softmax2d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Softmax2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies SoftMax over features to each spatial location.</p>
<p>When given an image of <code class="docutils literal notranslate"><span class="pre">Channels</span> <span class="pre">x</span> <span class="pre">Height</span> <span class="pre">x</span> <span class="pre">Width</span></code>, it will
apply <cite>Softmax</cite> to each location <img class="math" src="_images/math/e75e6ed0e24f1546237e7a66122438e6389b018b.svg" alt="(Channels, h_i, w_j)"/></p>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/682f63eaded2237f913167b337a56425e537bdb3.svg" alt="(N, C, H, W)"/></p></li>
<li><p>Output: <img class="math" src="_images/math/682f63eaded2237f913167b337a56425e537bdb3.svg" alt="(N, C, H, W)"/> (same shape as input)</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>a Tensor of the same dimension and shape as the input with
values in the range [0, 1]</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax2d</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># you softmax over the 2nd dimension</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">13</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="logsoftmax">
<h3><span class="hidden-section">LogSoftmax</span><a class="headerlink" href="#logsoftmax" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.LogSoftmax">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">LogSoftmax</code><span class="sig-paren">(</span><em class="sig-param">dim=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/activation.html#LogSoftmax"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.LogSoftmax" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies the <img class="math" src="_images/math/79f7d0f2841615b30a1f44924a638ab341284da0.svg" alt="\log(\text{Softmax}(x))"/> function to an n-dimensional
input Tensor. The LogSoftmax formulation can be simplified as:</p>
<div class="math">
<p><img src="_images/math/f6e2dcacaddb86bcbef54148aa57f3cec70d4ff9.svg" alt="\text{LogSoftmax}(x_{i}) = \log\left(\frac{\exp(x_i) }{ \sum_j \exp(x_j)} \right)"/></p>
</div><dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/2de0f5cf89ef2a5e8bd53fbaca25287a386e0784.svg" alt="(*)"/> where <cite>*</cite> means, any number of additional
dimensions</p></li>
<li><p>Output: <img class="math" src="_images/math/2de0f5cf89ef2a5e8bd53fbaca25287a386e0784.svg" alt="(*)"/>, same shape as the input</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – A dimension along which LogSoftmax will be computed.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a Tensor of the same dimension and shape as the input with
values in the range [-inf, 0)</p>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LogSoftmax</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="adaptivelogsoftmaxwithloss">
<h3><span class="hidden-section">AdaptiveLogSoftmaxWithLoss</span><a class="headerlink" href="#adaptivelogsoftmaxwithloss" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.AdaptiveLogSoftmaxWithLoss">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">AdaptiveLogSoftmaxWithLoss</code><span class="sig-paren">(</span><em class="sig-param">in_features</em>, <em class="sig-param">n_classes</em>, <em class="sig-param">cutoffs</em>, <em class="sig-param">div_value=4.0</em>, <em class="sig-param">head_bias=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/adaptive.html#AdaptiveLogSoftmaxWithLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.AdaptiveLogSoftmaxWithLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Efficient softmax approximation as described in
<a class="reference external" href="https://arxiv.org/abs/1609.04309">Efficient softmax approximation for GPUs</a> by Edouard Grave, Armand Joulin,
Moustapha Cissé, David Grangier, and Hervé Jégou.</p>
<p>Adaptive softmax is an approximate strategy for training models with large
output spaces. It is most effective when the label distribution is highly
imbalanced, for example in natural language modelling, where the word
frequency distribution approximately follows the <a class="reference external" href="https://en.wikipedia.org/wiki/Zipf%27s_law">Zipf’s law</a>.</p>
<p>Adaptive softmax partitions the labels into several clusters, according to
their frequency. These clusters may contain different number of targets
each.
Additionally, clusters containing less frequent labels assign lower
dimensional embeddings to those labels, which speeds up the computation.
For each minibatch, only clusters for which at least one target is
present are evaluated.</p>
<p>The idea is that the clusters which are accessed frequently
(like the first one, containing most frequent labels), should also be cheap
to compute – that is, contain a small number of assigned labels.</p>
<p>We highly recommend taking a look at the original paper for more details.</p>
<ul class="simple">
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">cutoffs</span></code> should be an ordered Sequence of integers sorted
in the increasing order.
It controls number of clusters and the partitioning of targets into
clusters. For example setting <code class="docutils literal notranslate"><span class="pre">cutoffs</span> <span class="pre">=</span> <span class="pre">[10,</span> <span class="pre">100,</span> <span class="pre">1000]</span></code>
means that first <cite>10</cite> targets will be assigned
to the ‘head’ of the adaptive softmax, targets <cite>11, 12, …, 100</cite> will be
assigned to the first cluster, and targets <cite>101, 102, …, 1000</cite> will be
assigned to the second cluster, while targets
<cite>1001, 1002, …, n_classes - 1</cite> will be assigned
to the last, third cluster.</p></li>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">div_value</span></code> is used to compute the size of each additional cluster,
which is given as
<img class="math" src="_images/math/401bfba17e7d052a4b22d7a2293a7c1e4a532d3b.svg" alt="\left\lfloor\frac{in\_features}{div\_value^{idx}}\right\rfloor"/>,
where <img class="math" src="_images/math/d419d7b82cfac77ad6a359d1be68b6d8b0308fa2.svg" alt="idx"/> is the cluster index (with clusters
for less frequent words having larger indices,
and indices starting from <img class="math" src="_images/math/ec830c85a5fbb48028fe797044da6bdfb924c2fa.svg" alt="1"/>).</p></li>
<li><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">head_bias</span></code> if set to True, adds a bias term to the ‘head’ of the
adaptive softmax. See paper for details. Set to False in the official
implementation.</p></li>
</ul>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Labels passed as inputs to this module should be sorted accoridng to
their frequency. This means that the most frequent label should be
represented by the index <cite>0</cite>, and the least frequent
label should be represented by the index <cite>n_classes - 1</cite>.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This module returns a <code class="docutils literal notranslate"><span class="pre">NamedTuple</span></code> with <code class="docutils literal notranslate"><span class="pre">output</span></code>
and <code class="docutils literal notranslate"><span class="pre">loss</span></code> fields. See further documentation for details.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To compute log-probabilities for all classes, the <code class="docutils literal notranslate"><span class="pre">log_prob</span></code>
method can be used.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_features</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Number of features in the input tensor</p></li>
<li><p><strong>n_classes</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Number of classes in the dataset</p></li>
<li><p><strong>cutoffs</strong> (<em>Sequence</em>) – Cutoffs used to assign targets to their buckets</p></li>
<li><p><strong>div_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em>) – value used as an exponent to compute sizes
of the clusters. Default: 4.0</p></li>
<li><p><strong>head_bias</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, adds a bias term to the ‘head’ of the
adaptive softmax. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>output</strong> is a Tensor of size <code class="docutils literal notranslate"><span class="pre">N</span></code> containing computed target
log probabilities for each example</p></li>
<li><p><strong>loss</strong> is a Scalar representing the computed negative
log likelihood loss</p></li>
</ul>
</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><code class="docutils literal notranslate"><span class="pre">NamedTuple</span></code> with <code class="docutils literal notranslate"><span class="pre">output</span></code> and <code class="docutils literal notranslate"><span class="pre">loss</span></code> fields</p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>input: <img class="math" src="_images/math/f1a093907fb74d813e1abe559e10dbe420596917.svg" alt="(N, in\_features)"/></p></li>
<li><p>target: <img class="math" src="_images/math/53c49d40851a9450d6838659cff1081c4065b1ce.svg" alt="(N)"/> where each value satisfies <img class="math" src="_images/math/6896bad44fe9aa07006d214412971c0548810bea.svg" alt="0 &lt;= target[i] &lt;= n\_classes"/></p></li>
<li><p>output1: <img class="math" src="_images/math/53c49d40851a9450d6838659cff1081c4065b1ce.svg" alt="(N)"/></p></li>
<li><p>output2: <code class="docutils literal notranslate"><span class="pre">Scalar</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="torch.nn.AdaptiveLogSoftmaxWithLoss.log_prob">
<code class="sig-name descname">log_prob</code><span class="sig-paren">(</span><em class="sig-param">input</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/adaptive.html#AdaptiveLogSoftmaxWithLoss.log_prob"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.AdaptiveLogSoftmaxWithLoss.log_prob" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes log probabilities for all <img class="math" src="_images/math/04275c87369e780c2f42b27f27cfc91b752f4ce9.svg" alt="n\_classes"/></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – a minibatch of examples</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>log-probabilities of for each class <img class="math" src="_images/math/d520a12f1579170834c32ad5f656de081bbb36fe.svg" alt="c"/>
in range <img class="math" src="_images/math/c9852dfad143c1bd6e6c055dec4fb71c5d896081.svg" alt="0 &lt;= c &lt;= n\_classes"/>, where <img class="math" src="_images/math/04275c87369e780c2f42b27f27cfc91b752f4ce9.svg" alt="n\_classes"/> is a
parameter passed to <code class="docutils literal notranslate"><span class="pre">AdaptiveLogSoftmaxWithLoss</span></code> constructor.</p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/f1a093907fb74d813e1abe559e10dbe420596917.svg" alt="(N, in\_features)"/></p></li>
<li><p>Output: <img class="math" src="_images/math/f23cb954c8621f793fb3775cb3f1e92b1ba0aeec.svg" alt="(N, n\_classes)"/></p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="torch.nn.AdaptiveLogSoftmaxWithLoss.predict">
<code class="sig-name descname">predict</code><span class="sig-paren">(</span><em class="sig-param">input</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/adaptive.html#AdaptiveLogSoftmaxWithLoss.predict"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.AdaptiveLogSoftmaxWithLoss.predict" title="Permalink to this definition">¶</a></dt>
<dd><p>This is equivalent to <cite>self.log_pob(input).argmax(dim=1)</cite>,
but is more efficient in some cases.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – a minibatch of examples</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a class with the highest probability for each example</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>output (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor">Tensor</a>)</p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/f1a093907fb74d813e1abe559e10dbe420596917.svg" alt="(N, in\_features)"/></p></li>
<li><p>Output: <img class="math" src="_images/math/53c49d40851a9450d6838659cff1081c4065b1ce.svg" alt="(N)"/></p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>
<div class="section" id="normalization-layers">
<h2>Normalization layers<a class="headerlink" href="#normalization-layers" title="Permalink to this headline">¶</a></h2>
<div class="section" id="batchnorm1d">
<h3><span class="hidden-section">BatchNorm1d</span><a class="headerlink" href="#batchnorm1d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.BatchNorm1d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">BatchNorm1d</code><span class="sig-paren">(</span><em class="sig-param">num_features</em>, <em class="sig-param">eps=1e-05</em>, <em class="sig-param">momentum=0.1</em>, <em class="sig-param">affine=True</em>, <em class="sig-param">track_running_stats=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/batchnorm.html#BatchNorm1d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.BatchNorm1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies Batch Normalization over a 2D or 3D input (a mini-batch of 1D
inputs with optional additional channel dimension) as described in the paper
<a class="reference external" href="https://arxiv.org/abs/1502.03167">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a> .</p>
<div class="math">
<p><img src="_images/math/11550c9ffe3375b86c94170a4bac842eff7ee1ea.svg" alt="y = \frac{x - \mathrm{E}[x]}{\sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta"/></p>
</div><p>The mean and standard-deviation are calculated per-dimension over
the mini-batches and <img class="math" src="_images/math/34d137cf01c787ecda732761c3f95b0f65a6c3e9.svg" alt="\gamma"/> and <img class="math" src="_images/math/7138dad9ac96835665b17f5817eacfcaa9b834c9.svg" alt="\beta"/> are learnable parameter vectors
of size <cite>C</cite> (where <cite>C</cite> is the input size). By default, the elements of <img class="math" src="_images/math/34d137cf01c787ecda732761c3f95b0f65a6c3e9.svg" alt="\gamma"/> are set
to 1 and the elements of <img class="math" src="_images/math/7138dad9ac96835665b17f5817eacfcaa9b834c9.svg" alt="\beta"/> are set to 0.</p>
<p>Also by default, during training this layer keeps running estimates of its
computed mean and variance, which are then used for normalization during
evaluation. The running estimates are kept with a default <code class="xref py py-attr docutils literal notranslate"><span class="pre">momentum</span></code>
of 0.1.</p>
<p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">track_running_stats</span></code> is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, this layer then does not
keep running estimates, and batch statistics are instead used during
evaluation time as well.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This <code class="xref py py-attr docutils literal notranslate"><span class="pre">momentum</span></code> argument is different from one used in optimizer
classes and the conventional notion of momentum. Mathematically, the
update rule for running statistics here is
<img class="math" src="_images/math/cb6a2ec7a06e646e9a6631360f4310af8f1c15df.svg" alt="\hat{x}_\text{new} = (1 - \text{momentum}) \times \hat{x} + \text{momentum} \times x_t"/>,
where <img class="math" src="_images/math/a787de15b9b3e025c3790414ce6a3bcc427b1715.svg" alt="\hat{x}"/> is the estimated statistic and <img class="math" src="_images/math/8f3c6b529aaa515fdbc6c51b4fc4f73293dbfc09.svg" alt="x_t"/> is the
new observed value.</p>
</div>
<p>Because the Batch Normalization is done over the <cite>C</cite> dimension, computing statistics
on <cite>(N, L)</cite> slices, it’s common terminology to call this Temporal Batch Normalization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_features</strong> – <img class="math" src="_images/math/4db5b6e16e06f929ce3f675c5e535d06ffb02ff7.svg" alt="C"/> from an expected input of size
<img class="math" src="_images/math/8d4eab9abe2fd5aeffd8210c4059fb7b01be90fb.svg" alt="(N, C, L)"/> or <img class="math" src="_images/math/19eef1966f7c545af3ac8c0fa486974d873e3c65.svg" alt="L"/> from input of size <img class="math" src="_images/math/22da643af5a2ffe5496b76b1567c5f507dcef712.svg" alt="(N, L)"/></p></li>
<li><p><strong>eps</strong> – a value added to the denominator for numerical stability.
Default: 1e-5</p></li>
<li><p><strong>momentum</strong> – the value used for the running_mean and running_var
computation. Can be set to <code class="docutils literal notranslate"><span class="pre">None</span></code> for cumulative moving average
(i.e. simple average). Default: 0.1</p></li>
<li><p><strong>affine</strong> – a boolean value that when set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, this module has
learnable affine parameters. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>track_running_stats</strong> – a boolean value that when set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, this
module tracks the running mean and variance, and when set to <code class="docutils literal notranslate"><span class="pre">False</span></code>,
this module does not track such statistics and always uses batch
statistics in both training and eval modes. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/b1bbd46713f69174c0592644b159895f715a74fa.svg" alt="(N, C)"/> or <img class="math" src="_images/math/8d4eab9abe2fd5aeffd8210c4059fb7b01be90fb.svg" alt="(N, C, L)"/></p></li>
<li><p>Output: <img class="math" src="_images/math/b1bbd46713f69174c0592644b159895f715a74fa.svg" alt="(N, C)"/> or <img class="math" src="_images/math/8d4eab9abe2fd5aeffd8210c4059fb7b01be90fb.svg" alt="(N, C, L)"/> (same shape as input)</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># With Learnable Parameters</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Without Learnable Parameters</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="batchnorm2d">
<h3><span class="hidden-section">BatchNorm2d</span><a class="headerlink" href="#batchnorm2d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.BatchNorm2d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">BatchNorm2d</code><span class="sig-paren">(</span><em class="sig-param">num_features</em>, <em class="sig-param">eps=1e-05</em>, <em class="sig-param">momentum=0.1</em>, <em class="sig-param">affine=True</em>, <em class="sig-param">track_running_stats=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/batchnorm.html#BatchNorm2d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.BatchNorm2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies Batch Normalization over a 4D input (a mini-batch of 2D inputs
with additional channel dimension) as described in the paper
<a class="reference external" href="https://arxiv.org/abs/1502.03167">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a> .</p>
<div class="math">
<p><img src="_images/math/ee5c3fdc91f720726c2fcd656cdc487f98a15829.svg" alt="y = \frac{x - \mathrm{E}[x]}{ \sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta"/></p>
</div><p>The mean and standard-deviation are calculated per-dimension over
the mini-batches and <img class="math" src="_images/math/34d137cf01c787ecda732761c3f95b0f65a6c3e9.svg" alt="\gamma"/> and <img class="math" src="_images/math/7138dad9ac96835665b17f5817eacfcaa9b834c9.svg" alt="\beta"/> are learnable parameter vectors
of size <cite>C</cite> (where <cite>C</cite> is the input size). By default, the elements of <img class="math" src="_images/math/34d137cf01c787ecda732761c3f95b0f65a6c3e9.svg" alt="\gamma"/> are set
to 1 and the elements of <img class="math" src="_images/math/7138dad9ac96835665b17f5817eacfcaa9b834c9.svg" alt="\beta"/> are set to 0.</p>
<p>Also by default, during training this layer keeps running estimates of its
computed mean and variance, which are then used for normalization during
evaluation. The running estimates are kept with a default <code class="xref py py-attr docutils literal notranslate"><span class="pre">momentum</span></code>
of 0.1.</p>
<p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">track_running_stats</span></code> is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, this layer then does not
keep running estimates, and batch statistics are instead used during
evaluation time as well.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This <code class="xref py py-attr docutils literal notranslate"><span class="pre">momentum</span></code> argument is different from one used in optimizer
classes and the conventional notion of momentum. Mathematically, the
update rule for running statistics here is
<img class="math" src="_images/math/cb6a2ec7a06e646e9a6631360f4310af8f1c15df.svg" alt="\hat{x}_\text{new} = (1 - \text{momentum}) \times \hat{x} + \text{momentum} \times x_t"/>,
where <img class="math" src="_images/math/a787de15b9b3e025c3790414ce6a3bcc427b1715.svg" alt="\hat{x}"/> is the estimated statistic and <img class="math" src="_images/math/8f3c6b529aaa515fdbc6c51b4fc4f73293dbfc09.svg" alt="x_t"/> is the
new observed value.</p>
</div>
<p>Because the Batch Normalization is done over the <cite>C</cite> dimension, computing statistics
on <cite>(N, H, W)</cite> slices, it’s common terminology to call this Spatial Batch Normalization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_features</strong> – <img class="math" src="_images/math/4db5b6e16e06f929ce3f675c5e535d06ffb02ff7.svg" alt="C"/> from an expected input of size
<img class="math" src="_images/math/682f63eaded2237f913167b337a56425e537bdb3.svg" alt="(N, C, H, W)"/></p></li>
<li><p><strong>eps</strong> – a value added to the denominator for numerical stability.
Default: 1e-5</p></li>
<li><p><strong>momentum</strong> – the value used for the running_mean and running_var
computation. Can be set to <code class="docutils literal notranslate"><span class="pre">None</span></code> for cumulative moving average
(i.e. simple average). Default: 0.1</p></li>
<li><p><strong>affine</strong> – a boolean value that when set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, this module has
learnable affine parameters. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>track_running_stats</strong> – a boolean value that when set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, this
module tracks the running mean and variance, and when set to <code class="docutils literal notranslate"><span class="pre">False</span></code>,
this module does not track such statistics and always uses batch
statistics in both training and eval modes. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/682f63eaded2237f913167b337a56425e537bdb3.svg" alt="(N, C, H, W)"/></p></li>
<li><p>Output: <img class="math" src="_images/math/682f63eaded2237f913167b337a56425e537bdb3.svg" alt="(N, C, H, W)"/> (same shape as input)</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># With Learnable Parameters</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Without Learnable Parameters</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="mi">45</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="batchnorm3d">
<h3><span class="hidden-section">BatchNorm3d</span><a class="headerlink" href="#batchnorm3d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.BatchNorm3d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">BatchNorm3d</code><span class="sig-paren">(</span><em class="sig-param">num_features</em>, <em class="sig-param">eps=1e-05</em>, <em class="sig-param">momentum=0.1</em>, <em class="sig-param">affine=True</em>, <em class="sig-param">track_running_stats=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/batchnorm.html#BatchNorm3d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.BatchNorm3d" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies Batch Normalization over a 5D input (a mini-batch of 3D inputs
with additional channel dimension) as described in the paper
<a class="reference external" href="https://arxiv.org/abs/1502.03167">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a> .</p>
<div class="math">
<p><img src="_images/math/ee5c3fdc91f720726c2fcd656cdc487f98a15829.svg" alt="y = \frac{x - \mathrm{E}[x]}{ \sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta"/></p>
</div><p>The mean and standard-deviation are calculated per-dimension over
the mini-batches and <img class="math" src="_images/math/34d137cf01c787ecda732761c3f95b0f65a6c3e9.svg" alt="\gamma"/> and <img class="math" src="_images/math/7138dad9ac96835665b17f5817eacfcaa9b834c9.svg" alt="\beta"/> are learnable parameter vectors
of size <cite>C</cite> (where <cite>C</cite> is the input size). By default, the elements of <img class="math" src="_images/math/34d137cf01c787ecda732761c3f95b0f65a6c3e9.svg" alt="\gamma"/> are set
to 1 and the elements of <img class="math" src="_images/math/7138dad9ac96835665b17f5817eacfcaa9b834c9.svg" alt="\beta"/> are set to 0.</p>
<p>Also by default, during training this layer keeps running estimates of its
computed mean and variance, which are then used for normalization during
evaluation. The running estimates are kept with a default <code class="xref py py-attr docutils literal notranslate"><span class="pre">momentum</span></code>
of 0.1.</p>
<p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">track_running_stats</span></code> is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, this layer then does not
keep running estimates, and batch statistics are instead used during
evaluation time as well.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This <code class="xref py py-attr docutils literal notranslate"><span class="pre">momentum</span></code> argument is different from one used in optimizer
classes and the conventional notion of momentum. Mathematically, the
update rule for running statistics here is
<img class="math" src="_images/math/cb6a2ec7a06e646e9a6631360f4310af8f1c15df.svg" alt="\hat{x}_\text{new} = (1 - \text{momentum}) \times \hat{x} + \text{momentum} \times x_t"/>,
where <img class="math" src="_images/math/a787de15b9b3e025c3790414ce6a3bcc427b1715.svg" alt="\hat{x}"/> is the estimated statistic and <img class="math" src="_images/math/8f3c6b529aaa515fdbc6c51b4fc4f73293dbfc09.svg" alt="x_t"/> is the
new observed value.</p>
</div>
<p>Because the Batch Normalization is done over the <cite>C</cite> dimension, computing statistics
on <cite>(N, D, H, W)</cite> slices, it’s common terminology to call this Volumetric Batch Normalization
or Spatio-temporal Batch Normalization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_features</strong> – <img class="math" src="_images/math/4db5b6e16e06f929ce3f675c5e535d06ffb02ff7.svg" alt="C"/> from an expected input of size
<img class="math" src="_images/math/98ea75cf626098a1b65ba3d34a365f6b32e5f8a8.svg" alt="(N, C, D, H, W)"/></p></li>
<li><p><strong>eps</strong> – a value added to the denominator for numerical stability.
Default: 1e-5</p></li>
<li><p><strong>momentum</strong> – the value used for the running_mean and running_var
computation. Can be set to <code class="docutils literal notranslate"><span class="pre">None</span></code> for cumulative moving average
(i.e. simple average). Default: 0.1</p></li>
<li><p><strong>affine</strong> – a boolean value that when set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, this module has
learnable affine parameters. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>track_running_stats</strong> – a boolean value that when set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, this
module tracks the running mean and variance, and when set to <code class="docutils literal notranslate"><span class="pre">False</span></code>,
this module does not track such statistics and always uses batch
statistics in both training and eval modes. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/98ea75cf626098a1b65ba3d34a365f6b32e5f8a8.svg" alt="(N, C, D, H, W)"/></p></li>
<li><p>Output: <img class="math" src="_images/math/98ea75cf626098a1b65ba3d34a365f6b32e5f8a8.svg" alt="(N, C, D, H, W)"/> (same shape as input)</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># With Learnable Parameters</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Without Learnable Parameters</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="mi">45</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="groupnorm">
<h3><span class="hidden-section">GroupNorm</span><a class="headerlink" href="#groupnorm" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.GroupNorm">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">GroupNorm</code><span class="sig-paren">(</span><em class="sig-param">num_groups</em>, <em class="sig-param">num_channels</em>, <em class="sig-param">eps=1e-05</em>, <em class="sig-param">affine=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/normalization.html#GroupNorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.GroupNorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies Group Normalization over a mini-batch of inputs as described in
the paper <a class="reference external" href="https://arxiv.org/abs/1803.08494">Group Normalization</a> .</p>
<div class="math">
<p><img src="_images/math/ee5c3fdc91f720726c2fcd656cdc487f98a15829.svg" alt="y = \frac{x - \mathrm{E}[x]}{ \sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta"/></p>
</div><p>The input channels are separated into <code class="xref py py-attr docutils literal notranslate"><span class="pre">num_groups</span></code> groups, each containing
<code class="docutils literal notranslate"><span class="pre">num_channels</span> <span class="pre">/</span> <span class="pre">num_groups</span></code> channels. The mean and standard-deviation are calculated
separately over the each group. <img class="math" src="_images/math/34d137cf01c787ecda732761c3f95b0f65a6c3e9.svg" alt="\gamma"/> and <img class="math" src="_images/math/7138dad9ac96835665b17f5817eacfcaa9b834c9.svg" alt="\beta"/> are learnable
per-channel affine transform parameter vectors of size <code class="xref py py-attr docutils literal notranslate"><span class="pre">num_channels</span></code> if
<code class="xref py py-attr docutils literal notranslate"><span class="pre">affine</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
<p>This layer uses statistics computed from input data in both training and
evaluation modes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_groups</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – number of groups to separate the channels into</p></li>
<li><p><strong>num_channels</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – number of channels expected in input</p></li>
<li><p><strong>eps</strong> – a value added to the denominator for numerical stability. Default: 1e-5</p></li>
<li><p><strong>affine</strong> – a boolean value that when set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, this module
has learnable per-channel affine parameters initialized to ones (for weights)
and zeros (for biases). Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/075615abf7466dfa600630602ad19a424154bc93.svg" alt="(N, C, *)"/> where <img class="math" src="_images/math/8ead1f63363bf3d45ceb17007c3b4ea01d0a7e88.svg" alt="C=\text{num\_channels}"/></p></li>
<li><p>Output: <img class="math" src="_images/math/075615abf7466dfa600630602ad19a424154bc93.svg" alt="(N, C, *)"/> (same shape as input)</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Separate 6 channels into 3 groups</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Separate 6 channels into 6 groups (equivalent with InstanceNorm)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Put all 6 channels into a single group (equivalent with LayerNorm)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GroupNorm</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Activating the module</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="syncbatchnorm">
<h3><span class="hidden-section">SyncBatchNorm</span><a class="headerlink" href="#syncbatchnorm" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.SyncBatchNorm">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">SyncBatchNorm</code><span class="sig-paren">(</span><em class="sig-param">num_features</em>, <em class="sig-param">eps=1e-05</em>, <em class="sig-param">momentum=0.1</em>, <em class="sig-param">affine=True</em>, <em class="sig-param">track_running_stats=True</em>, <em class="sig-param">process_group=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/batchnorm.html#SyncBatchNorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.SyncBatchNorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies Batch Normalization over a N-Dimensional input (a mini-batch of [N-2]D inputs
with additional channel dimension) as described in the paper
<a class="reference external" href="https://arxiv.org/abs/1502.03167">Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</a> .</p>
<div class="math">
<p><img src="_images/math/ee5c3fdc91f720726c2fcd656cdc487f98a15829.svg" alt="y = \frac{x - \mathrm{E}[x]}{ \sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta"/></p>
</div><p>The mean and standard-deviation are calculated per-dimension over all
mini-batches of the same process groups. <img class="math" src="_images/math/34d137cf01c787ecda732761c3f95b0f65a6c3e9.svg" alt="\gamma"/> and <img class="math" src="_images/math/7138dad9ac96835665b17f5817eacfcaa9b834c9.svg" alt="\beta"/>
are learnable parameter vectors of size <cite>C</cite> (where <cite>C</cite> is the input size).
By default, the elements of <img class="math" src="_images/math/34d137cf01c787ecda732761c3f95b0f65a6c3e9.svg" alt="\gamma"/> are sampled from
<img class="math" src="_images/math/794dc9a966ead44173b267381b1a71a95e22ed90.svg" alt="\mathcal{U}(0, 1)"/> and the elements of <img class="math" src="_images/math/7138dad9ac96835665b17f5817eacfcaa9b834c9.svg" alt="\beta"/> are set to 0.</p>
<p>Also by default, during training this layer keeps running estimates of its
computed mean and variance, which are then used for normalization during
evaluation. The running estimates are kept with a default <code class="xref py py-attr docutils literal notranslate"><span class="pre">momentum</span></code>
of 0.1.</p>
<p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">track_running_stats</span></code> is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, this layer then does not
keep running estimates, and batch statistics are instead used during
evaluation time as well.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This <code class="xref py py-attr docutils literal notranslate"><span class="pre">momentum</span></code> argument is different from one used in optimizer
classes and the conventional notion of momentum. Mathematically, the
update rule for running statistics here is
<img class="math" src="_images/math/cce430433a2d1bb0f07581e786ba93e72fce0beb.svg" alt="\hat{x}_\text{new} = (1 - \text{momentum}) \times \hat{x} + \text{momemtum} \times x_t"/>,
where <img class="math" src="_images/math/a787de15b9b3e025c3790414ce6a3bcc427b1715.svg" alt="\hat{x}"/> is the estimated statistic and <img class="math" src="_images/math/8f3c6b529aaa515fdbc6c51b4fc4f73293dbfc09.svg" alt="x_t"/> is the
new observed value.</p>
</div>
<p>Because the Batch Normalization is done over the <cite>C</cite> dimension, computing statistics
on <cite>(N, +)</cite> slices, it’s common terminology to call this Volumetric Batch Normalization
or Spatio-temporal Batch Normalization.</p>
<p>Currently SyncBatchNorm only supports DistributedDataParallel with single GPU per process. Use
torch.nn.SyncBatchNorm.convert_sync_batchnorm() to convert BatchNorm layer to SyncBatchNorm before wrapping
Network with DDP.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_features</strong> – <img class="math" src="_images/math/4db5b6e16e06f929ce3f675c5e535d06ffb02ff7.svg" alt="C"/> from an expected input of size
<img class="math" src="_images/math/a0561a863f3d0a1df2514b0670b05c04c53d3c39.svg" alt="(N, C, +)"/></p></li>
<li><p><strong>eps</strong> – a value added to the denominator for numerical stability.
Default: 1e-5</p></li>
<li><p><strong>momentum</strong> – the value used for the running_mean and running_var
computation. Can be set to <code class="docutils literal notranslate"><span class="pre">None</span></code> for cumulative moving average
(i.e. simple average). Default: 0.1</p></li>
<li><p><strong>affine</strong> – a boolean value that when set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, this module has
learnable affine parameters. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>track_running_stats</strong> – a boolean value that when set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, this
module tracks the running mean and variance, and when set to <code class="docutils literal notranslate"><span class="pre">False</span></code>,
this module does not track such statistics and always uses batch
statistics in both training and eval modes. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>process_group</strong> – synchronization of stats happen within each process group
individually. Default behavior is synchronization across the whole
world</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/a0561a863f3d0a1df2514b0670b05c04c53d3c39.svg" alt="(N, C, +)"/></p></li>
<li><p>Output: <img class="math" src="_images/math/a0561a863f3d0a1df2514b0670b05c04c53d3c39.svg" alt="(N, C, +)"/> (same shape as input)</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># With Learnable Parameters</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SyncBatchNorm</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># creating process group (optional)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># process_ids is a list of int identifying rank ids.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">process_group</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">new_group</span><span class="p">(</span><span class="n">process_ids</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Without Learnable Parameters</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm3d</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">process_group</span><span class="o">=</span><span class="n">process_group</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="mi">45</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># network is nn.BatchNorm layer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sync_bn_network</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SyncBatchNorm</span><span class="o">.</span><span class="n">convert_sync_batchnorm</span><span class="p">(</span><span class="n">network</span><span class="p">,</span> <span class="n">process_group</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># only single gpu per process is currently supported</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ddp_sync_bn_network</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">parallel</span><span class="o">.</span><span class="n">DistributedDataParallel</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>                        <span class="n">sync_bn_network</span><span class="p">,</span>
<span class="gp">&gt;&gt;&gt; </span>                        <span class="n">device_ids</span><span class="o">=</span><span class="p">[</span><span class="n">args</span><span class="o">.</span><span class="n">local_rank</span><span class="p">],</span>
<span class="gp">&gt;&gt;&gt; </span>                        <span class="n">output_device</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">local_rank</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="torch.nn.SyncBatchNorm.convert_sync_batchnorm">
<em class="property">classmethod </em><code class="sig-name descname">convert_sync_batchnorm</code><span class="sig-paren">(</span><em class="sig-param">module</em>, <em class="sig-param">process_group=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/batchnorm.html#SyncBatchNorm.convert_sync_batchnorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.SyncBatchNorm.convert_sync_batchnorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper function to convert <cite>torch.nn.BatchNormND</cite> layer in the model to
<cite>torch.nn.SyncBatchNorm</cite> layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> (<a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module"><em>nn.Module</em></a>) – containing module</p></li>
<li><p><strong>process_group</strong> (<em>optional</em>) – process group to scope synchronization,</p></li>
</ul>
</dd>
</dl>
<p>default is the whole world</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The original module with the converted <cite>torch.nn.SyncBatchNorm</cite> layer</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Network with nn.BatchNorm layer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">module</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
<span class="gp">&gt;&gt;&gt; </span>           <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">100</span><span class="p">),</span>
<span class="gp">&gt;&gt;&gt; </span>           <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm1d</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span>         <span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># creating process group (optional)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># process_ids is a list of int identifying rank ids.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">process_group</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">new_group</span><span class="p">(</span><span class="n">process_ids</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sync_bn_module</span> <span class="o">=</span> <span class="n">convert_sync_batchnorm</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">process_group</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="instancenorm1d">
<h3><span class="hidden-section">InstanceNorm1d</span><a class="headerlink" href="#instancenorm1d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.InstanceNorm1d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">InstanceNorm1d</code><span class="sig-paren">(</span><em class="sig-param">num_features</em>, <em class="sig-param">eps=1e-05</em>, <em class="sig-param">momentum=0.1</em>, <em class="sig-param">affine=False</em>, <em class="sig-param">track_running_stats=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/instancenorm.html#InstanceNorm1d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.InstanceNorm1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies Instance Normalization over a 3D input (a mini-batch of 1D
inputs with optional additional channel dimension) as described in the paper
<a class="reference external" href="https://arxiv.org/abs/1607.08022">Instance Normalization: The Missing Ingredient for Fast Stylization</a> .</p>
<div class="math">
<p><img src="_images/math/ee5c3fdc91f720726c2fcd656cdc487f98a15829.svg" alt="y = \frac{x - \mathrm{E}[x]}{ \sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta"/></p>
</div><p>The mean and standard-deviation are calculated per-dimension separately
for each object in a mini-batch. <img class="math" src="_images/math/34d137cf01c787ecda732761c3f95b0f65a6c3e9.svg" alt="\gamma"/> and <img class="math" src="_images/math/7138dad9ac96835665b17f5817eacfcaa9b834c9.svg" alt="\beta"/> are learnable parameter vectors
of size <cite>C</cite> (where <cite>C</cite> is the input size) if <code class="xref py py-attr docutils literal notranslate"><span class="pre">affine</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
<p>By default, this layer uses instance statistics computed from input data in
both training and evaluation modes.</p>
<p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">track_running_stats</span></code> is set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, during training this
layer keeps running estimates of its computed mean and variance, which are
then used for normalization during evaluation. The running estimates are
kept with a default <code class="xref py py-attr docutils literal notranslate"><span class="pre">momentum</span></code> of 0.1.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This <code class="xref py py-attr docutils literal notranslate"><span class="pre">momentum</span></code> argument is different from one used in optimizer
classes and the conventional notion of momentum. Mathematically, the
update rule for running statistics here is
<img class="math" src="_images/math/cce430433a2d1bb0f07581e786ba93e72fce0beb.svg" alt="\hat{x}_\text{new} = (1 - \text{momentum}) \times \hat{x} + \text{momemtum} \times x_t"/>,
where <img class="math" src="_images/math/a787de15b9b3e025c3790414ce6a3bcc427b1715.svg" alt="\hat{x}"/> is the estimated statistic and <img class="math" src="_images/math/8f3c6b529aaa515fdbc6c51b4fc4f73293dbfc09.svg" alt="x_t"/> is the
new observed value.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#torch.nn.InstanceNorm1d" title="torch.nn.InstanceNorm1d"><code class="xref py py-class docutils literal notranslate"><span class="pre">InstanceNorm1d</span></code></a> and <a class="reference internal" href="#torch.nn.LayerNorm" title="torch.nn.LayerNorm"><code class="xref py py-class docutils literal notranslate"><span class="pre">LayerNorm</span></code></a> are very similar, but
have some subtle differences. <a class="reference internal" href="#torch.nn.InstanceNorm1d" title="torch.nn.InstanceNorm1d"><code class="xref py py-class docutils literal notranslate"><span class="pre">InstanceNorm1d</span></code></a> is applied
on each channel of channeled data like multidimensional time series, but
<a class="reference internal" href="#torch.nn.LayerNorm" title="torch.nn.LayerNorm"><code class="xref py py-class docutils literal notranslate"><span class="pre">LayerNorm</span></code></a> is usually applied on entire sample and often in NLP
tasks. Additionaly, <a class="reference internal" href="#torch.nn.LayerNorm" title="torch.nn.LayerNorm"><code class="xref py py-class docutils literal notranslate"><span class="pre">LayerNorm</span></code></a> applies elementwise affine
transform, while <a class="reference internal" href="#torch.nn.InstanceNorm1d" title="torch.nn.InstanceNorm1d"><code class="xref py py-class docutils literal notranslate"><span class="pre">InstanceNorm1d</span></code></a> usually don’t apply affine
transform.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_features</strong> – <img class="math" src="_images/math/4db5b6e16e06f929ce3f675c5e535d06ffb02ff7.svg" alt="C"/> from an expected input of size
<img class="math" src="_images/math/8d4eab9abe2fd5aeffd8210c4059fb7b01be90fb.svg" alt="(N, C, L)"/> or <img class="math" src="_images/math/19eef1966f7c545af3ac8c0fa486974d873e3c65.svg" alt="L"/> from input of size <img class="math" src="_images/math/22da643af5a2ffe5496b76b1567c5f507dcef712.svg" alt="(N, L)"/></p></li>
<li><p><strong>eps</strong> – a value added to the denominator for numerical stability. Default: 1e-5</p></li>
<li><p><strong>momentum</strong> – the value used for the running_mean and running_var computation. Default: 0.1</p></li>
<li><p><strong>affine</strong> – a boolean value that when set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, this module has
learnable affine parameters, initialized the same way as done for batch normalization.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>track_running_stats</strong> – a boolean value that when set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, this
module tracks the running mean and variance, and when set to <code class="docutils literal notranslate"><span class="pre">False</span></code>,
this module does not track such statistics and always uses batch
statistics in both training and eval modes. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/8d4eab9abe2fd5aeffd8210c4059fb7b01be90fb.svg" alt="(N, C, L)"/></p></li>
<li><p>Output: <img class="math" src="_images/math/8d4eab9abe2fd5aeffd8210c4059fb7b01be90fb.svg" alt="(N, C, L)"/> (same shape as input)</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Without Learnable Parameters</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm1d</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># With Learnable Parameters</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm1d</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">40</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="instancenorm2d">
<h3><span class="hidden-section">InstanceNorm2d</span><a class="headerlink" href="#instancenorm2d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.InstanceNorm2d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">InstanceNorm2d</code><span class="sig-paren">(</span><em class="sig-param">num_features</em>, <em class="sig-param">eps=1e-05</em>, <em class="sig-param">momentum=0.1</em>, <em class="sig-param">affine=False</em>, <em class="sig-param">track_running_stats=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/instancenorm.html#InstanceNorm2d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.InstanceNorm2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies Instance Normalization over a 4D input (a mini-batch of 2D inputs
with additional channel dimension) as described in the paper
<a class="reference external" href="https://arxiv.org/abs/1607.08022">Instance Normalization: The Missing Ingredient for Fast Stylization</a> .</p>
<div class="math">
<p><img src="_images/math/ee5c3fdc91f720726c2fcd656cdc487f98a15829.svg" alt="y = \frac{x - \mathrm{E}[x]}{ \sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta"/></p>
</div><p>The mean and standard-deviation are calculated per-dimension separately
for each object in a mini-batch. <img class="math" src="_images/math/34d137cf01c787ecda732761c3f95b0f65a6c3e9.svg" alt="\gamma"/> and <img class="math" src="_images/math/7138dad9ac96835665b17f5817eacfcaa9b834c9.svg" alt="\beta"/> are learnable parameter vectors
of size <cite>C</cite> (where <cite>C</cite> is the input size) if <code class="xref py py-attr docutils literal notranslate"><span class="pre">affine</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
<p>By default, this layer uses instance statistics computed from input data in
both training and evaluation modes.</p>
<p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">track_running_stats</span></code> is set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, during training this
layer keeps running estimates of its computed mean and variance, which are
then used for normalization during evaluation. The running estimates are
kept with a default <code class="xref py py-attr docutils literal notranslate"><span class="pre">momentum</span></code> of 0.1.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This <code class="xref py py-attr docutils literal notranslate"><span class="pre">momentum</span></code> argument is different from one used in optimizer
classes and the conventional notion of momentum. Mathematically, the
update rule for running statistics here is
<img class="math" src="_images/math/cce430433a2d1bb0f07581e786ba93e72fce0beb.svg" alt="\hat{x}_\text{new} = (1 - \text{momentum}) \times \hat{x} + \text{momemtum} \times x_t"/>,
where <img class="math" src="_images/math/a787de15b9b3e025c3790414ce6a3bcc427b1715.svg" alt="\hat{x}"/> is the estimated statistic and <img class="math" src="_images/math/8f3c6b529aaa515fdbc6c51b4fc4f73293dbfc09.svg" alt="x_t"/> is the
new observed value.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#torch.nn.InstanceNorm2d" title="torch.nn.InstanceNorm2d"><code class="xref py py-class docutils literal notranslate"><span class="pre">InstanceNorm2d</span></code></a> and <a class="reference internal" href="#torch.nn.LayerNorm" title="torch.nn.LayerNorm"><code class="xref py py-class docutils literal notranslate"><span class="pre">LayerNorm</span></code></a> are very similar, but
have some subtle differences. <a class="reference internal" href="#torch.nn.InstanceNorm2d" title="torch.nn.InstanceNorm2d"><code class="xref py py-class docutils literal notranslate"><span class="pre">InstanceNorm2d</span></code></a> is applied
on each channel of channeled data like RGB images, but
<a class="reference internal" href="#torch.nn.LayerNorm" title="torch.nn.LayerNorm"><code class="xref py py-class docutils literal notranslate"><span class="pre">LayerNorm</span></code></a> is usually applied on entire sample and often in NLP
tasks. Additionaly, <a class="reference internal" href="#torch.nn.LayerNorm" title="torch.nn.LayerNorm"><code class="xref py py-class docutils literal notranslate"><span class="pre">LayerNorm</span></code></a> applies elementwise affine
transform, while <a class="reference internal" href="#torch.nn.InstanceNorm2d" title="torch.nn.InstanceNorm2d"><code class="xref py py-class docutils literal notranslate"><span class="pre">InstanceNorm2d</span></code></a> usually don’t apply affine
transform.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_features</strong> – <img class="math" src="_images/math/4db5b6e16e06f929ce3f675c5e535d06ffb02ff7.svg" alt="C"/> from an expected input of size
<img class="math" src="_images/math/682f63eaded2237f913167b337a56425e537bdb3.svg" alt="(N, C, H, W)"/></p></li>
<li><p><strong>eps</strong> – a value added to the denominator for numerical stability. Default: 1e-5</p></li>
<li><p><strong>momentum</strong> – the value used for the running_mean and running_var computation. Default: 0.1</p></li>
<li><p><strong>affine</strong> – a boolean value that when set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, this module has
learnable affine parameters, initialized the same way as done for batch normalization.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>track_running_stats</strong> – a boolean value that when set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, this
module tracks the running mean and variance, and when set to <code class="docutils literal notranslate"><span class="pre">False</span></code>,
this module does not track such statistics and always uses batch
statistics in both training and eval modes. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/682f63eaded2237f913167b337a56425e537bdb3.svg" alt="(N, C, H, W)"/></p></li>
<li><p>Output: <img class="math" src="_images/math/682f63eaded2237f913167b337a56425e537bdb3.svg" alt="(N, C, H, W)"/> (same shape as input)</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Without Learnable Parameters</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># With Learnable Parameters</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm2d</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="mi">45</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="instancenorm3d">
<h3><span class="hidden-section">InstanceNorm3d</span><a class="headerlink" href="#instancenorm3d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.InstanceNorm3d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">InstanceNorm3d</code><span class="sig-paren">(</span><em class="sig-param">num_features</em>, <em class="sig-param">eps=1e-05</em>, <em class="sig-param">momentum=0.1</em>, <em class="sig-param">affine=False</em>, <em class="sig-param">track_running_stats=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/instancenorm.html#InstanceNorm3d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.InstanceNorm3d" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies Instance Normalization over a 5D input (a mini-batch of 3D inputs
with additional channel dimension) as described in the paper
<a class="reference external" href="https://arxiv.org/abs/1607.08022">Instance Normalization: The Missing Ingredient for Fast Stylization</a> .</p>
<div class="math">
<p><img src="_images/math/ee5c3fdc91f720726c2fcd656cdc487f98a15829.svg" alt="y = \frac{x - \mathrm{E}[x]}{ \sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta"/></p>
</div><p>The mean and standard-deviation are calculated per-dimension separately
for each object in a mini-batch. <img class="math" src="_images/math/34d137cf01c787ecda732761c3f95b0f65a6c3e9.svg" alt="\gamma"/> and <img class="math" src="_images/math/7138dad9ac96835665b17f5817eacfcaa9b834c9.svg" alt="\beta"/> are learnable parameter vectors
of size C (where C is the input size) if <code class="xref py py-attr docutils literal notranslate"><span class="pre">affine</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
<p>By default, this layer uses instance statistics computed from input data in
both training and evaluation modes.</p>
<p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">track_running_stats</span></code> is set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, during training this
layer keeps running estimates of its computed mean and variance, which are
then used for normalization during evaluation. The running estimates are
kept with a default <code class="xref py py-attr docutils literal notranslate"><span class="pre">momentum</span></code> of 0.1.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This <code class="xref py py-attr docutils literal notranslate"><span class="pre">momentum</span></code> argument is different from one used in optimizer
classes and the conventional notion of momentum. Mathematically, the
update rule for running statistics here is
<img class="math" src="_images/math/cce430433a2d1bb0f07581e786ba93e72fce0beb.svg" alt="\hat{x}_\text{new} = (1 - \text{momentum}) \times \hat{x} + \text{momemtum} \times x_t"/>,
where <img class="math" src="_images/math/a787de15b9b3e025c3790414ce6a3bcc427b1715.svg" alt="\hat{x}"/> is the estimated statistic and <img class="math" src="_images/math/8f3c6b529aaa515fdbc6c51b4fc4f73293dbfc09.svg" alt="x_t"/> is the
new observed value.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><a class="reference internal" href="#torch.nn.InstanceNorm3d" title="torch.nn.InstanceNorm3d"><code class="xref py py-class docutils literal notranslate"><span class="pre">InstanceNorm3d</span></code></a> and <a class="reference internal" href="#torch.nn.LayerNorm" title="torch.nn.LayerNorm"><code class="xref py py-class docutils literal notranslate"><span class="pre">LayerNorm</span></code></a> are very similar, but
have some subtle differences. <a class="reference internal" href="#torch.nn.InstanceNorm3d" title="torch.nn.InstanceNorm3d"><code class="xref py py-class docutils literal notranslate"><span class="pre">InstanceNorm3d</span></code></a> is applied
on each channel of channeled data like 3D models with RGB color, but
<a class="reference internal" href="#torch.nn.LayerNorm" title="torch.nn.LayerNorm"><code class="xref py py-class docutils literal notranslate"><span class="pre">LayerNorm</span></code></a> is usually applied on entire sample and often in NLP
tasks. Additionaly, <a class="reference internal" href="#torch.nn.LayerNorm" title="torch.nn.LayerNorm"><code class="xref py py-class docutils literal notranslate"><span class="pre">LayerNorm</span></code></a> applies elementwise affine
transform, while <a class="reference internal" href="#torch.nn.InstanceNorm3d" title="torch.nn.InstanceNorm3d"><code class="xref py py-class docutils literal notranslate"><span class="pre">InstanceNorm3d</span></code></a> usually don’t apply affine
transform.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_features</strong> – <img class="math" src="_images/math/4db5b6e16e06f929ce3f675c5e535d06ffb02ff7.svg" alt="C"/> from an expected input of size
<img class="math" src="_images/math/98ea75cf626098a1b65ba3d34a365f6b32e5f8a8.svg" alt="(N, C, D, H, W)"/></p></li>
<li><p><strong>eps</strong> – a value added to the denominator for numerical stability. Default: 1e-5</p></li>
<li><p><strong>momentum</strong> – the value used for the running_mean and running_var computation. Default: 0.1</p></li>
<li><p><strong>affine</strong> – a boolean value that when set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, this module has
learnable affine parameters, initialized the same way as done for batch normalization.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>track_running_stats</strong> – a boolean value that when set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, this
module tracks the running mean and variance, and when set to <code class="docutils literal notranslate"><span class="pre">False</span></code>,
this module does not track such statistics and always uses batch
statistics in both training and eval modes. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/98ea75cf626098a1b65ba3d34a365f6b32e5f8a8.svg" alt="(N, C, D, H, W)"/></p></li>
<li><p>Output: <img class="math" src="_images/math/98ea75cf626098a1b65ba3d34a365f6b32e5f8a8.svg" alt="(N, C, D, H, W)"/> (same shape as input)</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># Without Learnable Parameters</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm3d</span><span class="p">(</span><span class="mi">100</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># With Learnable Parameters</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">InstanceNorm3d</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">affine</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">35</span><span class="p">,</span> <span class="mi">45</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="layernorm">
<h3><span class="hidden-section">LayerNorm</span><a class="headerlink" href="#layernorm" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.LayerNorm">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">LayerNorm</code><span class="sig-paren">(</span><em class="sig-param">normalized_shape</em>, <em class="sig-param">eps=1e-05</em>, <em class="sig-param">elementwise_affine=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/normalization.html#LayerNorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.LayerNorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies Layer Normalization over a mini-batch of inputs as described in
the paper <a class="reference external" href="https://arxiv.org/abs/1607.06450">Layer Normalization</a> .</p>
<div class="math">
<p><img src="_images/math/ee5c3fdc91f720726c2fcd656cdc487f98a15829.svg" alt="y = \frac{x - \mathrm{E}[x]}{ \sqrt{\mathrm{Var}[x] + \epsilon}} * \gamma + \beta"/></p>
</div><p>The mean and standard-deviation are calculated separately over the last
certain number dimensions which have to be of the shape specified by
<code class="xref py py-attr docutils literal notranslate"><span class="pre">normalized_shape</span></code>.
<img class="math" src="_images/math/34d137cf01c787ecda732761c3f95b0f65a6c3e9.svg" alt="\gamma"/> and <img class="math" src="_images/math/7138dad9ac96835665b17f5817eacfcaa9b834c9.svg" alt="\beta"/> are learnable affine transform parameters of
<code class="xref py py-attr docutils literal notranslate"><span class="pre">normalized_shape</span></code> if <code class="xref py py-attr docutils literal notranslate"><span class="pre">elementwise_affine</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Unlike Batch Normalization and Instance Normalization, which applies
scalar scale and bias for each entire channel/plane with the
<code class="xref py py-attr docutils literal notranslate"><span class="pre">affine</span></code> option, Layer Normalization applies per-element scale and
bias with <code class="xref py py-attr docutils literal notranslate"><span class="pre">elementwise_affine</span></code>.</p>
</div>
<p>This layer uses statistics computed from input data in both training and
evaluation modes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>normalized_shape</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.7)"><em>list</em></a><em> or </em><em>torch.Size</em>) – <p>input shape from an expected input
of size</p>
<div class="math">
<p><img src="_images/math/1e8ce1cd922e9ea84204df221a1dc4515078a86b.svg" alt="[* \times \text{normalized\_shape}[0] \times \text{normalized\_shape}[1]
    \times \ldots \times \text{normalized\_shape}[-1]]"/></p>
</div><p>If a single integer is used, it is treated as a singleton list, and this module will
normalize over the last dimension which is expected to be of that specific size.</p>
</p></li>
<li><p><strong>eps</strong> – a value added to the denominator for numerical stability. Default: 1e-5</p></li>
<li><p><strong>elementwise_affine</strong> – a boolean value that when set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, this module
has learnable per-element affine parameters initialized to ones (for weights)
and zeros (for biases). Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/></p></li>
<li><p>Output: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/> (same shape as input)</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># With Learnable Parameters</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="nb">input</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">1</span><span class="p">:])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Without Learnable Parameters</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="nb">input</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">1</span><span class="p">:],</span> <span class="n">elementwise_affine</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Normalize over last two dimensions</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Normalize over last dimension of size 10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Activating the module</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="localresponsenorm">
<h3><span class="hidden-section">LocalResponseNorm</span><a class="headerlink" href="#localresponsenorm" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.LocalResponseNorm">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">LocalResponseNorm</code><span class="sig-paren">(</span><em class="sig-param">size</em>, <em class="sig-param">alpha=0.0001</em>, <em class="sig-param">beta=0.75</em>, <em class="sig-param">k=1.0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/normalization.html#LocalResponseNorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.LocalResponseNorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies local response normalization over an input signal composed
of several input planes, where channels occupy the second dimension.
Applies normalization across channels.</p>
<div class="math">
<p><img src="_images/math/a1ae50dfee3411b5bab76fcbcb89795a83bd984d.svg" alt="b_{c} = a_{c}\left(k + \frac{\alpha}{n}
\sum_{c'=\max(0, c-n/2)}^{\min(N-1,c+n/2)}a_{c'}^2\right)^{-\beta}"/></p>
</div><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> – amount of neighbouring channels used for normalization</p></li>
<li><p><strong>alpha</strong> – multiplicative factor. Default: 0.0001</p></li>
<li><p><strong>beta</strong> – exponent. Default: 0.75</p></li>
<li><p><strong>k</strong> – additive factor. Default: 1</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/075615abf7466dfa600630602ad19a424154bc93.svg" alt="(N, C, *)"/></p></li>
<li><p>Output: <img class="math" src="_images/math/075615abf7466dfa600630602ad19a424154bc93.svg" alt="(N, C, *)"/> (same shape as input)</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">lrn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LocalResponseNorm</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">signal_2d</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">32</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">24</span><span class="p">,</span> <span class="mi">24</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">signal_4d</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output_2d</span> <span class="o">=</span> <span class="n">lrn</span><span class="p">(</span><span class="n">signal_2d</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output_4d</span> <span class="o">=</span> <span class="n">lrn</span><span class="p">(</span><span class="n">signal_4d</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
</div>
<div class="section" id="recurrent-layers">
<h2>Recurrent layers<a class="headerlink" href="#recurrent-layers" title="Permalink to this headline">¶</a></h2>
<div class="section" id="rnn">
<h3><span class="hidden-section">RNN</span><a class="headerlink" href="#rnn" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.RNN">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">RNN</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/rnn.html#RNN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.RNN" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a multi-layer Elman RNN with <img class="math" src="_images/math/9c3a598b149ed23de86cc7825ffd154a8f2d252f.svg" alt="tanh"/> or <img class="math" src="_images/math/ba378f4656e0a62ae7784111ce184e0c8da19b12.svg" alt="ReLU"/> non-linearity to an
input sequence.</p>
<p>For each element in the input sequence, each layer computes the following
function:</p>
<div class="math">
<p><img src="_images/math/3515c999300da9e1cee9aa875e347ef1881104d2.svg" alt="h_t = \text{tanh}(W_{ih} x_t + b_{ih} + W_{hh} h_{(t-1)} + b_{hh})"/></p>
</div><p>where <img class="math" src="_images/math/bc2c8745fbef9a05addc786a4cb65718655d0cb9.svg" alt="h_t"/> is the hidden state at time <cite>t</cite>, <img class="math" src="_images/math/8f3c6b529aaa515fdbc6c51b4fc4f73293dbfc09.svg" alt="x_t"/> is
the input at time <cite>t</cite>, and <img class="math" src="_images/math/8224cdfde9bee5beda30cceb02e10949a68ccf81.svg" alt="h_{(t-1)}"/> is the hidden state of the
previous layer at time <cite>t-1</cite> or the initial hidden state at time <cite>0</cite>.
If <code class="xref py py-attr docutils literal notranslate"><span class="pre">nonlinearity</span></code> is <code class="docutils literal notranslate"><span class="pre">'relu'</span></code>, then <cite>ReLU</cite> is used instead of <cite>tanh</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – The number of expected features in the input <cite>x</cite></p></li>
<li><p><strong>hidden_size</strong> – The number of features in the hidden state <cite>h</cite></p></li>
<li><p><strong>num_layers</strong> – Number of recurrent layers. E.g., setting <code class="docutils literal notranslate"><span class="pre">num_layers=2</span></code>
would mean stacking two RNNs together to form a <cite>stacked RNN</cite>,
with the second RNN taking in outputs of the first RNN and
computing the final results. Default: 1</p></li>
<li><p><strong>nonlinearity</strong> – The non-linearity to use. Can be either <code class="docutils literal notranslate"><span class="pre">'tanh'</span></code> or <code class="docutils literal notranslate"><span class="pre">'relu'</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">'tanh'</span></code></p></li>
<li><p><strong>bias</strong> – If <code class="docutils literal notranslate"><span class="pre">False</span></code>, then the layer does not use bias weights <cite>b_ih</cite> and <cite>b_hh</cite>.
Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>batch_first</strong> – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, then the input and output tensors are provided
as <cite>(batch, seq, feature)</cite>. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>dropout</strong> – If non-zero, introduces a <cite>Dropout</cite> layer on the outputs of each
RNN layer except the last layer, with dropout probability equal to
<code class="xref py py-attr docutils literal notranslate"><span class="pre">dropout</span></code>. Default: 0</p></li>
<li><p><strong>bidirectional</strong> – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, becomes a bidirectional RNN. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Inputs: input, h_0</dt><dd><ul class="simple">
<li><p><strong>input</strong> of shape <cite>(seq_len, batch, input_size)</cite>: tensor containing the features
of the input sequence. The input can also be a packed variable length
sequence. See <a class="reference internal" href="#torch.nn.utils.rnn.pack_padded_sequence" title="torch.nn.utils.rnn.pack_padded_sequence"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.nn.utils.rnn.pack_padded_sequence()</span></code></a>
or <a class="reference internal" href="#torch.nn.utils.rnn.pack_sequence" title="torch.nn.utils.rnn.pack_sequence"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.nn.utils.rnn.pack_sequence()</span></code></a>
for details.</p></li>
<li><p><strong>h_0</strong> of shape <cite>(num_layers * num_directions, batch, hidden_size)</cite>: tensor
containing the initial hidden state for each element in the batch.
Defaults to zero if not provided. If the RNN is bidirectional,
num_directions should be 2, else it should be 1.</p></li>
</ul>
</dd>
<dt>Outputs: output, h_n</dt><dd><ul>
<li><p><strong>output</strong> of shape <cite>(seq_len, batch, num_directions * hidden_size)</cite>: tensor
containing the output features (<cite>h_t</cite>) from the last layer of the RNN,
for each <cite>t</cite>.  If a <a class="reference internal" href="#torch.nn.utils.rnn.PackedSequence" title="torch.nn.utils.rnn.PackedSequence"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.utils.rnn.PackedSequence</span></code></a> has
been given as the input, the output will also be a packed sequence.</p>
<p>For the unpacked case, the directions can be separated
using <code class="docutils literal notranslate"><span class="pre">output.view(seq_len,</span> <span class="pre">batch,</span> <span class="pre">num_directions,</span> <span class="pre">hidden_size)</span></code>,
with forward and backward being direction <cite>0</cite> and <cite>1</cite> respectively.
Similarly, the directions can be separated in the packed case.</p>
</li>
<li><p><strong>h_n</strong> of shape <cite>(num_layers * num_directions, batch, hidden_size)</cite>: tensor
containing the hidden state for <cite>t = seq_len</cite>.</p>
<p>Like <em>output</em>, the layers can be separated using
<code class="docutils literal notranslate"><span class="pre">h_n.view(num_layers,</span> <span class="pre">num_directions,</span> <span class="pre">batch,</span> <span class="pre">hidden_size)</span></code>.</p>
</li>
</ul>
</dd>
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input1: <img class="math" src="_images/math/1fe90d6e0f86b897bc8f589909910d99df462b41.svg" alt="(L, N, H_{in})"/> tensor containing input features where
<img class="math" src="_images/math/327f1634e51f8d41a91cf78cd72b8006130562d7.svg" alt="H_{in}=\text{input\_size}"/> and <cite>L</cite> represents a sequence length.</p></li>
<li><p>Input2: <img class="math" src="_images/math/0a7c48c9c99a6856b24d486ce42bdb765ae60c7e.svg" alt="(S, N, H_{out})"/> tensor
containing the initial hidden state for each element in the batch.
<img class="math" src="_images/math/2ddc888cee1922bf593aad40fb6ff3690a88b48b.svg" alt="H_{out}=\text{hidden\_size}"/>
Defaults to zero if not provided. where <img class="math" src="_images/math/55425604fc72c07df1f6ee3245afde75e945f1fe.svg" alt="S=\text{num\_layers} * \text{num\_directions}"/>
If the RNN is bidirectional, num_directions should be 2, else it should be 1.</p></li>
<li><p>Output1: <img class="math" src="_images/math/b8002a4b9a86e5279ef01e6c306360388bc4352a.svg" alt="(L, N, H_{all})"/> where <img class="math" src="_images/math/f1b36eb7e8fa5d79eecea08ec1c4764d01ee847d.svg" alt="H_{all}=\text{num\_directions} * \text{hidden\_size}"/></p></li>
<li><p>Output2: <img class="math" src="_images/math/0a7c48c9c99a6856b24d486ce42bdb765ae60c7e.svg" alt="(S, N, H_{out})"/> tensor containing the next hidden state
for each element in the batch</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>~RNN.weight_ih_l[k]</strong> – the learnable input-hidden weights of the k-th layer,
of shape <cite>(hidden_size, input_size)</cite> for <cite>k = 0</cite>. Otherwise, the shape is
<cite>(hidden_size, num_directions * hidden_size)</cite></p></li>
<li><p><strong>~RNN.weight_hh_l[k]</strong> – the learnable hidden-hidden weights of the k-th layer,
of shape <cite>(hidden_size, hidden_size)</cite></p></li>
<li><p><strong>~RNN.bias_ih_l[k]</strong> – the learnable input-hidden bias of the k-th layer,
of shape <cite>(hidden_size)</cite></p></li>
<li><p><strong>~RNN.bias_hh_l[k]</strong> – the learnable hidden-hidden bias of the k-th layer,
of shape <cite>(hidden_size)</cite></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All the weights and biases are initialized from <img class="math" src="_images/math/c4acd08f3a59fa0f26605b209d8e6882cffb6300.svg" alt="\mathcal{U}(-\sqrt{k}, \sqrt{k})"/>
where <img class="math" src="_images/math/0161b8617e7795ff2dd36af6fd6e67e2f0a853af.svg" alt="k = \frac{1}{\text{hidden\_size}}"/></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the following conditions are satisfied:
1) cudnn is enabled,
2) input data is on the GPU
3) input data has dtype <code class="docutils literal notranslate"><span class="pre">torch.float16</span></code>
4) V100 GPU is used,
5) input data is not in <code class="docutils literal notranslate"><span class="pre">PackedSequence</span></code> format
persistent algorithm can be selected to improve performance.</p>
</div>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">h0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="n">rnn</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">h0</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="lstm">
<h3><span class="hidden-section">LSTM</span><a class="headerlink" href="#lstm" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.LSTM">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">LSTM</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/rnn.html#LSTM"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.LSTM" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a multi-layer long short-term memory (LSTM) RNN to an input
sequence.</p>
<p>For each element in the input sequence, each layer computes the following
function:</p>
<div class="math">
<p><img src="_images/math/8edee0066c2bf0382fb5b1327f6ad78cbbdf3632.svg" alt="\begin{array}{ll} \\
    i_t = \sigma(W_{ii} x_t + b_{ii} + W_{hi} h_{(t-1)} + b_{hi}) \\
    f_t = \sigma(W_{if} x_t + b_{if} + W_{hf} h_{(t-1)} + b_{hf}) \\
    g_t = \tanh(W_{ig} x_t + b_{ig} + W_{hg} h_{(t-1)} + b_{hg}) \\
    o_t = \sigma(W_{io} x_t + b_{io} + W_{ho} h_{(t-1)} + b_{ho}) \\
    c_t = f_t * c_{(t-1)} + i_t * g_t \\
    h_t = o_t * \tanh(c_t) \\
\end{array}"/></p>
</div><p>where <img class="math" src="_images/math/bc2c8745fbef9a05addc786a4cb65718655d0cb9.svg" alt="h_t"/> is the hidden state at time <cite>t</cite>, <img class="math" src="_images/math/fa4d0eb07934fe149c235c897da698a2d03bb38f.svg" alt="c_t"/> is the cell
state at time <cite>t</cite>, <img class="math" src="_images/math/8f3c6b529aaa515fdbc6c51b4fc4f73293dbfc09.svg" alt="x_t"/> is the input at time <cite>t</cite>, <img class="math" src="_images/math/8224cdfde9bee5beda30cceb02e10949a68ccf81.svg" alt="h_{(t-1)}"/>
is the hidden state of the layer at time <cite>t-1</cite> or the initial hidden
state at time <cite>0</cite>, and <img class="math" src="_images/math/58adea7f5964619f5156b3c6eb68d8d9ecade706.svg" alt="i_t"/>, <img class="math" src="_images/math/5fc6668c12965b671cba16a6499d9caec6b6907f.svg" alt="f_t"/>, <img class="math" src="_images/math/f70bb007c194617abdd0e3c86c6dd27a8ac32359.svg" alt="g_t"/>,
<img class="math" src="_images/math/e72f71794d593249aa183cbdf3e7a47fb8298c77.svg" alt="o_t"/> are the input, forget, cell, and output gates, respectively.
<img class="math" src="_images/math/b52df27bfb0b1e3af0c2c68a7b9da459178c2a7d.svg" alt="\sigma"/> is the sigmoid function, and <img class="math" src="_images/math/520a99913b8ff14daccff07aa63cdb8d6583e0fc.svg" alt="*"/> is the Hadamard product.</p>
<p>In a multilayer LSTM, the input <img class="math" src="_images/math/718da9c7e8f8b8368fab2078d1a4c5385abc2cba.svg" alt="x^{(l)}_t"/> of the <img class="math" src="_images/math/470aa65888a2971c9346e573f12b37ea406b8ec9.svg" alt="l"/> -th layer
(<img class="math" src="_images/math/53d0a2733bfbfd45d4b06f8688ffbc154c9f5194.svg" alt="l &gt;= 2"/>) is the hidden state <img class="math" src="_images/math/ee875758aa6382912befb137cf70fddfb84d6e81.svg" alt="h^{(l-1)}_t"/> of the previous layer multiplied by
dropout <img class="math" src="_images/math/f990d1fb521d511dd13e99327add877eb76ba9fb.svg" alt="\delta^{(l-1)}_t"/> where each <img class="math" src="_images/math/f990d1fb521d511dd13e99327add877eb76ba9fb.svg" alt="\delta^{(l-1)}_t"/> is a Bernoulli random
variable which is <img class="math" src="_images/math/31fdf41b39df23c95e52c5aef07f59d9adf82f3c.svg" alt="0"/> with probability <code class="xref py py-attr docutils literal notranslate"><span class="pre">dropout</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – The number of expected features in the input <cite>x</cite></p></li>
<li><p><strong>hidden_size</strong> – The number of features in the hidden state <cite>h</cite></p></li>
<li><p><strong>num_layers</strong> – Number of recurrent layers. E.g., setting <code class="docutils literal notranslate"><span class="pre">num_layers=2</span></code>
would mean stacking two LSTMs together to form a <cite>stacked LSTM</cite>,
with the second LSTM taking in outputs of the first LSTM and
computing the final results. Default: 1</p></li>
<li><p><strong>bias</strong> – If <code class="docutils literal notranslate"><span class="pre">False</span></code>, then the layer does not use bias weights <cite>b_ih</cite> and <cite>b_hh</cite>.
Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>batch_first</strong> – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, then the input and output tensors are provided
as (batch, seq, feature). Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>dropout</strong> – If non-zero, introduces a <cite>Dropout</cite> layer on the outputs of each
LSTM layer except the last layer, with dropout probability equal to
<code class="xref py py-attr docutils literal notranslate"><span class="pre">dropout</span></code>. Default: 0</p></li>
<li><p><strong>bidirectional</strong> – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, becomes a bidirectional LSTM. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Inputs: input, (h_0, c_0)</dt><dd><ul>
<li><p><strong>input</strong> of shape <cite>(seq_len, batch, input_size)</cite>: tensor containing the features
of the input sequence.
The input can also be a packed variable length sequence.
See <a class="reference internal" href="#torch.nn.utils.rnn.pack_padded_sequence" title="torch.nn.utils.rnn.pack_padded_sequence"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.nn.utils.rnn.pack_padded_sequence()</span></code></a> or
<a class="reference internal" href="#torch.nn.utils.rnn.pack_sequence" title="torch.nn.utils.rnn.pack_sequence"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.nn.utils.rnn.pack_sequence()</span></code></a> for details.</p></li>
<li><p><strong>h_0</strong> of shape <cite>(num_layers * num_directions, batch, hidden_size)</cite>: tensor
containing the initial hidden state for each element in the batch.
If the LSTM is bidirectional, num_directions should be 2, else it should be 1.</p></li>
<li><p><strong>c_0</strong> of shape <cite>(num_layers * num_directions, batch, hidden_size)</cite>: tensor
containing the initial cell state for each element in the batch.</p>
<p>If <cite>(h_0, c_0)</cite> is not provided, both <strong>h_0</strong> and <strong>c_0</strong> default to zero.</p>
</li>
</ul>
</dd>
<dt>Outputs: output, (h_n, c_n)</dt><dd><ul>
<li><p><strong>output</strong> of shape <cite>(seq_len, batch, num_directions * hidden_size)</cite>: tensor
containing the output features <cite>(h_t)</cite> from the last layer of the LSTM,
for each <cite>t</cite>. If a <a class="reference internal" href="#torch.nn.utils.rnn.PackedSequence" title="torch.nn.utils.rnn.PackedSequence"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.utils.rnn.PackedSequence</span></code></a> has been
given as the input, the output will also be a packed sequence.</p>
<p>For the unpacked case, the directions can be separated
using <code class="docutils literal notranslate"><span class="pre">output.view(seq_len,</span> <span class="pre">batch,</span> <span class="pre">num_directions,</span> <span class="pre">hidden_size)</span></code>,
with forward and backward being direction <cite>0</cite> and <cite>1</cite> respectively.
Similarly, the directions can be separated in the packed case.</p>
</li>
<li><p><strong>h_n</strong> of shape <cite>(num_layers * num_directions, batch, hidden_size)</cite>: tensor
containing the hidden state for <cite>t = seq_len</cite>.</p>
<p>Like <em>output</em>, the layers can be separated using
<code class="docutils literal notranslate"><span class="pre">h_n.view(num_layers,</span> <span class="pre">num_directions,</span> <span class="pre">batch,</span> <span class="pre">hidden_size)</span></code> and similarly for <em>c_n</em>.</p>
</li>
<li><p><strong>c_n</strong> of shape <cite>(num_layers * num_directions, batch, hidden_size)</cite>: tensor
containing the cell state for <cite>t = seq_len</cite>.</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>~LSTM.weight_ih_l[k]</strong> – the learnable input-hidden weights of the <img class="math" src="_images/math/81f68bee5fd62b35c367250cd1513698797c2cf2.svg" alt="\text{k}^{th}"/> layer
<cite>(W_ii|W_if|W_ig|W_io)</cite>, of shape <cite>(4*hidden_size, input_size)</cite> for <cite>k = 0</cite>.
Otherwise, the shape is <cite>(4*hidden_size, num_directions * hidden_size)</cite></p></li>
<li><p><strong>~LSTM.weight_hh_l[k]</strong> – the learnable hidden-hidden weights of the <img class="math" src="_images/math/81f68bee5fd62b35c367250cd1513698797c2cf2.svg" alt="\text{k}^{th}"/> layer
<cite>(W_hi|W_hf|W_hg|W_ho)</cite>, of shape <cite>(4*hidden_size, hidden_size)</cite></p></li>
<li><p><strong>~LSTM.bias_ih_l[k]</strong> – the learnable input-hidden bias of the <img class="math" src="_images/math/81f68bee5fd62b35c367250cd1513698797c2cf2.svg" alt="\text{k}^{th}"/> layer
<cite>(b_ii|b_if|b_ig|b_io)</cite>, of shape <cite>(4*hidden_size)</cite></p></li>
<li><p><strong>~LSTM.bias_hh_l[k]</strong> – the learnable hidden-hidden bias of the <img class="math" src="_images/math/81f68bee5fd62b35c367250cd1513698797c2cf2.svg" alt="\text{k}^{th}"/> layer
<cite>(b_hi|b_hf|b_hg|b_ho)</cite>, of shape <cite>(4*hidden_size)</cite></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All the weights and biases are initialized from <img class="math" src="_images/math/c4acd08f3a59fa0f26605b209d8e6882cffb6300.svg" alt="\mathcal{U}(-\sqrt{k}, \sqrt{k})"/>
where <img class="math" src="_images/math/0161b8617e7795ff2dd36af6fd6e67e2f0a853af.svg" alt="k = \frac{1}{\text{hidden\_size}}"/></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the following conditions are satisfied:
1) cudnn is enabled,
2) input data is on the GPU
3) input data has dtype <code class="docutils literal notranslate"><span class="pre">torch.float16</span></code>
4) V100 GPU is used,
5) input data is not in <code class="docutils literal notranslate"><span class="pre">PackedSequence</span></code> format
persistent algorithm can be selected to improve performance.</p>
</div>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">h0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="p">(</span><span class="n">hn</span><span class="p">,</span> <span class="n">cn</span><span class="p">)</span> <span class="o">=</span> <span class="n">rnn</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="p">(</span><span class="n">h0</span><span class="p">,</span> <span class="n">c0</span><span class="p">))</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="gru">
<h3><span class="hidden-section">GRU</span><a class="headerlink" href="#gru" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.GRU">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">GRU</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/rnn.html#GRU"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.GRU" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a multi-layer gated recurrent unit (GRU) RNN to an input sequence.</p>
<p>For each element in the input sequence, each layer computes the following
function:</p>
<div class="math">
<p><img src="_images/math/6bde47151f8c58ccd0a6dc732276ddf5cdf23ae5.svg" alt="\begin{array}{ll}
    r_t = \sigma(W_{ir} x_t + b_{ir} + W_{hr} h_{(t-1)} + b_{hr}) \\
    z_t = \sigma(W_{iz} x_t + b_{iz} + W_{hz} h_{(t-1)} + b_{hz}) \\
    n_t = \tanh(W_{in} x_t + b_{in} + r_t * (W_{hn} h_{(t-1)}+ b_{hn})) \\
    h_t = (1 - z_t) * n_t + z_t * h_{(t-1)}
\end{array}"/></p>
</div><p>where <img class="math" src="_images/math/bc2c8745fbef9a05addc786a4cb65718655d0cb9.svg" alt="h_t"/> is the hidden state at time <cite>t</cite>, <img class="math" src="_images/math/8f3c6b529aaa515fdbc6c51b4fc4f73293dbfc09.svg" alt="x_t"/> is the input
at time <cite>t</cite>, <img class="math" src="_images/math/8224cdfde9bee5beda30cceb02e10949a68ccf81.svg" alt="h_{(t-1)}"/> is the hidden state of the layer
at time <cite>t-1</cite> or the initial hidden state at time <cite>0</cite>, and <img class="math" src="_images/math/e92d0a0db81eb0ed078e9e553863167bf026f303.svg" alt="r_t"/>,
<img class="math" src="_images/math/4c38ca94e0538b85760627179366adff9b54d70c.svg" alt="z_t"/>, <img class="math" src="_images/math/0dae3b16a416a9a9c11e35da12b2be21d2c1cbf1.svg" alt="n_t"/> are the reset, update, and new gates, respectively.
<img class="math" src="_images/math/b52df27bfb0b1e3af0c2c68a7b9da459178c2a7d.svg" alt="\sigma"/> is the sigmoid function, and <img class="math" src="_images/math/520a99913b8ff14daccff07aa63cdb8d6583e0fc.svg" alt="*"/> is the Hadamard product.</p>
<p>In a multilayer GRU, the input <img class="math" src="_images/math/718da9c7e8f8b8368fab2078d1a4c5385abc2cba.svg" alt="x^{(l)}_t"/> of the <img class="math" src="_images/math/470aa65888a2971c9346e573f12b37ea406b8ec9.svg" alt="l"/> -th layer
(<img class="math" src="_images/math/53d0a2733bfbfd45d4b06f8688ffbc154c9f5194.svg" alt="l &gt;= 2"/>) is the hidden state <img class="math" src="_images/math/ee875758aa6382912befb137cf70fddfb84d6e81.svg" alt="h^{(l-1)}_t"/> of the previous layer multiplied by
dropout <img class="math" src="_images/math/f990d1fb521d511dd13e99327add877eb76ba9fb.svg" alt="\delta^{(l-1)}_t"/> where each <img class="math" src="_images/math/f990d1fb521d511dd13e99327add877eb76ba9fb.svg" alt="\delta^{(l-1)}_t"/> is a Bernoulli random
variable which is <img class="math" src="_images/math/31fdf41b39df23c95e52c5aef07f59d9adf82f3c.svg" alt="0"/> with probability <code class="xref py py-attr docutils literal notranslate"><span class="pre">dropout</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – The number of expected features in the input <cite>x</cite></p></li>
<li><p><strong>hidden_size</strong> – The number of features in the hidden state <cite>h</cite></p></li>
<li><p><strong>num_layers</strong> – Number of recurrent layers. E.g., setting <code class="docutils literal notranslate"><span class="pre">num_layers=2</span></code>
would mean stacking two GRUs together to form a <cite>stacked GRU</cite>,
with the second GRU taking in outputs of the first GRU and
computing the final results. Default: 1</p></li>
<li><p><strong>bias</strong> – If <code class="docutils literal notranslate"><span class="pre">False</span></code>, then the layer does not use bias weights <cite>b_ih</cite> and <cite>b_hh</cite>.
Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>batch_first</strong> – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, then the input and output tensors are provided
as (batch, seq, feature). Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
<li><p><strong>dropout</strong> – If non-zero, introduces a <cite>Dropout</cite> layer on the outputs of each
GRU layer except the last layer, with dropout probability equal to
<code class="xref py py-attr docutils literal notranslate"><span class="pre">dropout</span></code>. Default: 0</p></li>
<li><p><strong>bidirectional</strong> – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, becomes a bidirectional GRU. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Inputs: input, h_0</dt><dd><ul class="simple">
<li><p><strong>input</strong> of shape <cite>(seq_len, batch, input_size)</cite>: tensor containing the features
of the input sequence. The input can also be a packed variable length
sequence. See <a class="reference internal" href="#torch.nn.utils.rnn.pack_padded_sequence" title="torch.nn.utils.rnn.pack_padded_sequence"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.nn.utils.rnn.pack_padded_sequence()</span></code></a>
for details.</p></li>
<li><p><strong>h_0</strong> of shape <cite>(num_layers * num_directions, batch, hidden_size)</cite>: tensor
containing the initial hidden state for each element in the batch.
Defaults to zero if not provided. If the RNN is bidirectional,
num_directions should be 2, else it should be 1.</p></li>
</ul>
</dd>
<dt>Outputs: output, h_n</dt><dd><ul>
<li><p><strong>output</strong> of shape <cite>(seq_len, batch, num_directions * hidden_size)</cite>: tensor
containing the output features h_t from the last layer of the GRU,
for each <cite>t</cite>. If a <a class="reference internal" href="#torch.nn.utils.rnn.PackedSequence" title="torch.nn.utils.rnn.PackedSequence"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.utils.rnn.PackedSequence</span></code></a> has been
given as the input, the output will also be a packed sequence.
For the unpacked case, the directions can be separated
using <code class="docutils literal notranslate"><span class="pre">output.view(seq_len,</span> <span class="pre">batch,</span> <span class="pre">num_directions,</span> <span class="pre">hidden_size)</span></code>,
with forward and backward being direction <cite>0</cite> and <cite>1</cite> respectively.</p>
<p>Similarly, the directions can be separated in the packed case.</p>
</li>
<li><p><strong>h_n</strong> of shape <cite>(num_layers * num_directions, batch, hidden_size)</cite>: tensor
containing the hidden state for <cite>t = seq_len</cite></p>
<p>Like <em>output</em>, the layers can be separated using
<code class="docutils literal notranslate"><span class="pre">h_n.view(num_layers,</span> <span class="pre">num_directions,</span> <span class="pre">batch,</span> <span class="pre">hidden_size)</span></code>.</p>
</li>
</ul>
</dd>
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input1: <img class="math" src="_images/math/1fe90d6e0f86b897bc8f589909910d99df462b41.svg" alt="(L, N, H_{in})"/> tensor containing input features where
<img class="math" src="_images/math/327f1634e51f8d41a91cf78cd72b8006130562d7.svg" alt="H_{in}=\text{input\_size}"/> and <cite>L</cite> represents a sequence length.</p></li>
<li><p>Input2: <img class="math" src="_images/math/0a7c48c9c99a6856b24d486ce42bdb765ae60c7e.svg" alt="(S, N, H_{out})"/> tensor
containing the initial hidden state for each element in the batch.
<img class="math" src="_images/math/2ddc888cee1922bf593aad40fb6ff3690a88b48b.svg" alt="H_{out}=\text{hidden\_size}"/>
Defaults to zero if not provided. where <img class="math" src="_images/math/55425604fc72c07df1f6ee3245afde75e945f1fe.svg" alt="S=\text{num\_layers} * \text{num\_directions}"/>
If the RNN is bidirectional, num_directions should be 2, else it should be 1.</p></li>
<li><p>Output1: <img class="math" src="_images/math/b8002a4b9a86e5279ef01e6c306360388bc4352a.svg" alt="(L, N, H_{all})"/> where <img class="math" src="_images/math/f1b36eb7e8fa5d79eecea08ec1c4764d01ee847d.svg" alt="H_{all}=\text{num\_directions} * \text{hidden\_size}"/></p></li>
<li><p>Output2: <img class="math" src="_images/math/0a7c48c9c99a6856b24d486ce42bdb765ae60c7e.svg" alt="(S, N, H_{out})"/> tensor containing the next hidden state
for each element in the batch</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>~GRU.weight_ih_l[k]</strong> – the learnable input-hidden weights of the <img class="math" src="_images/math/81f68bee5fd62b35c367250cd1513698797c2cf2.svg" alt="\text{k}^{th}"/> layer
(W_ir|W_iz|W_in), of shape <cite>(3*hidden_size, input_size)</cite> for <cite>k = 0</cite>.
Otherwise, the shape is <cite>(3*hidden_size, num_directions * hidden_size)</cite></p></li>
<li><p><strong>~GRU.weight_hh_l[k]</strong> – the learnable hidden-hidden weights of the <img class="math" src="_images/math/81f68bee5fd62b35c367250cd1513698797c2cf2.svg" alt="\text{k}^{th}"/> layer
(W_hr|W_hz|W_hn), of shape <cite>(3*hidden_size, hidden_size)</cite></p></li>
<li><p><strong>~GRU.bias_ih_l[k]</strong> – the learnable input-hidden bias of the <img class="math" src="_images/math/81f68bee5fd62b35c367250cd1513698797c2cf2.svg" alt="\text{k}^{th}"/> layer
(b_ir|b_iz|b_in), of shape <cite>(3*hidden_size)</cite></p></li>
<li><p><strong>~GRU.bias_hh_l[k]</strong> – the learnable hidden-hidden bias of the <img class="math" src="_images/math/81f68bee5fd62b35c367250cd1513698797c2cf2.svg" alt="\text{k}^{th}"/> layer
(b_hr|b_hz|b_hn), of shape <cite>(3*hidden_size)</cite></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All the weights and biases are initialized from <img class="math" src="_images/math/c4acd08f3a59fa0f26605b209d8e6882cffb6300.svg" alt="\mathcal{U}(-\sqrt{k}, \sqrt{k})"/>
where <img class="math" src="_images/math/0161b8617e7795ff2dd36af6fd6e67e2f0a853af.svg" alt="k = \frac{1}{\text{hidden\_size}}"/></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the following conditions are satisfied:
1) cudnn is enabled,
2) input data is on the GPU
3) input data has dtype <code class="docutils literal notranslate"><span class="pre">torch.float16</span></code>
4) V100 GPU is used,
5) input data is not in <code class="docutils literal notranslate"><span class="pre">PackedSequence</span></code> format
persistent algorithm can be selected to improve performance.</p>
</div>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">h0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="p">,</span> <span class="n">hn</span> <span class="o">=</span> <span class="n">rnn</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">h0</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="rnncell">
<h3><span class="hidden-section">RNNCell</span><a class="headerlink" href="#rnncell" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.RNNCell">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">RNNCell</code><span class="sig-paren">(</span><em class="sig-param">input_size</em>, <em class="sig-param">hidden_size</em>, <em class="sig-param">bias=True</em>, <em class="sig-param">nonlinearity='tanh'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/rnn.html#RNNCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.RNNCell" title="Permalink to this definition">¶</a></dt>
<dd><p>An Elman RNN cell with tanh or ReLU non-linearity.</p>
<div class="math">
<p><img src="_images/math/d4df19ba9e0ca38beacccc02af195db351306507.svg" alt="h' = \tanh(W_{ih} x + b_{ih}  +  W_{hh} h + b_{hh})"/></p>
</div><p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">nonlinearity</span></code> is <cite>‘relu’</cite>, then ReLU is used in place of tanh.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – The number of expected features in the input <cite>x</cite></p></li>
<li><p><strong>hidden_size</strong> – The number of features in the hidden state <cite>h</cite></p></li>
<li><p><strong>bias</strong> – If <code class="docutils literal notranslate"><span class="pre">False</span></code>, then the layer does not use bias weights <cite>b_ih</cite> and <cite>b_hh</cite>.
Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>nonlinearity</strong> – The non-linearity to use. Can be either <code class="docutils literal notranslate"><span class="pre">'tanh'</span></code> or <code class="docutils literal notranslate"><span class="pre">'relu'</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">'tanh'</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs: input, hidden</dt><dd><ul class="simple">
<li><p><strong>input</strong> of shape <cite>(batch, input_size)</cite>: tensor containing input features</p></li>
<li><p><strong>hidden</strong> of shape <cite>(batch, hidden_size)</cite>: tensor containing the initial hidden
state for each element in the batch.
Defaults to zero if not provided.</p></li>
</ul>
</dd>
<dt>Outputs: h’</dt><dd><ul class="simple">
<li><p><strong>h’</strong> of shape <cite>(batch, hidden_size)</cite>: tensor containing the next hidden state
for each element in the batch</p></li>
</ul>
</dd>
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input1: <img class="math" src="_images/math/39ef9429236d09d3f68d89487717608372f33ea4.svg" alt="(N, H_{in})"/> tensor containing input features where
<img class="math" src="_images/math/c4fa86f14bfbf05f1649b531e17b631086018fc2.svg" alt="H_{in}"/> = <cite>input_size</cite></p></li>
<li><p>Input2: <img class="math" src="_images/math/8c500928c24ef4110586551ce83f4c69d55ec22d.svg" alt="(N, H_{out})"/> tensor containing the initial hidden
state for each element in the batch where <img class="math" src="_images/math/b758a99caaa1bbfe1b15461746074d3572394755.svg" alt="H_{out}"/> = <cite>hidden_size</cite>
Defaults to zero if not provided.</p></li>
<li><p>Output: <img class="math" src="_images/math/8c500928c24ef4110586551ce83f4c69d55ec22d.svg" alt="(N, H_{out})"/> tensor containing the next hidden state
for each element in the batch</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>~RNNCell.weight_ih</strong> – the learnable input-hidden weights, of shape
<cite>(hidden_size, input_size)</cite></p></li>
<li><p><strong>~RNNCell.weight_hh</strong> – the learnable hidden-hidden weights, of shape
<cite>(hidden_size, hidden_size)</cite></p></li>
<li><p><strong>~RNNCell.bias_ih</strong> – the learnable input-hidden bias, of shape <cite>(hidden_size)</cite></p></li>
<li><p><strong>~RNNCell.bias_hh</strong> – the learnable hidden-hidden bias, of shape <cite>(hidden_size)</cite></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All the weights and biases are initialized from <img class="math" src="_images/math/c4acd08f3a59fa0f26605b209d8e6882cffb6300.svg" alt="\mathcal{U}(-\sqrt{k}, \sqrt{k})"/>
where <img class="math" src="_images/math/0161b8617e7795ff2dd36af6fd6e67e2f0a853af.svg" alt="k = \frac{1}{\text{hidden\_size}}"/></p>
</div>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">RNNCell</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="p">[]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">):</span>
<span class="go">        hx = rnn(input[i], hx)</span>
<span class="go">        output.append(hx)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="lstmcell">
<h3><span class="hidden-section">LSTMCell</span><a class="headerlink" href="#lstmcell" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.LSTMCell">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">LSTMCell</code><span class="sig-paren">(</span><em class="sig-param">input_size</em>, <em class="sig-param">hidden_size</em>, <em class="sig-param">bias=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/rnn.html#LSTMCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.LSTMCell" title="Permalink to this definition">¶</a></dt>
<dd><p>A long short-term memory (LSTM) cell.</p>
<div class="math">
<p><img src="_images/math/f2617c2828523a051e0f8b6a250e549d743a09fc.svg" alt="\begin{array}{ll}
i = \sigma(W_{ii} x + b_{ii} + W_{hi} h + b_{hi}) \\
f = \sigma(W_{if} x + b_{if} + W_{hf} h + b_{hf}) \\
g = \tanh(W_{ig} x + b_{ig} + W_{hg} h + b_{hg}) \\
o = \sigma(W_{io} x + b_{io} + W_{ho} h + b_{ho}) \\
c' = f * c + i * g \\
h' = o * \tanh(c') \\
\end{array}"/></p>
</div><p>where <img class="math" src="_images/math/b52df27bfb0b1e3af0c2c68a7b9da459178c2a7d.svg" alt="\sigma"/> is the sigmoid function, and <img class="math" src="_images/math/520a99913b8ff14daccff07aa63cdb8d6583e0fc.svg" alt="*"/> is the Hadamard product.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – The number of expected features in the input <cite>x</cite></p></li>
<li><p><strong>hidden_size</strong> – The number of features in the hidden state <cite>h</cite></p></li>
<li><p><strong>bias</strong> – If <code class="docutils literal notranslate"><span class="pre">False</span></code>, then the layer does not use bias weights <cite>b_ih</cite> and
<cite>b_hh</cite>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Inputs: input, (h_0, c_0)</dt><dd><ul>
<li><p><strong>input</strong> of shape <cite>(batch, input_size)</cite>: tensor containing input features</p></li>
<li><p><strong>h_0</strong> of shape <cite>(batch, hidden_size)</cite>: tensor containing the initial hidden
state for each element in the batch.</p></li>
<li><p><strong>c_0</strong> of shape <cite>(batch, hidden_size)</cite>: tensor containing the initial cell state
for each element in the batch.</p>
<p>If <cite>(h_0, c_0)</cite> is not provided, both <strong>h_0</strong> and <strong>c_0</strong> default to zero.</p>
</li>
</ul>
</dd>
<dt>Outputs: (h_1, c_1)</dt><dd><ul class="simple">
<li><p><strong>h_1</strong> of shape <cite>(batch, hidden_size)</cite>: tensor containing the next hidden state
for each element in the batch</p></li>
<li><p><strong>c_1</strong> of shape <cite>(batch, hidden_size)</cite>: tensor containing the next cell state
for each element in the batch</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>~LSTMCell.weight_ih</strong> – the learnable input-hidden weights, of shape
<cite>(4*hidden_size, input_size)</cite></p></li>
<li><p><strong>~LSTMCell.weight_hh</strong> – the learnable hidden-hidden weights, of shape
<cite>(4*hidden_size, hidden_size)</cite></p></li>
<li><p><strong>~LSTMCell.bias_ih</strong> – the learnable input-hidden bias, of shape <cite>(4*hidden_size)</cite></p></li>
<li><p><strong>~LSTMCell.bias_hh</strong> – the learnable hidden-hidden bias, of shape <cite>(4*hidden_size)</cite></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All the weights and biases are initialized from <img class="math" src="_images/math/c4acd08f3a59fa0f26605b209d8e6882cffb6300.svg" alt="\mathcal{U}(-\sqrt{k}, \sqrt{k})"/>
where <img class="math" src="_images/math/0161b8617e7795ff2dd36af6fd6e67e2f0a853af.svg" alt="k = \frac{1}{\text{hidden\_size}}"/></p>
</div>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTMCell</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="p">[]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">):</span>
<span class="go">        hx, cx = rnn(input[i], (hx, cx))</span>
<span class="go">        output.append(hx)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="grucell">
<h3><span class="hidden-section">GRUCell</span><a class="headerlink" href="#grucell" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.GRUCell">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">GRUCell</code><span class="sig-paren">(</span><em class="sig-param">input_size</em>, <em class="sig-param">hidden_size</em>, <em class="sig-param">bias=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/rnn.html#GRUCell"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.GRUCell" title="Permalink to this definition">¶</a></dt>
<dd><p>A gated recurrent unit (GRU) cell</p>
<div class="math">
<p><img src="_images/math/4b8e172dd55641654b07fc1491964a34b941039a.svg" alt="\begin{array}{ll}
r = \sigma(W_{ir} x + b_{ir} + W_{hr} h + b_{hr}) \\
z = \sigma(W_{iz} x + b_{iz} + W_{hz} h + b_{hz}) \\
n = \tanh(W_{in} x + b_{in} + r * (W_{hn} h + b_{hn})) \\
h' = (1 - z) * n + z * h
\end{array}"/></p>
</div><p>where <img class="math" src="_images/math/b52df27bfb0b1e3af0c2c68a7b9da459178c2a7d.svg" alt="\sigma"/> is the sigmoid function, and <img class="math" src="_images/math/520a99913b8ff14daccff07aa63cdb8d6583e0fc.svg" alt="*"/> is the Hadamard product.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> – The number of expected features in the input <cite>x</cite></p></li>
<li><p><strong>hidden_size</strong> – The number of features in the hidden state <cite>h</cite></p></li>
<li><p><strong>bias</strong> – If <code class="docutils literal notranslate"><span class="pre">False</span></code>, then the layer does not use bias weights <cite>b_ih</cite> and
<cite>b_hh</cite>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Inputs: input, hidden</dt><dd><ul class="simple">
<li><p><strong>input</strong> of shape <cite>(batch, input_size)</cite>: tensor containing input features</p></li>
<li><p><strong>hidden</strong> of shape <cite>(batch, hidden_size)</cite>: tensor containing the initial hidden
state for each element in the batch.
Defaults to zero if not provided.</p></li>
</ul>
</dd>
<dt>Outputs: h’</dt><dd><ul class="simple">
<li><p><strong>h’</strong> of shape <cite>(batch, hidden_size)</cite>: tensor containing the next hidden state
for each element in the batch</p></li>
</ul>
</dd>
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input1: <img class="math" src="_images/math/39ef9429236d09d3f68d89487717608372f33ea4.svg" alt="(N, H_{in})"/> tensor containing input features where
<img class="math" src="_images/math/c4fa86f14bfbf05f1649b531e17b631086018fc2.svg" alt="H_{in}"/> = <cite>input_size</cite></p></li>
<li><p>Input2: <img class="math" src="_images/math/8c500928c24ef4110586551ce83f4c69d55ec22d.svg" alt="(N, H_{out})"/> tensor containing the initial hidden
state for each element in the batch where <img class="math" src="_images/math/b758a99caaa1bbfe1b15461746074d3572394755.svg" alt="H_{out}"/> = <cite>hidden_size</cite>
Defaults to zero if not provided.</p></li>
<li><p>Output: <img class="math" src="_images/math/8c500928c24ef4110586551ce83f4c69d55ec22d.svg" alt="(N, H_{out})"/> tensor containing the next hidden state
for each element in the batch</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>~GRUCell.weight_ih</strong> – the learnable input-hidden weights, of shape
<cite>(3*hidden_size, input_size)</cite></p></li>
<li><p><strong>~GRUCell.weight_hh</strong> – the learnable hidden-hidden weights, of shape
<cite>(3*hidden_size, hidden_size)</cite></p></li>
<li><p><strong>~GRUCell.bias_ih</strong> – the learnable input-hidden bias, of shape <cite>(3*hidden_size)</cite></p></li>
<li><p><strong>~GRUCell.bias_hh</strong> – the learnable hidden-hidden bias, of shape <cite>(3*hidden_size)</cite></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All the weights and biases are initialized from <img class="math" src="_images/math/c4acd08f3a59fa0f26605b209d8e6882cffb6300.svg" alt="\mathcal{U}(-\sqrt{k}, \sqrt{k})"/>
where <img class="math" src="_images/math/0161b8617e7795ff2dd36af6fd6e67e2f0a853af.svg" alt="k = \frac{1}{\text{hidden\_size}}"/></p>
</div>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRUCell</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hx</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="p">[]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">):</span>
<span class="go">        hx = rnn(input[i], hx)</span>
<span class="go">        output.append(hx)</span>
</pre></div>
</div>
</dd></dl>

</div>
</div>
<div class="section" id="transformer-layers">
<h2>Transformer layers<a class="headerlink" href="#transformer-layers" title="Permalink to this headline">¶</a></h2>
<div class="section" id="transformer">
<h3><span class="hidden-section">Transformer</span><a class="headerlink" href="#transformer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.Transformer">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">Transformer</code><span class="sig-paren">(</span><em class="sig-param">d_model=512</em>, <em class="sig-param">nhead=8</em>, <em class="sig-param">num_encoder_layers=6</em>, <em class="sig-param">num_decoder_layers=6</em>, <em class="sig-param">dim_feedforward=2048</em>, <em class="sig-param">dropout=0.1</em>, <em class="sig-param">custom_encoder=None</em>, <em class="sig-param">custom_decoder=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/transformer.html#Transformer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Transformer" title="Permalink to this definition">¶</a></dt>
<dd><p>A transformer model. User is able to modify the attributes as needed. The architechture
is based on the paper “Attention Is All You Need”. Ashish Vaswani, Noam Shazeer,
Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and
Illia Polosukhin. 2017. Attention is all you need. In Advances in Neural Information
Processing Systems, pages 6000-6010.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>d_model</strong> – the number of expected features in the encoder/decoder inputs (default=512).</p></li>
<li><p><strong>nhead</strong> – the number of heads in the multiheadattention models (default=8).</p></li>
<li><p><strong>num_encoder_layers</strong> – the number of sub-encoder-layers in the encoder (default=6).</p></li>
<li><p><strong>num_decoder_layers</strong> – the number of sub-decoder-layers in the decoder (default=6).</p></li>
<li><p><strong>dim_feedforward</strong> – the dimension of the feedforward network model (default=2048).</p></li>
<li><p><strong>dropout</strong> – the dropout value (default=0.1).</p></li>
<li><p><strong>custom_encoder</strong> – custom encoder (default=None).</p></li>
<li><p><strong>custom_decoder</strong> – custom decoder (default=None).</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Examples::</dt><dd><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">transformer_model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Transformer</span><span class="p">(</span><span class="n">src_vocab</span><span class="p">,</span> <span class="n">tgt_vocab</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">transformer_model</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Transformer</span><span class="p">(</span><span class="n">src_vocab</span><span class="p">,</span> <span class="n">tgt_vocab</span><span class="p">,</span> <span class="n">nhead</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span> <span class="n">num_encoder_layers</span><span class="o">=</span><span class="mi">12</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<dl class="method">
<dt id="torch.nn.Transformer.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">src</em>, <em class="sig-param">tgt</em>, <em class="sig-param">src_mask=None</em>, <em class="sig-param">tgt_mask=None</em>, <em class="sig-param">memory_mask=None</em>, <em class="sig-param">src_key_padding_mask=None</em>, <em class="sig-param">tgt_key_padding_mask=None</em>, <em class="sig-param">memory_key_padding_mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/transformer.html#Transformer.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Transformer.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Take in and process masked source/target sequences.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>src</strong> – the sequence to the encoder (required).</p></li>
<li><p><strong>tgt</strong> – the sequence to the decoder (required).</p></li>
<li><p><strong>src_mask</strong> – the additive mask for the src sequence (optional).</p></li>
<li><p><strong>tgt_mask</strong> – the additive mask for the tgt sequence (optional).</p></li>
<li><p><strong>memory_mask</strong> – the additive mask for the encoder output (optional).</p></li>
<li><p><strong>src_key_padding_mask</strong> – the ByteTensor mask for src keys per batch (optional).</p></li>
<li><p><strong>tgt_key_padding_mask</strong> – the ByteTensor mask for tgt keys per batch (optional).</p></li>
<li><p><strong>memory_key_padding_mask</strong> – the ByteTensor mask for memory keys per batch (optional).</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul class="simple">
<li><p>src: <img class="math" src="_images/math/903cf91d206b99e3970dd2b86697540b33f96d28.svg" alt="(S, N, E)"/>.</p></li>
<li><p>tgt: <img class="math" src="_images/math/a113f947fda86584c255ff7be9d21a1ddcc31f92.svg" alt="(T, N, E)"/>.</p></li>
<li><p>src_mask: <img class="math" src="_images/math/90e2b2f2d359135d36a8958daefb721fbfff1860.svg" alt="(S, S)"/>.</p></li>
<li><p>tgt_mask: <img class="math" src="_images/math/3e7ffa89ba50ac727c611f238dd0658876f4f29b.svg" alt="(T, T)"/>.</p></li>
<li><p>memory_mask: <img class="math" src="_images/math/bf5ce24d7d9d4fde4176fbc4acd774ad5e93774c.svg" alt="(T, S)"/>.</p></li>
<li><p>src_key_padding_mask: <img class="math" src="_images/math/086c186c4e24812b2ff657326cc5cddbe7f879a3.svg" alt="(N, S)"/>.</p></li>
<li><p>tgt_key_padding_mask: <img class="math" src="_images/math/ab06ed8f7412a86ae93c7811781742a736a9b1ee.svg" alt="(N, T)"/>.</p></li>
<li><p>memory_key_padding_mask: <img class="math" src="_images/math/086c186c4e24812b2ff657326cc5cddbe7f879a3.svg" alt="(N, S)"/>.</p></li>
</ul>
<p>Note: [src/tgt/memory]_mask should be filled with
float(‘-inf’) for the masked positions and float(0.0) else. These masks
ensure that predictions for position i depend only on the unmasked positions
j and are applied identically for each sequence in a batch.
[src/tgt/memory]_key_padding_mask should be a ByteTensor where True values are positions
that should be masked with float(‘-inf’) and False values will be unchanged.
This mask ensures that no information will be taken from position i if
it is masked, and has a separate mask for each sequence in a batch.</p>
<ul class="simple">
<li><p>output: <img class="math" src="_images/math/a113f947fda86584c255ff7be9d21a1ddcc31f92.svg" alt="(T, N, E)"/>.</p></li>
</ul>
<p>Note: Due to the multi-head attention architecture in the transformer model,
the output sequence length of a transformer is same as the input sequence
(i.e. target) length of the decode.</p>
<p>where S is the source sequence length, T is the target sequence length, N is the
batch size, E is the feature number</p>
</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">transformer_model</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">tgt</span><span class="p">,</span> <span class="n">src_mask</span><span class="o">=</span><span class="n">src_mask</span><span class="p">,</span> <span class="n">tgt_mask</span><span class="o">=</span><span class="n">tgt_mask</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="method">
<dt id="torch.nn.Transformer.generate_square_subsequent_mask">
<code class="sig-name descname">generate_square_subsequent_mask</code><span class="sig-paren">(</span><em class="sig-param">sz</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/transformer.html#Transformer.generate_square_subsequent_mask"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Transformer.generate_square_subsequent_mask" title="Permalink to this definition">¶</a></dt>
<dd><p>Generate a square mask for the sequence. The masked positions are filled with float(‘-inf’).
Unmasked positions are filled with float(0.0).</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="transformerencoder">
<h3><span class="hidden-section">TransformerEncoder</span><a class="headerlink" href="#transformerencoder" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.TransformerEncoder">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">TransformerEncoder</code><span class="sig-paren">(</span><em class="sig-param">encoder_layer</em>, <em class="sig-param">num_layers</em>, <em class="sig-param">norm=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/transformer.html#TransformerEncoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.TransformerEncoder" title="Permalink to this definition">¶</a></dt>
<dd><p>TransformerEncoder is a stack of N encoder layers</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>encoder_layer</strong> – an instance of the TransformerEncoderLayer() class (required).</p></li>
<li><p><strong>num_layers</strong> – the number of sub-encoder-layers in the encoder (required).</p></li>
<li><p><strong>norm</strong> – the layer normalization component (optional).</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Examples::</dt><dd><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">encoder_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TransformerEncoderLayer</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">nhead</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">transformer_encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TransformerEncoder</span><span class="p">(</span><span class="n">encoder_layer</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<dl class="method">
<dt id="torch.nn.TransformerEncoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">src</em>, <em class="sig-param">mask=None</em>, <em class="sig-param">src_key_padding_mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/transformer.html#TransformerEncoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.TransformerEncoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Pass the input through the endocder layers in turn.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>src</strong> – the sequnce to the encoder (required).</p></li>
<li><p><strong>mask</strong> – the mask for the src sequence (optional).</p></li>
<li><p><strong>src_key_padding_mask</strong> – the mask for the src keys per batch (optional).</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><p>see the docs in Transformer class.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="transformerdecoder">
<h3><span class="hidden-section">TransformerDecoder</span><a class="headerlink" href="#transformerdecoder" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.TransformerDecoder">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">TransformerDecoder</code><span class="sig-paren">(</span><em class="sig-param">decoder_layer</em>, <em class="sig-param">num_layers</em>, <em class="sig-param">norm=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/transformer.html#TransformerDecoder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.TransformerDecoder" title="Permalink to this definition">¶</a></dt>
<dd><p>TransformerDecoder is a stack of N decoder layers</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>decoder_layer</strong> – an instance of the TransformerDecoderLayer() class (required).</p></li>
<li><p><strong>num_layers</strong> – the number of sub-decoder-layers in the decoder (required).</p></li>
<li><p><strong>norm</strong> – the layer normalization component (optional).</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Examples::</dt><dd><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">decoder_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TransformerDecoderLayer</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">nhead</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">transformer_decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TransformerDecoder</span><span class="p">(</span><span class="n">decoder_layer</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<dl class="method">
<dt id="torch.nn.TransformerDecoder.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">tgt</em>, <em class="sig-param">memory</em>, <em class="sig-param">tgt_mask=None</em>, <em class="sig-param">memory_mask=None</em>, <em class="sig-param">tgt_key_padding_mask=None</em>, <em class="sig-param">memory_key_padding_mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/transformer.html#TransformerDecoder.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.TransformerDecoder.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Pass the inputs (and mask) through the decoder layer in turn.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tgt</strong> – the sequence to the decoder (required).</p></li>
<li><p><strong>memory</strong> – the sequnce from the last layer of the encoder (required).</p></li>
<li><p><strong>tgt_mask</strong> – the mask for the tgt sequence (optional).</p></li>
<li><p><strong>memory_mask</strong> – the mask for the memory sequence (optional).</p></li>
<li><p><strong>tgt_key_padding_mask</strong> – the mask for the tgt keys per batch (optional).</p></li>
<li><p><strong>memory_key_padding_mask</strong> – the mask for the memory keys per batch (optional).</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><p>see the docs in Transformer class.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="transformerencoderlayer">
<h3><span class="hidden-section">TransformerEncoderLayer</span><a class="headerlink" href="#transformerencoderlayer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.TransformerEncoderLayer">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">TransformerEncoderLayer</code><span class="sig-paren">(</span><em class="sig-param">d_model</em>, <em class="sig-param">nhead</em>, <em class="sig-param">dim_feedforward=2048</em>, <em class="sig-param">dropout=0.1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/transformer.html#TransformerEncoderLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.TransformerEncoderLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>TransformerEncoderLayer is made up of self-attn and feedforward network.
This standard encoder layer is based on the paper “Attention Is All You Need”.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,
Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in
Neural Information Processing Systems, pages 6000-6010. Users may modify or implement
in a different way during application.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>d_model</strong> – the number of expected features in the input (required).</p></li>
<li><p><strong>nhead</strong> – the number of heads in the multiheadattention models (required).</p></li>
<li><p><strong>dim_feedforward</strong> – the dimension of the feedforward network model (default=2048).</p></li>
<li><p><strong>dropout</strong> – the dropout value (default=0.1).</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Examples::</dt><dd><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">encoder_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TransformerEncoderLayer</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">nhead</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<dl class="method">
<dt id="torch.nn.TransformerEncoderLayer.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">src</em>, <em class="sig-param">src_mask=None</em>, <em class="sig-param">src_key_padding_mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/transformer.html#TransformerEncoderLayer.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.TransformerEncoderLayer.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Pass the input through the endocder layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>src</strong> – the sequnce to the encoder layer (required).</p></li>
<li><p><strong>src_mask</strong> – the mask for the src sequence (optional).</p></li>
<li><p><strong>src_key_padding_mask</strong> – the mask for the src keys per batch (optional).</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><p>see the docs in Transformer class.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="transformerdecoderlayer">
<h3><span class="hidden-section">TransformerDecoderLayer</span><a class="headerlink" href="#transformerdecoderlayer" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.TransformerDecoderLayer">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">TransformerDecoderLayer</code><span class="sig-paren">(</span><em class="sig-param">d_model</em>, <em class="sig-param">nhead</em>, <em class="sig-param">dim_feedforward=2048</em>, <em class="sig-param">dropout=0.1</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/transformer.html#TransformerDecoderLayer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.TransformerDecoderLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>TransformerDecoderLayer is made up of self-attn, multi-head-attn and feedforward network.
This standard decoder layer is based on the paper “Attention Is All You Need”.
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,
Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in
Neural Information Processing Systems, pages 6000-6010. Users may modify or implement
in a different way during application.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>d_model</strong> – the number of expected features in the input (required).</p></li>
<li><p><strong>nhead</strong> – the number of heads in the multiheadattention models (required).</p></li>
<li><p><strong>dim_feedforward</strong> – the dimension of the feedforward network model (default=2048).</p></li>
<li><p><strong>dropout</strong> – the dropout value (default=0.1).</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Examples::</dt><dd><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">decoder_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TransformerDecoderLayer</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">nhead</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<dl class="method">
<dt id="torch.nn.TransformerDecoderLayer.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">tgt</em>, <em class="sig-param">memory</em>, <em class="sig-param">tgt_mask=None</em>, <em class="sig-param">memory_mask=None</em>, <em class="sig-param">tgt_key_padding_mask=None</em>, <em class="sig-param">memory_key_padding_mask=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/transformer.html#TransformerDecoderLayer.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.TransformerDecoderLayer.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Pass the inputs (and mask) through the decoder layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tgt</strong> – the sequence to the decoder layer (required).</p></li>
<li><p><strong>memory</strong> – the sequnce from the last layer of the encoder (required).</p></li>
<li><p><strong>tgt_mask</strong> – the mask for the tgt sequence (optional).</p></li>
<li><p><strong>memory_mask</strong> – the mask for the memory sequence (optional).</p></li>
<li><p><strong>tgt_key_padding_mask</strong> – the mask for the tgt keys per batch (optional).</p></li>
<li><p><strong>memory_key_padding_mask</strong> – the mask for the memory keys per batch (optional).</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><p>see the docs in Transformer class.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</div>
</div>
<div class="section" id="linear-layers">
<h2>Linear layers<a class="headerlink" href="#linear-layers" title="Permalink to this headline">¶</a></h2>
<div class="section" id="identity">
<h3><span class="hidden-section">Identity</span><a class="headerlink" href="#identity" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.Identity">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">Identity</code><span class="sig-paren">(</span><em class="sig-param">*args</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/linear.html#Identity"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Identity" title="Permalink to this definition">¶</a></dt>
<dd><p>A placeholder identity operator that is argument-insensitive.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>args</strong> – any argument (unused)</p></li>
<li><p><strong>kwargs</strong> – any keyword argument (unused)</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">(</span><span class="mi">54</span><span class="p">,</span> <span class="n">unused_argument1</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">unused_argument2</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">torch.Size([128, 20])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="linear">
<h3><span class="hidden-section">Linear</span><a class="headerlink" href="#linear" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.Linear">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">Linear</code><span class="sig-paren">(</span><em class="sig-param">in_features</em>, <em class="sig-param">out_features</em>, <em class="sig-param">bias=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/linear.html#Linear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Linear" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a linear transformation to the incoming data: <img class="math" src="_images/math/8ac9189e90c7e79fe7d322b676cc0e8ad6d88221.svg" alt="y = xA^T + b"/></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_features</strong> – size of each input sample</p></li>
<li><p><strong>out_features</strong> – size of each output sample</p></li>
<li><p><strong>bias</strong> – If set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, the layer will not learn an additive bias.
Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/fb4a73742b1baf7f603330d2202c170191d51d9e.svg" alt="(N, *, H_{in})"/> where <img class="math" src="_images/math/520a99913b8ff14daccff07aa63cdb8d6583e0fc.svg" alt="*"/> means any number of
additional dimensions and <img class="math" src="_images/math/096da58c48c4b1edf4a2d6f7b3b45fcf077fab89.svg" alt="H_{in} = \text{in\_features}"/></p></li>
<li><p>Output: <img class="math" src="_images/math/07d3729c0c3631f6a7bf8c0c6df0edf21cbfbdb6.svg" alt="(N, *, H_{out})"/> where all but the last dimension
are the same shape as the input and <img class="math" src="_images/math/e8b41996f4878d5693a1089effe8829aec835054.svg" alt="H_{out} = \text{out\_features}"/>.</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>~Linear.weight</strong> – the learnable weights of the module of shape
<img class="math" src="_images/math/86d5c81591a05e951d33497a83c4d3b1bd9aa96f.svg" alt="(\text{out\_features}, \text{in\_features})"/>. The values are
initialized from <img class="math" src="_images/math/c4acd08f3a59fa0f26605b209d8e6882cffb6300.svg" alt="\mathcal{U}(-\sqrt{k}, \sqrt{k})"/>, where
<img class="math" src="_images/math/6dc47806cec018798d5f2419a6753aa5eae36f3c.svg" alt="k = \frac{1}{\text{in\_features}}"/></p></li>
<li><p><strong>~Linear.bias</strong> – the learnable bias of the module of shape <img class="math" src="_images/math/00105ac5a121cd7558127291965caf5b0425217c.svg" alt="(\text{out\_features})"/>.
If <code class="xref py py-attr docutils literal notranslate"><span class="pre">bias</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, the values are initialized from
<img class="math" src="_images/math/c4acd08f3a59fa0f26605b209d8e6882cffb6300.svg" alt="\mathcal{U}(-\sqrt{k}, \sqrt{k})"/> where
<img class="math" src="_images/math/6dc47806cec018798d5f2419a6753aa5eae36f3c.svg" alt="k = \frac{1}{\text{in\_features}}"/></p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">torch.Size([128, 30])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="bilinear">
<h3><span class="hidden-section">Bilinear</span><a class="headerlink" href="#bilinear" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.Bilinear">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">Bilinear</code><span class="sig-paren">(</span><em class="sig-param">in1_features</em>, <em class="sig-param">in2_features</em>, <em class="sig-param">out_features</em>, <em class="sig-param">bias=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/linear.html#Bilinear"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Bilinear" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a bilinear transformation to the incoming data:
<img class="math" src="_images/math/65a2975be99f615bce078fb5bcaed676d5c2c99f.svg" alt="y = x_1 A x_2 + b"/></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in1_features</strong> – size of each first input sample</p></li>
<li><p><strong>in2_features</strong> – size of each second input sample</p></li>
<li><p><strong>out_features</strong> – size of each output sample</p></li>
<li><p><strong>bias</strong> – If set to False, the layer will not learn an additive bias.
Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input1: <img class="math" src="_images/math/51c7885ca738e3c440220189b110730a0493729b.svg" alt="(N, *, H_{in1})"/> where <img class="math" src="_images/math/b896a3caf50eb09905138479868236ad323a8e6c.svg" alt="H_{in1}=\text{in1\_features}"/> and
<img class="math" src="_images/math/520a99913b8ff14daccff07aa63cdb8d6583e0fc.svg" alt="*"/> means any number of additional dimensions. All but the last dimension
of the inputs should be the same.</p></li>
<li><p>Input2: <img class="math" src="_images/math/87ff0c3596cb0527457ce912eaa88510c7503c2c.svg" alt="(N, *, H_{in2})"/> where <img class="math" src="_images/math/a258b86d04b1abb6c376f10d0e7e2b9e7146c165.svg" alt="H_{in2}=\text{in2\_features}"/>.</p></li>
<li><p>Output: <img class="math" src="_images/math/07d3729c0c3631f6a7bf8c0c6df0edf21cbfbdb6.svg" alt="(N, *, H_{out})"/> where <img class="math" src="_images/math/8825ee9bc0f89d1832c1f513b42dfe8ec29d01e7.svg" alt="H_{out}=\text{out\_features}"/>
and all but the last dimension are the same shape as the input.</p></li>
</ul>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>~Bilinear.weight</strong> – the learnable weights of the module of shape
<img class="math" src="_images/math/30abda3b16d183a5dbce42cb801ab3c7cade350a.svg" alt="(\text{out\_features}, \text{in1\_features}, \text{in2\_features})"/>.
The values are initialized from <img class="math" src="_images/math/c4acd08f3a59fa0f26605b209d8e6882cffb6300.svg" alt="\mathcal{U}(-\sqrt{k}, \sqrt{k})"/>, where
<img class="math" src="_images/math/faa5d9240e411c81fc83c6198628375248591bc2.svg" alt="k = \frac{1}{\text{in1\_features}}"/></p></li>
<li><p><strong>~Bilinear.bias</strong> – the learnable bias of the module of shape <img class="math" src="_images/math/00105ac5a121cd7558127291965caf5b0425217c.svg" alt="(\text{out\_features})"/>.
If <code class="xref py py-attr docutils literal notranslate"><span class="pre">bias</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, the values are initialized from
<img class="math" src="_images/math/c4acd08f3a59fa0f26605b209d8e6882cffb6300.svg" alt="\mathcal{U}(-\sqrt{k}, \sqrt{k})"/>, where
<img class="math" src="_images/math/faa5d9240e411c81fc83c6198628375248591bc2.svg" alt="k = \frac{1}{\text{in1\_features}}"/></p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Bilinear</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">40</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">30</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">torch.Size([128, 40])</span>
</pre></div>
</div>
</dd></dl>

</div>
</div>
<div class="section" id="dropout-layers">
<h2>Dropout layers<a class="headerlink" href="#dropout-layers" title="Permalink to this headline">¶</a></h2>
<div class="section" id="dropout">
<h3><span class="hidden-section">Dropout</span><a class="headerlink" href="#dropout" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.Dropout">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">Dropout</code><span class="sig-paren">(</span><em class="sig-param">p=0.5</em>, <em class="sig-param">inplace=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/dropout.html#Dropout"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Dropout" title="Permalink to this definition">¶</a></dt>
<dd><p>During training, randomly zeroes some of the elements of the input
tensor with probability <code class="xref py py-attr docutils literal notranslate"><span class="pre">p</span></code> using samples from a Bernoulli
distribution. Each channel will be zeroed out independently on every forward
call.</p>
<p>This has proven to be an effective technique for regularization and
preventing the co-adaptation of neurons as described in the paper
<a class="reference external" href="https://arxiv.org/abs/1207.0580">Improving neural networks by preventing co-adaptation of feature
detectors</a> .</p>
<p>Furthermore, the outputs are scaled by a factor of <img class="math" src="_images/math/274e33358563ad24e1b53a0313ead3c9446176fb.svg" alt="\frac{1}{1-p}"/> during
training. This means that during evaluation the module simply computes an
identity function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> – probability of an element to be zeroed. Default: 0.5</p></li>
<li><p><strong>inplace</strong> – If set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, will do this operation in-place. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/2de0f5cf89ef2a5e8bd53fbaca25287a386e0784.svg" alt="(*)"/>. Input can be of any shape</p></li>
<li><p>Output: <img class="math" src="_images/math/2de0f5cf89ef2a5e8bd53fbaca25287a386e0784.svg" alt="(*)"/>. Output is of the same shape as input</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="dropout2d">
<h3><span class="hidden-section">Dropout2d</span><a class="headerlink" href="#dropout2d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.Dropout2d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">Dropout2d</code><span class="sig-paren">(</span><em class="sig-param">p=0.5</em>, <em class="sig-param">inplace=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/dropout.html#Dropout2d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Dropout2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Randomly zero out entire channels (a channel is a 2D feature map,
e.g., the <img class="math" src="_images/math/e3fc28292267f066fee7718c64f4bbfece521f24.svg" alt="j"/>-th channel of the <img class="math" src="_images/math/5aa339d4daf45a810dda332e3c80a0698e526e04.svg" alt="i"/>-th sample in the
batched input is a 2D tensor <img class="math" src="_images/math/61c8e30457250fb5145465446a06e9c44e09ba7f.svg" alt="\text{input}[i, j]"/>).
Each channel will be zeroed out independently on every forward call with
probability <code class="xref py py-attr docutils literal notranslate"><span class="pre">p</span></code> using samples from a Bernoulli distribution.</p>
<p>Usually the input comes from <code class="xref py py-class docutils literal notranslate"><span class="pre">nn.Conv2d</span></code> modules.</p>
<p>As described in the paper
<a class="reference external" href="http://arxiv.org/abs/1411.4280">Efficient Object Localization Using Convolutional Networks</a> ,
if adjacent pixels within feature maps are strongly correlated
(as is normally the case in early convolution layers) then i.i.d. dropout
will not regularize the activations and will otherwise just result
in an effective learning rate decrease.</p>
<p>In this case, <code class="xref py py-func docutils literal notranslate"><span class="pre">nn.Dropout2d()</span></code> will help promote independence between
feature maps and should be used instead.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em>) – probability of an element to be zero-ed.</p></li>
<li><p><strong>inplace</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, will do this operation
in-place</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/682f63eaded2237f913167b337a56425e537bdb3.svg" alt="(N, C, H, W)"/></p></li>
<li><p>Output: <img class="math" src="_images/math/682f63eaded2237f913167b337a56425e537bdb3.svg" alt="(N, C, H, W)"/> (same shape as input)</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout2d</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="dropout3d">
<h3><span class="hidden-section">Dropout3d</span><a class="headerlink" href="#dropout3d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.Dropout3d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">Dropout3d</code><span class="sig-paren">(</span><em class="sig-param">p=0.5</em>, <em class="sig-param">inplace=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/dropout.html#Dropout3d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Dropout3d" title="Permalink to this definition">¶</a></dt>
<dd><p>Randomly zero out entire channels (a channel is a 3D feature map,
e.g., the <img class="math" src="_images/math/e3fc28292267f066fee7718c64f4bbfece521f24.svg" alt="j"/>-th channel of the <img class="math" src="_images/math/5aa339d4daf45a810dda332e3c80a0698e526e04.svg" alt="i"/>-th sample in the
batched input is a 3D tensor <img class="math" src="_images/math/61c8e30457250fb5145465446a06e9c44e09ba7f.svg" alt="\text{input}[i, j]"/>).
Each channel will be zeroed out independently on every forward call with
probability <code class="xref py py-attr docutils literal notranslate"><span class="pre">p</span></code> using samples from a Bernoulli distribution.</p>
<p>Usually the input comes from <code class="xref py py-class docutils literal notranslate"><span class="pre">nn.Conv3d</span></code> modules.</p>
<p>As described in the paper
<a class="reference external" href="http://arxiv.org/abs/1411.4280">Efficient Object Localization Using Convolutional Networks</a> ,
if adjacent pixels within feature maps are strongly correlated
(as is normally the case in early convolution layers) then i.i.d. dropout
will not regularize the activations and will otherwise just result
in an effective learning rate decrease.</p>
<p>In this case, <code class="xref py py-func docutils literal notranslate"><span class="pre">nn.Dropout3d()</span></code> will help promote independence between
feature maps and should be used instead.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em>) – probability of an element to be zeroed.</p></li>
<li><p><strong>inplace</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, will do this operation
in-place</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/98ea75cf626098a1b65ba3d34a365f6b32e5f8a8.svg" alt="(N, C, D, H, W)"/></p></li>
<li><p>Output: <img class="math" src="_images/math/98ea75cf626098a1b65ba3d34a365f6b32e5f8a8.svg" alt="(N, C, D, H, W)"/> (same shape as input)</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout3d</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="alphadropout">
<h3><span class="hidden-section">AlphaDropout</span><a class="headerlink" href="#alphadropout" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.AlphaDropout">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">AlphaDropout</code><span class="sig-paren">(</span><em class="sig-param">p=0.5</em>, <em class="sig-param">inplace=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/dropout.html#AlphaDropout"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.AlphaDropout" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies Alpha Dropout over the input.</p>
<p>Alpha Dropout is a type of Dropout that maintains the self-normalizing
property.
For an input with zero mean and unit standard deviation, the output of
Alpha Dropout maintains the original mean and standard deviation of the
input.
Alpha Dropout goes hand-in-hand with SELU activation function, which ensures
that the outputs have zero mean and unit standard deviation.</p>
<p>During training, it randomly masks some of the elements of the input
tensor with probability <em>p</em> using samples from a bernoulli distribution.
The elements to masked are randomized on every forward call, and scaled
and shifted to maintain zero mean and unit standard deviation.</p>
<p>During evaluation the module simply computes an identity function.</p>
<p>More details can be found in the paper <a class="reference external" href="https://arxiv.org/abs/1706.02515">Self-Normalizing Neural Networks</a> .</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – probability of an element to be dropped. Default: 0.5</p></li>
<li><p><strong>inplace</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – If set to <code class="docutils literal notranslate"><span class="pre">True</span></code>, will do this operation
in-place</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/2de0f5cf89ef2a5e8bd53fbaca25287a386e0784.svg" alt="(*)"/>. Input can be of any shape</p></li>
<li><p>Output: <img class="math" src="_images/math/2de0f5cf89ef2a5e8bd53fbaca25287a386e0784.svg" alt="(*)"/>. Output is of the same shape as input</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AlphaDropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">16</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
</div>
<div class="section" id="sparse-layers">
<h2>Sparse layers<a class="headerlink" href="#sparse-layers" title="Permalink to this headline">¶</a></h2>
<div class="section" id="embedding">
<h3><span class="hidden-section">Embedding</span><a class="headerlink" href="#embedding" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.Embedding">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">Embedding</code><span class="sig-paren">(</span><em class="sig-param">num_embeddings</em>, <em class="sig-param">embedding_dim</em>, <em class="sig-param">padding_idx=None</em>, <em class="sig-param">max_norm=None</em>, <em class="sig-param">norm_type=2.0</em>, <em class="sig-param">scale_grad_by_freq=False</em>, <em class="sig-param">sparse=False</em>, <em class="sig-param">_weight=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/sparse.html#Embedding"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Embedding" title="Permalink to this definition">¶</a></dt>
<dd><p>A simple lookup table that stores embeddings of a fixed dictionary and size.</p>
<p>This module is often used to store word embeddings and retrieve them using indices.
The input to the module is a list of indices, and the output is the corresponding
word embeddings.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_embeddings</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – size of the dictionary of embeddings</p></li>
<li><p><strong>embedding_dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – the size of each embedding vector</p></li>
<li><p><strong>padding_idx</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em>) – If given, pads the output with the embedding vector at <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding_idx</span></code>
(initialized to zeros) whenever it encounters the index.</p></li>
<li><p><strong>max_norm</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em>) – If given, each embedding vector with norm larger than <code class="xref py py-attr docutils literal notranslate"><span class="pre">max_norm</span></code>
is renormalized to have norm <code class="xref py py-attr docutils literal notranslate"><span class="pre">max_norm</span></code>.</p></li>
<li><p><strong>norm_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em>) – The p of the p-norm to compute for the <code class="xref py py-attr docutils literal notranslate"><span class="pre">max_norm</span></code> option. Default <code class="docutils literal notranslate"><span class="pre">2</span></code>.</p></li>
<li><p><strong>scale_grad_by_freq</strong> (<em>boolean</em><em>, </em><em>optional</em>) – If given, this will scale gradients by the inverse of frequency of
the words in the mini-batch. Default <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>sparse</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, gradient w.r.t. <code class="xref py py-attr docutils literal notranslate"><span class="pre">weight</span></code> matrix will be a sparse tensor.
See Notes for more details regarding sparse gradients.</p></li>
</ul>
</dd>
<dt class="field-even">Variables</dt>
<dd class="field-even"><p><strong>~Embedding.weight</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – the learnable weights of the module of shape (num_embeddings, embedding_dim)
initialized from <img class="math" src="_images/math/10a6a60db1bd0310f30556a0a3bd6eda70380c12.svg" alt="\mathcal{N}(0, 1)"/></p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/2de0f5cf89ef2a5e8bd53fbaca25287a386e0784.svg" alt="(*)"/>, LongTensor of arbitrary shape containing the indices to extract</p></li>
<li><p>Output: <img class="math" src="_images/math/3cecd3501efab7702eb0436a162cff20f5ceb886.svg" alt="(*, H)"/>, where <cite>*</cite> is the input shape and <img class="math" src="_images/math/ebe5bacb50564c844814f373c98fa89671f0cff0.svg" alt="H=\text{embedding\_dim}"/></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Keep in mind that only a limited number of optimizers support
sparse gradients: currently it’s <code class="xref py py-class docutils literal notranslate"><span class="pre">optim.SGD</span></code> (<cite>CUDA</cite> and <cite>CPU</cite>),
<code class="xref py py-class docutils literal notranslate"><span class="pre">optim.SparseAdam</span></code> (<cite>CUDA</cite> and <cite>CPU</cite>) and <code class="xref py py-class docutils literal notranslate"><span class="pre">optim.Adagrad</span></code> (<cite>CPU</cite>)</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>With <code class="xref py py-attr docutils literal notranslate"><span class="pre">padding_idx</span></code> set, the embedding vector at
<code class="xref py py-attr docutils literal notranslate"><span class="pre">padding_idx</span></code> is initialized to all zeros. However, note that this
vector can be modified afterwards, e.g., using a customized
initialization method, and thus changing the vector used to pad the
output. The gradient for this vector from <a class="reference internal" href="#torch.nn.Embedding" title="torch.nn.Embedding"><code class="xref py py-class docutils literal notranslate"><span class="pre">Embedding</span></code></a>
is always zero.</p>
</div>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># an Embedding module containing 10 tensors of size 3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># a batch of 2 samples of 4 indices each</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">],[</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">9</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">embedding</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[-0.0251, -1.6902,  0.7172],</span>
<span class="go">         [-0.6431,  0.0748,  0.6969],</span>
<span class="go">         [ 1.4970,  1.3448, -0.9685],</span>
<span class="go">         [-0.3677, -2.7265, -0.1685]],</span>

<span class="go">        [[ 1.4970,  1.3448, -0.9685],</span>
<span class="go">         [ 0.4362, -0.4004,  0.9400],</span>
<span class="go">         [-0.6431,  0.0748,  0.6969],</span>
<span class="go">         [ 0.9124, -2.3616,  1.1151]]])</span>


<span class="gp">&gt;&gt;&gt; </span><span class="c1"># example with padding_idx</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">padding_idx</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">5</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">embedding</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[ 0.0000,  0.0000,  0.0000],</span>
<span class="go">         [ 0.1535, -2.0309,  0.9315],</span>
<span class="go">         [ 0.0000,  0.0000,  0.0000],</span>
<span class="go">         [-0.1655,  0.9897,  0.0635]]])</span>
</pre></div>
</div>
<dl class="method">
<dt id="torch.nn.Embedding.from_pretrained">
<em class="property">classmethod </em><code class="sig-name descname">from_pretrained</code><span class="sig-paren">(</span><em class="sig-param">embeddings</em>, <em class="sig-param">freeze=True</em>, <em class="sig-param">padding_idx=None</em>, <em class="sig-param">max_norm=None</em>, <em class="sig-param">norm_type=2.0</em>, <em class="sig-param">scale_grad_by_freq=False</em>, <em class="sig-param">sparse=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/sparse.html#Embedding.from_pretrained"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Embedding.from_pretrained" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates Embedding instance from given 2-dimensional FloatTensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>embeddings</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – FloatTensor containing weights for the Embedding.
First dimension is being passed to Embedding as <code class="docutils literal notranslate"><span class="pre">num_embeddings</span></code>, second as <code class="docutils literal notranslate"><span class="pre">embedding_dim</span></code>.</p></li>
<li><p><strong>freeze</strong> (<em>boolean</em><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, the tensor does not get updated in the learning process.
Equivalent to <code class="docutils literal notranslate"><span class="pre">embedding.weight.requires_grad</span> <span class="pre">=</span> <span class="pre">False</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>padding_idx</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em>) – See module initialization documentation.</p></li>
<li><p><strong>max_norm</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em>) – See module initialization documentation.</p></li>
<li><p><strong>norm_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em>) – See module initialization documentation. Default <code class="docutils literal notranslate"><span class="pre">2</span></code>.</p></li>
<li><p><strong>scale_grad_by_freq</strong> (<em>boolean</em><em>, </em><em>optional</em>) – See module initialization documentation. Default <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>sparse</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – See module initialization documentation.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># FloatTensor containing pretrained weights</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mf">5.1</span><span class="p">,</span> <span class="mf">6.3</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Get embeddings for index 1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">embedding</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[ 4.0000,  5.1000,  6.3000]])</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="embeddingbag">
<h3><span class="hidden-section">EmbeddingBag</span><a class="headerlink" href="#embeddingbag" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.EmbeddingBag">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">EmbeddingBag</code><span class="sig-paren">(</span><em class="sig-param">num_embeddings</em>, <em class="sig-param">embedding_dim</em>, <em class="sig-param">max_norm=None</em>, <em class="sig-param">norm_type=2.0</em>, <em class="sig-param">scale_grad_by_freq=False</em>, <em class="sig-param">mode='mean'</em>, <em class="sig-param">sparse=False</em>, <em class="sig-param">_weight=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/sparse.html#EmbeddingBag"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.EmbeddingBag" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes sums or means of ‘bags’ of embeddings, without instantiating the
intermediate embeddings.</p>
<p>For bags of constant length and no <code class="xref py py-attr docutils literal notranslate"><span class="pre">per_sample_weights</span></code>, this class</p>
<blockquote>
<div><ul class="simple">
<li><p>with <code class="docutils literal notranslate"><span class="pre">mode=&quot;sum&quot;</span></code> is equivalent to <a class="reference internal" href="#torch.nn.Embedding" title="torch.nn.Embedding"><code class="xref py py-class docutils literal notranslate"><span class="pre">Embedding</span></code></a> followed by <code class="docutils literal notranslate"><span class="pre">torch.sum(dim=0)</span></code>,</p></li>
<li><p>with <code class="docutils literal notranslate"><span class="pre">mode=&quot;mean&quot;</span></code> is equivalent to <a class="reference internal" href="#torch.nn.Embedding" title="torch.nn.Embedding"><code class="xref py py-class docutils literal notranslate"><span class="pre">Embedding</span></code></a> followed by <code class="docutils literal notranslate"><span class="pre">torch.mean(dim=0)</span></code>,</p></li>
<li><p>with <code class="docutils literal notranslate"><span class="pre">mode=&quot;max&quot;</span></code> is equivalent to <a class="reference internal" href="#torch.nn.Embedding" title="torch.nn.Embedding"><code class="xref py py-class docutils literal notranslate"><span class="pre">Embedding</span></code></a> followed by <code class="docutils literal notranslate"><span class="pre">torch.max(dim=0)</span></code>.</p></li>
</ul>
</div></blockquote>
<p>However, <a class="reference internal" href="#torch.nn.EmbeddingBag" title="torch.nn.EmbeddingBag"><code class="xref py py-class docutils literal notranslate"><span class="pre">EmbeddingBag</span></code></a> is much more time and memory efficient than using a chain of these
operations.</p>
<p>EmbeddingBag also supports per-sample weights as an argument to the forward
pass. This scales the output of the Embedding before performing a weighted
reduction as specified by <code class="docutils literal notranslate"><span class="pre">mode</span></code>. If <code class="xref py py-attr docutils literal notranslate"><span class="pre">per_sample_weights`</span></code> is passed, the
only supported <code class="docutils literal notranslate"><span class="pre">mode</span></code> is <code class="docutils literal notranslate"><span class="pre">&quot;sum&quot;</span></code>, which computes a weighted sum according to
<code class="xref py py-attr docutils literal notranslate"><span class="pre">per_sample_weights</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>num_embeddings</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – size of the dictionary of embeddings</p></li>
<li><p><strong>embedding_dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – the size of each embedding vector</p></li>
<li><p><strong>max_norm</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em>) – If given, each embedding vector with norm larger than <code class="xref py py-attr docutils literal notranslate"><span class="pre">max_norm</span></code>
is renormalized to have norm <code class="xref py py-attr docutils literal notranslate"><span class="pre">max_norm</span></code>.</p></li>
<li><p><strong>norm_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em>) – The p of the p-norm to compute for the <code class="xref py py-attr docutils literal notranslate"><span class="pre">max_norm</span></code> option. Default <code class="docutils literal notranslate"><span class="pre">2</span></code>.</p></li>
<li><p><strong>scale_grad_by_freq</strong> (<em>boolean</em><em>, </em><em>optional</em>) – if given, this will scale gradients by the inverse of frequency of
the words in the mini-batch. Default <code class="docutils literal notranslate"><span class="pre">False</span></code>.
Note: this option is not supported when <code class="docutils literal notranslate"><span class="pre">mode=&quot;max&quot;</span></code>.</p></li>
<li><p><strong>mode</strong> (<em>string</em><em>, </em><em>optional</em>) – <code class="docutils literal notranslate"><span class="pre">&quot;sum&quot;</span></code>, <code class="docutils literal notranslate"><span class="pre">&quot;mean&quot;</span></code> or <code class="docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code>. Specifies the way to reduce the bag.
<code class="docutils literal notranslate"><span class="pre">&quot;sum&quot;</span></code> computes the weighted sum, taking <code class="xref py py-attr docutils literal notranslate"><span class="pre">per_sample_weights</span></code>
into consideration. <code class="docutils literal notranslate"><span class="pre">&quot;mean&quot;</span></code> computes the average of the values
in the bag, <code class="docutils literal notranslate"><span class="pre">&quot;max&quot;</span></code> computes the max value over each bag.
Default: <code class="docutils literal notranslate"><span class="pre">&quot;mean&quot;</span></code></p></li>
<li><p><strong>sparse</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, gradient w.r.t. <code class="xref py py-attr docutils literal notranslate"><span class="pre">weight</span></code> matrix will be a sparse tensor. See
Notes for more details regarding sparse gradients. Note: this option is not
supported when <code class="docutils literal notranslate"><span class="pre">mode=&quot;max&quot;</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Variables</dt>
<dd class="field-even"><p><strong>~EmbeddingBag.weight</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – the learnable weights of the module of shape <cite>(num_embeddings, embedding_dim)</cite>
initialized from <img class="math" src="_images/math/10a6a60db1bd0310f30556a0a3bd6eda70380c12.svg" alt="\mathcal{N}(0, 1)"/>.</p>
</dd>
</dl>
<dl>
<dt>Inputs: <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> (LongTensor), <code class="xref py py-attr docutils literal notranslate"><span class="pre">offsets</span></code> (LongTensor, optional), and</dt><dd><p><code class="xref py py-attr docutils literal notranslate"><span class="pre">per_index_weights</span></code> (Tensor, optional)</p>
<ul>
<li><p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> is 2D of shape <cite>(B, N)</cite>,</p>
<p>it will be treated as <code class="docutils literal notranslate"><span class="pre">B</span></code> bags (sequences) each of fixed length <code class="docutils literal notranslate"><span class="pre">N</span></code>, and
this will return <code class="docutils literal notranslate"><span class="pre">B</span></code> values aggregated in a way depending on the <code class="xref py py-attr docutils literal notranslate"><span class="pre">mode</span></code>.
<code class="xref py py-attr docutils literal notranslate"><span class="pre">offsets</span></code> is ignored and required to be <code class="docutils literal notranslate"><span class="pre">None</span></code> in this case.</p>
</li>
<li><p>If <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> is 1D of shape <cite>(N)</cite>,</p>
<p>it will be treated as a concatenation of multiple bags (sequences).
<code class="xref py py-attr docutils literal notranslate"><span class="pre">offsets</span></code> is required to be a 1D tensor containing the
starting index positions of each bag in <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code>. Therefore,
for <code class="xref py py-attr docutils literal notranslate"><span class="pre">offsets</span></code> of shape <cite>(B)</cite>, <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> will be viewed as
having <code class="docutils literal notranslate"><span class="pre">B</span></code> bags. Empty bags (i.e., having 0-length) will have
returned vectors filled by zeros.</p>
</li>
</ul>
<dl class="simple">
<dt>per_sample_weights (Tensor, optional): a tensor of float / double weights, or None</dt><dd><p>to indicate all weights should be taken to be <code class="docutils literal notranslate"><span class="pre">1</span></code>. If specified, <code class="xref py py-attr docutils literal notranslate"><span class="pre">per_sample_weights</span></code>
must have exactly the same shape as input and is treated as having the same
<code class="xref py py-attr docutils literal notranslate"><span class="pre">offsets</span></code>, if those are not <code class="docutils literal notranslate"><span class="pre">None</span></code>. Only supported for <code class="docutils literal notranslate"><span class="pre">mode='sum'</span></code>.</p>
</dd>
</dl>
</dd>
</dl>
<p>Output shape: <cite>(B, embedding_dim)</cite></p>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># an Embedding module containing 10 tensors of size 3</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">embedding_sum</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">EmbeddingBag</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;sum&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># a batch of 2 samples of 4 indices each</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">9</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">offsets</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">embedding_sum</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">offsets</span><span class="p">)</span>
<span class="go">tensor([[-0.8861, -5.4350, -0.0523],</span>
<span class="go">        [ 1.1306, -2.5798, -1.0044]])</span>
</pre></div>
</div>
<dl class="method">
<dt id="torch.nn.EmbeddingBag.from_pretrained">
<em class="property">classmethod </em><code class="sig-name descname">from_pretrained</code><span class="sig-paren">(</span><em class="sig-param">embeddings</em>, <em class="sig-param">freeze=True</em>, <em class="sig-param">max_norm=None</em>, <em class="sig-param">norm_type=2.0</em>, <em class="sig-param">scale_grad_by_freq=False</em>, <em class="sig-param">mode='mean'</em>, <em class="sig-param">sparse=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/sparse.html#EmbeddingBag.from_pretrained"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.EmbeddingBag.from_pretrained" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates EmbeddingBag instance from given 2-dimensional FloatTensor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>embeddings</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – FloatTensor containing weights for the EmbeddingBag.
First dimension is being passed to EmbeddingBag as ‘num_embeddings’, second as ‘embedding_dim’.</p></li>
<li><p><strong>freeze</strong> (<em>boolean</em><em>, </em><em>optional</em>) – If <code class="docutils literal notranslate"><span class="pre">True</span></code>, the tensor does not get updated in the learning process.
Equivalent to <code class="docutils literal notranslate"><span class="pre">embeddingbag.weight.requires_grad</span> <span class="pre">=</span> <span class="pre">False</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>max_norm</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em>) – See module initialization documentation. Default: <code class="docutils literal notranslate"><span class="pre">None</span></code></p></li>
<li><p><strong>norm_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em>) – See module initialization documentation. Default <code class="docutils literal notranslate"><span class="pre">2</span></code>.</p></li>
<li><p><strong>scale_grad_by_freq</strong> (<em>boolean</em><em>, </em><em>optional</em>) – See module initialization documentation. Default <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>mode</strong> (<em>string</em><em>, </em><em>optional</em>) – See module initialization documentation. Default: <code class="docutils literal notranslate"><span class="pre">&quot;mean&quot;</span></code></p></li>
<li><p><strong>sparse</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – See module initialization documentation. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># FloatTensor containing pretrained weights</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mf">2.3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mf">5.1</span><span class="p">,</span> <span class="mf">6.3</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">embeddingbag</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">EmbeddingBag</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">weight</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Get embeddings for index 1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">embeddingbag</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[ 2.5000,  3.7000,  4.6500]])</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

</div>
</div>
<div class="section" id="distance-functions">
<h2>Distance functions<a class="headerlink" href="#distance-functions" title="Permalink to this headline">¶</a></h2>
<div class="section" id="cosinesimilarity">
<h3><span class="hidden-section">CosineSimilarity</span><a class="headerlink" href="#cosinesimilarity" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.CosineSimilarity">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">CosineSimilarity</code><span class="sig-paren">(</span><em class="sig-param">dim=1</em>, <em class="sig-param">eps=1e-08</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/distance.html#CosineSimilarity"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.CosineSimilarity" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns cosine similarity between <img class="math" src="_images/math/5ea99039cd8359fa2e14317dbfae4497ebbc1360.svg" alt="x_1"/> and <img class="math" src="_images/math/b7bda214149c6fe0d7c6c494b0c896805bf51262.svg" alt="x_2"/>, computed along dim.</p>
<div class="math">
<p><img src="_images/math/6016560413eb97520798bd75d033a832358107b5.svg" alt="\text{similarity} = \dfrac{x_1 \cdot x_2}{\max(\Vert x_1 \Vert _2 \cdot \Vert x_2 \Vert _2, \epsilon)}."/></p>
</div><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em>) – Dimension where cosine similarity is computed. Default: 1</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em>) – Small value to avoid division by zero.
Default: 1e-8</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input1: <img class="math" src="_images/math/ddca7faf28f7d5052b9e5d8e6630b788d8593512.svg" alt="(\ast_1, D, \ast_2)"/> where D is at position <cite>dim</cite></p></li>
<li><p>Input2: <img class="math" src="_images/math/ddca7faf28f7d5052b9e5d8e6630b788d8593512.svg" alt="(\ast_1, D, \ast_2)"/>, same shape as the Input1</p></li>
<li><p>Output: <img class="math" src="_images/math/a097fe65f3384709f5fdd135715004a30b4f439d.svg" alt="(\ast_1, \ast_2)"/></p></li>
</ul>
</dd>
<dt>Examples::</dt><dd><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cos</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CosineSimilarity</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">cos</span><span class="p">(</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="pairwisedistance">
<h3><span class="hidden-section">PairwiseDistance</span><a class="headerlink" href="#pairwisedistance" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.PairwiseDistance">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">PairwiseDistance</code><span class="sig-paren">(</span><em class="sig-param">p=2.0</em>, <em class="sig-param">eps=1e-06</em>, <em class="sig-param">keepdim=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/distance.html#PairwiseDistance"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.PairwiseDistance" title="Permalink to this definition">¶</a></dt>
<dd><p>Computes the batchwise pairwise distance between vectors <img class="math" src="_images/math/1c74485fdd094fc0242d5a0e1a357dc89527ca7e.svg" alt="v_1"/>, <img class="math" src="_images/math/dce2ee68e8a49072ebdeaa689da6f207bee581ea.svg" alt="v_2"/> using the p-norm:</p>
<div class="math">
<p><img src="_images/math/8e12883dae9bf0f6a054f40e8c23d8da4e3b1327.svg" alt="\Vert x \Vert _p = \left( \sum_{i=1}^n  \vert x_i \vert ^ p \right) ^ {1/p}."/></p>
</div><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<em>real</em>) – the norm degree. Default: 2</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em>) – Small value to avoid division by zero.
Default: 1e-6</p></li>
<li><p><strong>keepdim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Determines whether or not to keep the vector dimension.
Default: False</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input1: <img class="math" src="_images/math/82c436ae5b51139f385d40c4ecddb4572bf8d5c4.svg" alt="(N, D)"/> where <cite>D = vector dimension</cite></p></li>
<li><p>Input2: <img class="math" src="_images/math/82c436ae5b51139f385d40c4ecddb4572bf8d5c4.svg" alt="(N, D)"/>, same shape as the Input1</p></li>
<li><p>Output: <img class="math" src="_images/math/53c49d40851a9450d6838659cff1081c4065b1ce.svg" alt="(N)"/>. If <code class="xref py py-attr docutils literal notranslate"><span class="pre">keepdim</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, then <img class="math" src="_images/math/7230d04c2e9ec09634de7f06b8b4f9f5d0fe8afb.svg" alt="(N, 1)"/>.</p></li>
</ul>
</dd>
<dt>Examples::</dt><dd><div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">pdist</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">PairwiseDistance</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">pdist</span><span class="p">(</span><span class="n">input1</span><span class="p">,</span> <span class="n">input2</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

</div>
</div>
<div class="section" id="loss-functions">
<h2>Loss functions<a class="headerlink" href="#loss-functions" title="Permalink to this headline">¶</a></h2>
<div class="section" id="l1loss">
<h3><span class="hidden-section">L1Loss</span><a class="headerlink" href="#l1loss" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.L1Loss">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">L1Loss</code><span class="sig-paren">(</span><em class="sig-param">size_average=None</em>, <em class="sig-param">reduce=None</em>, <em class="sig-param">reduction='mean'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/loss.html#L1Loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.L1Loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a criterion that measures the mean absolute error (MAE) between each element in
the input <img class="math" src="_images/math/888f7c323ac0341871e867220ae2d76467d74d6e.svg" alt="x"/> and target <img class="math" src="_images/math/1b5e577d6216dca3af7d87aa122a0b9b360d6cb3.svg" alt="y"/>.</p>
<p>The unreduced (i.e. with <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> set to <code class="docutils literal notranslate"><span class="pre">'none'</span></code>) loss can be described as:</p>
<div class="math">
<p><img src="_images/math/e382c9f15689e71363c2ecb163431dec6e10e453.svg" alt="\ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad
l_n = \left| x_n - y_n \right|,"/></p>
</div><p>where <img class="math" src="_images/math/3bfb3a64189a14b2704f4610827762d5e3145114.svg" alt="N"/> is the batch size. If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is not <code class="docutils literal notranslate"><span class="pre">'none'</span></code>
(default <code class="docutils literal notranslate"><span class="pre">'mean'</span></code>), then:</p>
<div class="math">
<p><img src="_images/math/7c6f1f821269ff6a32010c48afb38999beb318a6.svg" alt="\ell(x, y) =
\begin{cases}
    \operatorname{mean}(L), &amp; \text{if reduction} = \text{'mean';}\\
    \operatorname{sum}(L),  &amp; \text{if reduction} = \text{'sum'.}
\end{cases}"/></p>
</div><p><img class="math" src="_images/math/888f7c323ac0341871e867220ae2d76467d74d6e.svg" alt="x"/> and <img class="math" src="_images/math/1b5e577d6216dca3af7d87aa122a0b9b360d6cb3.svg" alt="y"/> are tensors of arbitrary shapes with a total
of <img class="math" src="_images/math/5a939c5280da7202ca4531f175a7780ad5e1f80a.svg" alt="n"/> elements each.</p>
<p>The sum operation still operates over all the elements, and divides by <img class="math" src="_images/math/5a939c5280da7202ca4531f175a7780ad5e1f80a.svg" alt="n"/>.</p>
<p>The division by <img class="math" src="_images/math/5a939c5280da7202ca4531f175a7780ad5e1f80a.svg" alt="n"/> can be avoided if one sets <code class="docutils literal notranslate"><span class="pre">reduction</span> <span class="pre">=</span> <span class="pre">'sum'</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size_average</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>). By default,
the losses are averaged over each loss element in the batch. Note that for
some losses, there are multiple elements per sample. If the field <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>
is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, the losses are instead summed for each minibatch. Ignored
when reduce is <code class="docutils literal notranslate"><span class="pre">False</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>reduce</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>). By default, the
losses are averaged or summed over observations for each minibatch depending
on <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>. When <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code>, returns a loss per
batch element instead and ignores <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>reduction</strong> (<em>string</em><em>, </em><em>optional</em>) – Specifies the reduction to apply to the output:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. <code class="docutils literal notranslate"><span class="pre">'none'</span></code>: no reduction will be applied,
<code class="docutils literal notranslate"><span class="pre">'mean'</span></code>: the sum of the output will be divided by the number of
elements in the output, <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>: the output will be summed. Note: <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>
and <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> are in the process of being deprecated, and in the meantime,
specifying either of those two args will override <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/> where <img class="math" src="_images/math/520a99913b8ff14daccff07aa63cdb8d6583e0fc.svg" alt="*"/> means, any number of additional
dimensions</p></li>
<li><p>Target: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/>, same shape as the input</p></li>
<li><p>Output: scalar. If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <code class="docutils literal notranslate"><span class="pre">'none'</span></code>, then
<img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/>, same shape as the input</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">L1Loss</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="mseloss">
<h3><span class="hidden-section">MSELoss</span><a class="headerlink" href="#mseloss" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.MSELoss">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">MSELoss</code><span class="sig-paren">(</span><em class="sig-param">size_average=None</em>, <em class="sig-param">reduce=None</em>, <em class="sig-param">reduction='mean'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/loss.html#MSELoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.MSELoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a criterion that measures the mean squared error (squared L2 norm) between
each element in the input <img class="math" src="_images/math/888f7c323ac0341871e867220ae2d76467d74d6e.svg" alt="x"/> and target <img class="math" src="_images/math/1b5e577d6216dca3af7d87aa122a0b9b360d6cb3.svg" alt="y"/>.</p>
<p>The unreduced (i.e. with <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> set to <code class="docutils literal notranslate"><span class="pre">'none'</span></code>) loss can be described as:</p>
<div class="math">
<p><img src="_images/math/508ac167b30479bdf64a10ee9eb769d331e4b3e6.svg" alt="\ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad
l_n = \left( x_n - y_n \right)^2,"/></p>
</div><p>where <img class="math" src="_images/math/3bfb3a64189a14b2704f4610827762d5e3145114.svg" alt="N"/> is the batch size. If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is not <code class="docutils literal notranslate"><span class="pre">'none'</span></code>
(default <code class="docutils literal notranslate"><span class="pre">'mean'</span></code>), then:</p>
<div class="math">
<p><img src="_images/math/701d93304cf89ccc6ddeb5090645e84094ee0258.svg" alt="\ell(x, y) =
\begin{cases}
    \operatorname{mean}(L), &amp;  \text{if reduction} = \text{'mean';}\\
    \operatorname{sum}(L),  &amp;  \text{if reduction} = \text{'sum'.}
\end{cases}"/></p>
</div><p><img class="math" src="_images/math/888f7c323ac0341871e867220ae2d76467d74d6e.svg" alt="x"/> and <img class="math" src="_images/math/1b5e577d6216dca3af7d87aa122a0b9b360d6cb3.svg" alt="y"/> are tensors of arbitrary shapes with a total
of <img class="math" src="_images/math/5a939c5280da7202ca4531f175a7780ad5e1f80a.svg" alt="n"/> elements each.</p>
<p>The sum operation still operates over all the elements, and divides by <img class="math" src="_images/math/5a939c5280da7202ca4531f175a7780ad5e1f80a.svg" alt="n"/>.</p>
<p>The division by <img class="math" src="_images/math/5a939c5280da7202ca4531f175a7780ad5e1f80a.svg" alt="n"/> can be avoided if one sets <code class="docutils literal notranslate"><span class="pre">reduction</span> <span class="pre">=</span> <span class="pre">'sum'</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size_average</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>). By default,
the losses are averaged over each loss element in the batch. Note that for
some losses, there are multiple elements per sample. If the field <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>
is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, the losses are instead summed for each minibatch. Ignored
when reduce is <code class="docutils literal notranslate"><span class="pre">False</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>reduce</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>). By default, the
losses are averaged or summed over observations for each minibatch depending
on <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>. When <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code>, returns a loss per
batch element instead and ignores <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>reduction</strong> (<em>string</em><em>, </em><em>optional</em>) – Specifies the reduction to apply to the output:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. <code class="docutils literal notranslate"><span class="pre">'none'</span></code>: no reduction will be applied,
<code class="docutils literal notranslate"><span class="pre">'mean'</span></code>: the sum of the output will be divided by the number of
elements in the output, <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>: the output will be summed. Note: <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>
and <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> are in the process of being deprecated, and in the meantime,
specifying either of those two args will override <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/> where <img class="math" src="_images/math/520a99913b8ff14daccff07aa63cdb8d6583e0fc.svg" alt="*"/> means, any number of additional
dimensions</p></li>
<li><p>Target: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/>, same shape as the input</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="crossentropyloss">
<h3><span class="hidden-section">CrossEntropyLoss</span><a class="headerlink" href="#crossentropyloss" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.CrossEntropyLoss">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">CrossEntropyLoss</code><span class="sig-paren">(</span><em class="sig-param">weight=None</em>, <em class="sig-param">size_average=None</em>, <em class="sig-param">ignore_index=-100</em>, <em class="sig-param">reduce=None</em>, <em class="sig-param">reduction='mean'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/loss.html#CrossEntropyLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.CrossEntropyLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>This criterion combines <code class="xref py py-func docutils literal notranslate"><span class="pre">nn.LogSoftmax()</span></code> and <code class="xref py py-func docutils literal notranslate"><span class="pre">nn.NLLLoss()</span></code> in one single class.</p>
<p>It is useful when training a classification problem with <cite>C</cite> classes.
If provided, the optional argument <code class="xref py py-attr docutils literal notranslate"><span class="pre">weight</span></code> should be a 1D <cite>Tensor</cite>
assigning weight to each of the classes.
This is particularly useful when you have an unbalanced training set.</p>
<p>The <cite>input</cite> is expected to contain raw, unnormalized scores for each class.</p>
<p><cite>input</cite> has to be a Tensor of size either <img class="math" src="_images/math/43eacfc9e7c997cf685df13baf2c66abb6e3bf59.svg" alt="(minibatch, C)"/> or
<img class="math" src="_images/math/328057e8bac7dfa0dc93a7cc62cbc0f9717cc6fd.svg" alt="(minibatch, C, d_1, d_2, ..., d_K)"/>
with <img class="math" src="_images/math/958ad271e79c805e9f757c48d38bb9568bfa403e.svg" alt="K \geq 1"/> for the <cite>K</cite>-dimensional case (described later).</p>
<p>This criterion expects a class index in the range <img class="math" src="_images/math/94035d2a1ecd714e30dd1d758233d4dcb14e6788.svg" alt="[0, C-1]"/> as the
<cite>target</cite> for each value of a 1D tensor of size <cite>minibatch</cite>; if <cite>ignore_index</cite>
is specified, this criterion also accepts this class index (this index may not
necessarily be in the class range).</p>
<p>The loss can be described as:</p>
<div class="math">
<p><img src="_images/math/fcfdfe5edbf56fcd5a3e0dde1354ee29832dffe7.svg" alt="\text{loss}(x, class) = -\log\left(\frac{\exp(x[class])}{\sum_j \exp(x[j])}\right)
               = -x[class] + \log\left(\sum_j \exp(x[j])\right)"/></p>
</div><p>or in the case of the <code class="xref py py-attr docutils literal notranslate"><span class="pre">weight</span></code> argument being specified:</p>
<div class="math">
<p><img src="_images/math/3ad557dc435c1073d18323a826ea58e4324b7f08.svg" alt="\text{loss}(x, class) = weight[class] \left(-x[class] + \log\left(\sum_j \exp(x[j])\right)\right)"/></p>
</div><p>The losses are averaged across observations for each minibatch.</p>
<p>Can also be used for higher dimension inputs, such as 2D images, by providing
an input of size <img class="math" src="_images/math/328057e8bac7dfa0dc93a7cc62cbc0f9717cc6fd.svg" alt="(minibatch, C, d_1, d_2, ..., d_K)"/> with <img class="math" src="_images/math/958ad271e79c805e9f757c48d38bb9568bfa403e.svg" alt="K \geq 1"/>,
where <img class="math" src="_images/math/52ddc0cde6d632f631533173562fe3ca375b1f32.svg" alt="K"/> is the number of dimensions, and a target of appropriate shape
(see below).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>weight</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) – a manual rescaling weight given to each class.
If given, has to be a Tensor of size <cite>C</cite></p></li>
<li><p><strong>size_average</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>). By default,
the losses are averaged over each loss element in the batch. Note that for
some losses, there are multiple elements per sample. If the field <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>
is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, the losses are instead summed for each minibatch. Ignored
when reduce is <code class="docutils literal notranslate"><span class="pre">False</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>ignore_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em>) – Specifies a target value that is ignored
and does not contribute to the input gradient. When <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code> is
<code class="docutils literal notranslate"><span class="pre">True</span></code>, the loss is averaged over non-ignored targets.</p></li>
<li><p><strong>reduce</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>). By default, the
losses are averaged or summed over observations for each minibatch depending
on <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>. When <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code>, returns a loss per
batch element instead and ignores <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>reduction</strong> (<em>string</em><em>, </em><em>optional</em>) – Specifies the reduction to apply to the output:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. <code class="docutils literal notranslate"><span class="pre">'none'</span></code>: no reduction will be applied,
<code class="docutils literal notranslate"><span class="pre">'mean'</span></code>: the sum of the output will be divided by the number of
elements in the output, <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>: the output will be summed. Note: <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>
and <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> are in the process of being deprecated, and in the meantime,
specifying either of those two args will override <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/b1bbd46713f69174c0592644b159895f715a74fa.svg" alt="(N, C)"/> where <cite>C = number of classes</cite>, or
<img class="math" src="_images/math/aa2539e83f3a8dec9fce4f07cc9a0479a047b8ee.svg" alt="(N, C, d_1, d_2, ..., d_K)"/> with <img class="math" src="_images/math/958ad271e79c805e9f757c48d38bb9568bfa403e.svg" alt="K \geq 1"/>
in the case of <cite>K</cite>-dimensional loss.</p></li>
<li><p>Target: <img class="math" src="_images/math/53c49d40851a9450d6838659cff1081c4065b1ce.svg" alt="(N)"/> where each value is <img class="math" src="_images/math/1033fe9240ee5a2e4896ecabebd6e3f79837afd2.svg" alt="0 \leq \text{targets}[i] \leq C-1"/>, or
<img class="math" src="_images/math/58b8cfdf39457f04b5cedd06ff0c7d339e41d002.svg" alt="(N, d_1, d_2, ..., d_K)"/> with <img class="math" src="_images/math/958ad271e79c805e9f757c48d38bb9568bfa403e.svg" alt="K \geq 1"/> in the case of
K-dimensional loss.</p></li>
<li><p>Output: scalar.
If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <code class="docutils literal notranslate"><span class="pre">'none'</span></code>, then the same size as the target:
<img class="math" src="_images/math/53c49d40851a9450d6838659cff1081c4065b1ce.svg" alt="(N)"/>, or
<img class="math" src="_images/math/58b8cfdf39457f04b5cedd06ff0c7d339e41d002.svg" alt="(N, d_1, d_2, ..., d_K)"/> with <img class="math" src="_images/math/958ad271e79c805e9f757c48d38bb9568bfa403e.svg" alt="K \geq 1"/> in the case
of K-dimensional loss.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span><span class="o">.</span><span class="n">random_</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="ctcloss">
<h3><span class="hidden-section">CTCLoss</span><a class="headerlink" href="#ctcloss" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.CTCLoss">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">CTCLoss</code><span class="sig-paren">(</span><em class="sig-param">blank=0</em>, <em class="sig-param">reduction='mean'</em>, <em class="sig-param">zero_infinity=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/loss.html#CTCLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.CTCLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>The Connectionist Temporal Classification loss.</p>
<p>Calculates loss between a continuous (unsegmented) time series and a target sequence. CTCLoss sums over the
probability of possible alignments of input to target, producing a loss value which is differentiable
with respect to each input node. The alignment of input to target is assumed to be “many-to-one”, which
limits the length of the target sequence such that it must be <img class="math" src="_images/math/8a062baade83eb0aaa8c5b00f6fce6124847bd68.svg" alt="\leq"/> the input length.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>blank</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em>) – blank label. Default <img class="math" src="_images/math/31fdf41b39df23c95e52c5aef07f59d9adf82f3c.svg" alt="0"/>.</p></li>
<li><p><strong>reduction</strong> (<em>string</em><em>, </em><em>optional</em>) – Specifies the reduction to apply to the output:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. <code class="docutils literal notranslate"><span class="pre">'none'</span></code>: no reduction will be applied,
<code class="docutils literal notranslate"><span class="pre">'mean'</span></code>: the output losses will be divided by the target lengths and
then the mean over the batch is taken. Default: <code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
<li><p><strong>zero_infinity</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Whether to zero infinite losses and the associated gradients.
Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>
Infinite losses mainly occur when the inputs are too short
to be aligned to the targets.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Log_probs: Tensor of size <img class="math" src="_images/math/1977a78d4a878e88a5ce16db285e961fe1bbdb95.svg" alt="(T, N, C)"/>,
where <img class="math" src="_images/math/d5dfbdd0a752ab6b1c86eb10aa962148abb94502.svg" alt="T = \text{input length}"/>,
<img class="math" src="_images/math/dcc42bb68e8127b495e9d77ba9df6589de18315e.svg" alt="N = \text{batch size}"/>, and
<img class="math" src="_images/math/c8bd801790d39cc73d0176c53225566c0f3eaff4.svg" alt="C = \text{number of classes (including blank)}"/>.
The logarithmized probabilities of the outputs (e.g. obtained with
<a class="reference internal" href="nn.functional.html#torch.nn.functional.log_softmax" title="torch.nn.functional.log_softmax"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.nn.functional.log_softmax()</span></code></a>).</p></li>
<li><p>Targets: Tensor of size <img class="math" src="_images/math/086c186c4e24812b2ff657326cc5cddbe7f879a3.svg" alt="(N, S)"/> or
<img class="math" src="_images/math/64e83579a06d6814482c9b1d472186cc03827615.svg" alt="(\operatorname{sum}(\text{target\_lengths}))"/>,
where <img class="math" src="_images/math/dcc42bb68e8127b495e9d77ba9df6589de18315e.svg" alt="N = \text{batch size}"/> and
<img class="math" src="_images/math/d688e6cdbda54e6871801c4aedd3a7ab2623bc5e.svg" alt="S = \text{max target length, if shape is } (N, S)"/>.
It represent the target sequences. Each element in the target
sequence is a class index. And the target index cannot be blank (default=0).
In the <img class="math" src="_images/math/086c186c4e24812b2ff657326cc5cddbe7f879a3.svg" alt="(N, S)"/> form, targets are padded to the
length of the longest sequence, and stacked.
In the <img class="math" src="_images/math/64e83579a06d6814482c9b1d472186cc03827615.svg" alt="(\operatorname{sum}(\text{target\_lengths}))"/> form,
the targets are assumed to be un-padded and
concatenated within 1 dimension.</p></li>
<li><p>Input_lengths: Tuple or tensor of size <img class="math" src="_images/math/53c49d40851a9450d6838659cff1081c4065b1ce.svg" alt="(N)"/>,
where <img class="math" src="_images/math/dcc42bb68e8127b495e9d77ba9df6589de18315e.svg" alt="N = \text{batch size}"/>. It represent the lengths of the
inputs (must each be <img class="math" src="_images/math/b514eb1ab527e37dbb4341dfd34a540af4af2508.svg" alt="\leq T"/>). And the lengths are specified
for each sequence to achieve masking under the assumption that sequences
are padded to equal lengths.</p></li>
<li><p>Target_lengths: Tuple or tensor of size <img class="math" src="_images/math/53c49d40851a9450d6838659cff1081c4065b1ce.svg" alt="(N)"/>,
where <img class="math" src="_images/math/dcc42bb68e8127b495e9d77ba9df6589de18315e.svg" alt="N = \text{batch size}"/>. It represent lengths of the targets.
Lengths are specified for each sequence to achieve masking under the
assumption that sequences are padded to equal lengths. If target shape is
<img class="math" src="_images/math/0ed7494f6a4682a14a7fd5198ca27ed82acfb461.svg" alt="(N,S)"/>, target_lengths are effectively the stop index
<img class="math" src="_images/math/af809d42ebe58463b1b00677b3405f11505c0b92.svg" alt="s_n"/> for each target sequence, such that <code class="docutils literal notranslate"><span class="pre">target_n</span> <span class="pre">=</span> <span class="pre">targets[n,0:s_n]</span></code> for
each target in a batch. Lengths must each be <img class="math" src="_images/math/31cd7fb98b1830f068d2594f3c6fb54e8a6ed2d4.svg" alt="\leq S"/>
If the targets are given as a 1d tensor that is the concatenation of individual
targets, the target_lengths must add up to the total length of the tensor.</p></li>
<li><p>Output: scalar. If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <code class="docutils literal notranslate"><span class="pre">'none'</span></code>, then
<img class="math" src="_images/math/53c49d40851a9450d6838659cff1081c4065b1ce.svg" alt="(N)"/>, where <img class="math" src="_images/math/dcc42bb68e8127b495e9d77ba9df6589de18315e.svg" alt="N = \text{batch size}"/>.</p></li>
</ul>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">T</span> <span class="o">=</span> <span class="mi">50</span>      <span class="c1"># Input sequence length</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">C</span> <span class="o">=</span> <span class="mi">20</span>      <span class="c1"># Number of classes (including blank)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">N</span> <span class="o">=</span> <span class="mi">16</span>      <span class="c1"># Batch size</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">S</span> <span class="o">=</span> <span class="mi">30</span>      <span class="c1"># Target sequence length of longest target in batch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">S_min</span> <span class="o">=</span> <span class="mi">10</span>  <span class="c1"># Minimum target length, for demonstration purposes</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Initialize random batch of input vectors, for *size = (T,N,C)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">T</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">C</span><span class="p">)</span><span class="o">.</span><span class="n">log_softmax</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Initialize random batch of targets (0 = blank, 1:C = classes)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">S</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_lengths</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,),</span> <span class="n">fill_value</span><span class="o">=</span><span class="n">T</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target_lengths</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="n">S_min</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">S</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ctc_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CTCLoss</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">ctc_loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">input_lengths</span><span class="p">,</span> <span class="n">target_lengths</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<dl class="simple">
<dt>Reference:</dt><dd><p>A. Graves et al.: Connectionist Temporal Classification:
Labelling Unsegmented Sequence Data with Recurrent Neural Networks:
<a class="reference external" href="https://www.cs.toronto.edu/~graves/icml_2006.pdf">https://www.cs.toronto.edu/~graves/icml_2006.pdf</a></p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In order to use CuDNN, the following must be satisfied: <code class="xref py py-attr docutils literal notranslate"><span class="pre">targets</span></code> must be
in concatenated format, all <code class="xref py py-attr docutils literal notranslate"><span class="pre">input_lengths</span></code> must be <cite>T</cite>.  <img class="math" src="_images/math/731b5cae1f48341e3c0d858ee177d4a3523fd345.svg" alt="blank=0"/>,
<code class="xref py py-attr docutils literal notranslate"><span class="pre">target_lengths</span></code> <img class="math" src="_images/math/afc4a14adadde8a623202ae30510898365db72c5.svg" alt="\leq 256"/>, the integer arguments must be of
dtype <code class="xref py py-attr docutils literal notranslate"><span class="pre">torch.int32</span></code>.</p>
<p>The regular implementation uses the (more common in PyTorch) <cite>torch.long</cite> dtype.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In some circumstances when using the CUDA backend with CuDNN, this operator
may select a nondeterministic algorithm to increase performance. If this is
undesirable, you can try to make the operation deterministic (potentially at
a performance cost) by setting <code class="docutils literal notranslate"><span class="pre">torch.backends.cudnn.deterministic</span> <span class="pre">=</span>
<span class="pre">True</span></code>.
Please see the notes on <a class="reference internal" href="notes/randomness.html"><span class="doc">Reproducibility</span></a> for background.</p>
</div>
</dd></dl>

</div>
<div class="section" id="nllloss">
<h3><span class="hidden-section">NLLLoss</span><a class="headerlink" href="#nllloss" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.NLLLoss">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">NLLLoss</code><span class="sig-paren">(</span><em class="sig-param">weight=None</em>, <em class="sig-param">size_average=None</em>, <em class="sig-param">ignore_index=-100</em>, <em class="sig-param">reduce=None</em>, <em class="sig-param">reduction='mean'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/loss.html#NLLLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.NLLLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>The negative log likelihood loss. It is useful to train a classification
problem with <cite>C</cite> classes.</p>
<p>If provided, the optional argument <code class="xref py py-attr docutils literal notranslate"><span class="pre">weight</span></code> should be a 1D Tensor assigning
weight to each of the classes. This is particularly useful when you have an
unbalanced training set.</p>
<p>The <cite>input</cite> given through a forward call is expected to contain
log-probabilities of each class. <cite>input</cite> has to be a Tensor of size either
<img class="math" src="_images/math/43eacfc9e7c997cf685df13baf2c66abb6e3bf59.svg" alt="(minibatch, C)"/> or <img class="math" src="_images/math/328057e8bac7dfa0dc93a7cc62cbc0f9717cc6fd.svg" alt="(minibatch, C, d_1, d_2, ..., d_K)"/>
with <img class="math" src="_images/math/958ad271e79c805e9f757c48d38bb9568bfa403e.svg" alt="K \geq 1"/> for the <cite>K</cite>-dimensional case (described later).</p>
<p>Obtaining log-probabilities in a neural network is easily achieved by
adding a  <cite>LogSoftmax</cite>  layer in the last layer of your network.
You may use <cite>CrossEntropyLoss</cite> instead, if you prefer not to add an extra
layer.</p>
<p>The <cite>target</cite> that this loss expects should be a class index in the range <img class="math" src="_images/math/94035d2a1ecd714e30dd1d758233d4dcb14e6788.svg" alt="[0, C-1]"/>
where <cite>C = number of classes</cite>; if <cite>ignore_index</cite> is specified, this loss also accepts
this class index (this index may not necessarily be in the class range).</p>
<p>The unreduced (i.e. with <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> set to <code class="docutils literal notranslate"><span class="pre">'none'</span></code>) loss can be described as:</p>
<div class="math">
<p><img src="_images/math/5be8dd74f4d0e850872f18f2e5ba58bd9adf92cf.svg" alt="\ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad
l_n = - w_{y_n} x_{n,y_n}, \quad
w_{c} = \text{weight}[c] \cdot \mathbb{1}\{c \not= \text{ignore\_index}\},"/></p>
</div><p>where <img class="math" src="_images/math/3bfb3a64189a14b2704f4610827762d5e3145114.svg" alt="N"/> is the batch size. If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is not <code class="docutils literal notranslate"><span class="pre">'none'</span></code>
(default <code class="docutils literal notranslate"><span class="pre">'mean'</span></code>), then</p>
<div class="math">
<p><img src="_images/math/f52e4384175790925900c909bca579a644a1b646.svg" alt="\ell(x, y) = \begin{cases}
    \sum_{n=1}^N \frac{1}{\sum_{n=1}^N w_{y_n}} l_n, &amp;
    \text{if reduction} = \text{'mean';}\\
    \sum_{n=1}^N l_n,  &amp;
    \text{if reduction} = \text{'sum'.}
\end{cases}"/></p>
</div><p>Can also be used for higher dimension inputs, such as 2D images, by providing
an input of size <img class="math" src="_images/math/328057e8bac7dfa0dc93a7cc62cbc0f9717cc6fd.svg" alt="(minibatch, C, d_1, d_2, ..., d_K)"/> with <img class="math" src="_images/math/958ad271e79c805e9f757c48d38bb9568bfa403e.svg" alt="K \geq 1"/>,
where <img class="math" src="_images/math/52ddc0cde6d632f631533173562fe3ca375b1f32.svg" alt="K"/> is the number of dimensions, and a target of appropriate shape
(see below). In the case of images, it computes NLL loss per-pixel.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>weight</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) – a manual rescaling weight given to each
class. If given, it has to be a Tensor of size <cite>C</cite>. Otherwise, it is
treated as if having all ones.</p></li>
<li><p><strong>size_average</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>). By default,
the losses are averaged over each loss element in the batch. Note that for
some losses, there are multiple elements per sample. If the field <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>
is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, the losses are instead summed for each minibatch. Ignored
when reduce is <code class="docutils literal notranslate"><span class="pre">False</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>ignore_index</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em>) – Specifies a target value that is ignored
and does not contribute to the input gradient. When
<code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, the loss is averaged over
non-ignored targets.</p></li>
<li><p><strong>reduce</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>). By default, the
losses are averaged or summed over observations for each minibatch depending
on <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>. When <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code>, returns a loss per
batch element instead and ignores <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>reduction</strong> (<em>string</em><em>, </em><em>optional</em>) – Specifies the reduction to apply to the output:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. <code class="docutils literal notranslate"><span class="pre">'none'</span></code>: no reduction will be applied,
<code class="docutils literal notranslate"><span class="pre">'mean'</span></code>: the sum of the output will be divided by the number of
elements in the output, <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>: the output will be summed. Note: <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>
and <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> are in the process of being deprecated, and in the meantime,
specifying either of those two args will override <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/b1bbd46713f69174c0592644b159895f715a74fa.svg" alt="(N, C)"/> where <cite>C = number of classes</cite>, or
<img class="math" src="_images/math/aa2539e83f3a8dec9fce4f07cc9a0479a047b8ee.svg" alt="(N, C, d_1, d_2, ..., d_K)"/> with <img class="math" src="_images/math/958ad271e79c805e9f757c48d38bb9568bfa403e.svg" alt="K \geq 1"/>
in the case of <cite>K</cite>-dimensional loss.</p></li>
<li><p>Target: <img class="math" src="_images/math/53c49d40851a9450d6838659cff1081c4065b1ce.svg" alt="(N)"/> where each value is <img class="math" src="_images/math/1033fe9240ee5a2e4896ecabebd6e3f79837afd2.svg" alt="0 \leq \text{targets}[i] \leq C-1"/>, or
<img class="math" src="_images/math/58b8cfdf39457f04b5cedd06ff0c7d339e41d002.svg" alt="(N, d_1, d_2, ..., d_K)"/> with <img class="math" src="_images/math/958ad271e79c805e9f757c48d38bb9568bfa403e.svg" alt="K \geq 1"/> in the case of
K-dimensional loss.</p></li>
<li><p>Output: scalar.
If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <code class="docutils literal notranslate"><span class="pre">'none'</span></code>, then the same size as the target: <img class="math" src="_images/math/53c49d40851a9450d6838659cff1081c4065b1ce.svg" alt="(N)"/>, or
<img class="math" src="_images/math/58b8cfdf39457f04b5cedd06ff0c7d339e41d002.svg" alt="(N, d_1, d_2, ..., d_K)"/> with <img class="math" src="_images/math/958ad271e79c805e9f757c48d38bb9568bfa403e.svg" alt="K \geq 1"/> in the case
of K-dimensional loss.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LogSoftmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># input is of size N x C = 3 x 5</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># each element in target has to have 0 &lt;= value &lt; C</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">),</span> <span class="n">target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 2D loss example (used, for example, with image inputs)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">N</span><span class="p">,</span> <span class="n">C</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">4</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">NLLLoss</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># input is of size N x C x height x width</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LogSoftmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># each element in target has to have 0 &lt;= value &lt; C</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span><span class="o">.</span><span class="n">random_</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">C</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">m</span><span class="p">(</span><span class="n">conv</span><span class="p">(</span><span class="n">data</span><span class="p">)),</span> <span class="n">target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="poissonnllloss">
<h3><span class="hidden-section">PoissonNLLLoss</span><a class="headerlink" href="#poissonnllloss" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.PoissonNLLLoss">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">PoissonNLLLoss</code><span class="sig-paren">(</span><em class="sig-param">log_input=True</em>, <em class="sig-param">full=False</em>, <em class="sig-param">size_average=None</em>, <em class="sig-param">eps=1e-08</em>, <em class="sig-param">reduce=None</em>, <em class="sig-param">reduction='mean'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/loss.html#PoissonNLLLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.PoissonNLLLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Negative log likelihood loss with Poisson distribution of target.</p>
<p>The loss can be described as:</p>
<div class="math">
<p><img src="_images/math/608028b335c350052c9c136bfa7a717fe755bcb3.svg" alt="\text{target} \sim \mathrm{Poisson}(\text{input})

\text{loss}(\text{input}, \text{target}) = \text{input} - \text{target} * \log(\text{input})
                            + \log(\text{target!})"/></p>
</div><p>The last term can be omitted or approximated with Stirling formula. The
approximation is used for target values more than 1. For targets less or
equal to 1 zeros are added to the loss.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>log_input</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code> the loss is computed as
<img class="math" src="_images/math/2d2e57c22be658e63c5df2e1a2d726ab54bf8f7a.svg" alt="\exp(\text{input}) - \text{target}*\text{input}"/>, if <code class="docutils literal notranslate"><span class="pre">False</span></code> the loss is
<img class="math" src="_images/math/fa193978360e6e3e3e4d9127dde65095df1dd9c7.svg" alt="\text{input} - \text{target}*\log(\text{input}+\text{eps})"/>.</p></li>
<li><p><strong>full</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – <p>whether to compute full loss, i. e. to add the
Stirling approximation term</p>
<div class="math">
<p><img src="_images/math/a32ab243707b63cc93cd89c434973dfee007c8ba.svg" alt="\text{target}*\log(\text{target}) - \text{target} + 0.5 * \log(2\pi\text{target})."/></p>
</div></p></li>
<li><p><strong>size_average</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>). By default,
the losses are averaged over each loss element in the batch. Note that for
some losses, there are multiple elements per sample. If the field <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>
is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, the losses are instead summed for each minibatch. Ignored
when reduce is <code class="docutils literal notranslate"><span class="pre">False</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em>) – Small value to avoid evaluation of <img class="math" src="_images/math/d906b97d92a17e96af16540d5b59312063fd83f9.svg" alt="\log(0)"/> when
<code class="xref py py-attr docutils literal notranslate"><span class="pre">log_input</span> <span class="pre">=</span> <span class="pre">False</span></code>. Default: 1e-8</p></li>
<li><p><strong>reduce</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>). By default, the
losses are averaged or summed over observations for each minibatch depending
on <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>. When <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code>, returns a loss per
batch element instead and ignores <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>reduction</strong> (<em>string</em><em>, </em><em>optional</em>) – Specifies the reduction to apply to the output:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. <code class="docutils literal notranslate"><span class="pre">'none'</span></code>: no reduction will be applied,
<code class="docutils literal notranslate"><span class="pre">'mean'</span></code>: the sum of the output will be divided by the number of
elements in the output, <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>: the output will be summed. Note: <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>
and <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> are in the process of being deprecated, and in the meantime,
specifying either of those two args will override <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">PoissonNLLLoss</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">log_input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">log_input</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/> where <img class="math" src="_images/math/520a99913b8ff14daccff07aa63cdb8d6583e0fc.svg" alt="*"/> means, any number of additional
dimensions</p></li>
<li><p>Target: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/>, same shape as the input</p></li>
<li><p>Output: scalar by default. If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <code class="docutils literal notranslate"><span class="pre">'none'</span></code>, then <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/>,
the same shape as the input</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="kldivloss">
<h3><span class="hidden-section">KLDivLoss</span><a class="headerlink" href="#kldivloss" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.KLDivLoss">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">KLDivLoss</code><span class="sig-paren">(</span><em class="sig-param">size_average=None</em>, <em class="sig-param">reduce=None</em>, <em class="sig-param">reduction='mean'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/loss.html#KLDivLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.KLDivLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>The <a class="reference external" href="https://en.wikipedia.org/wiki/Kullback-Leibler_divergence">Kullback-Leibler divergence</a> Loss</p>
<p>KL divergence is a useful distance measure for continuous distributions
and is often useful when performing direct regression over the space of
(discretely sampled) continuous output distributions.</p>
<p>As with <a class="reference internal" href="#torch.nn.NLLLoss" title="torch.nn.NLLLoss"><code class="xref py py-class docutils literal notranslate"><span class="pre">NLLLoss</span></code></a>, the <cite>input</cite> given is expected to contain
<em>log-probabilities</em> and is not restricted to a 2D Tensor.
The targets are given as <em>probabilities</em> (i.e. without taking the logarithm).</p>
<p>This criterion expects a <cite>target</cite> <cite>Tensor</cite> of the same size as the
<cite>input</cite> <cite>Tensor</cite>.</p>
<p>The unreduced (i.e. with <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> set to <code class="docutils literal notranslate"><span class="pre">'none'</span></code>) loss can be described as:</p>
<div class="math">
<p><img src="_images/math/06e4c2844113ebe6856ea0bbf309d2d145711961.svg" alt="l(x,y) = L = \{ l_1,\dots,l_N \}, \quad
l_n = y_n \cdot \left( \log y_n - x_n \right)"/></p>
</div><p>where the index <img class="math" src="_images/math/3bfb3a64189a14b2704f4610827762d5e3145114.svg" alt="N"/> spans all dimensions of <code class="docutils literal notranslate"><span class="pre">input</span></code> and <img class="math" src="_images/math/19eef1966f7c545af3ac8c0fa486974d873e3c65.svg" alt="L"/> has the same
shape as <code class="docutils literal notranslate"><span class="pre">input</span></code>. If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is not <code class="docutils literal notranslate"><span class="pre">'none'</span></code> (default <code class="docutils literal notranslate"><span class="pre">'mean'</span></code>), then:</p>
<div class="math">
<p><img src="_images/math/fe7cee8a03cce5f48d3cc01e8eed8f8937be9617.svg" alt="\ell(x, y) = \begin{cases}
    \operatorname{mean}(L), &amp; \text{if reduction} = \text{'mean';} \\
    \operatorname{sum}(L),  &amp; \text{if reduction} = \text{'sum'.}
\end{cases}"/></p>
</div><p>In default <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> mode <code class="docutils literal notranslate"><span class="pre">'mean'</span></code>, the losses are averaged for each minibatch over observations
<strong>as well as</strong> over dimensions. <code class="docutils literal notranslate"><span class="pre">'batchmean'</span></code> mode gives the correct KL divergence where losses
are averaged over batch dimension only. <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> mode’s behavior will be changed to the same as
<code class="docutils literal notranslate"><span class="pre">'batchmean'</span></code> in the next major release.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size_average</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>). By default,
the losses are averaged over each loss element in the batch. Note that for
some losses, there are multiple elements per sample. If the field <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>
is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, the losses are instead summed for each minibatch. Ignored
when reduce is <code class="docutils literal notranslate"><span class="pre">False</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>reduce</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>). By default, the
losses are averaged or summed over observations for each minibatch depending
on <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>. When <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code>, returns a loss per
batch element instead and ignores <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>reduction</strong> (<em>string</em><em>, </em><em>optional</em>) – Specifies the reduction to apply to the output:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'batchmean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code>.
<code class="docutils literal notranslate"><span class="pre">'none'</span></code>: no reduction will be applied.
<code class="docutils literal notranslate"><span class="pre">'batchmean'</span></code>: the sum of the output will be divided by batchsize.
<code class="docutils literal notranslate"><span class="pre">'sum'</span></code>: the output will be summed.
<code class="docutils literal notranslate"><span class="pre">'mean'</span></code>: the output will be divided by the number of elements in the output.
Default: <code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> are in the process of being deprecated,
and in the meantime, specifying either of those two args will override <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> = <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> doesn’t return the true kl divergence value, please use
<code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> = <code class="docutils literal notranslate"><span class="pre">'batchmean'</span></code> which aligns with KL math definition.
In the next major release, <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> will be changed to be the same as <code class="docutils literal notranslate"><span class="pre">'batchmean'</span></code>.</p>
</div>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/> where <img class="math" src="_images/math/520a99913b8ff14daccff07aa63cdb8d6583e0fc.svg" alt="*"/> means, any number of additional
dimensions</p></li>
<li><p>Target: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/>, same shape as the input</p></li>
<li><p>Output: scalar by default. If :attr:<code class="docutils literal notranslate"><span class="pre">reduction</span></code> is <code class="docutils literal notranslate"><span class="pre">'none'</span></code>, then <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/>,
the same shape as the input</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="bceloss">
<h3><span class="hidden-section">BCELoss</span><a class="headerlink" href="#bceloss" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.BCELoss">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">BCELoss</code><span class="sig-paren">(</span><em class="sig-param">weight=None</em>, <em class="sig-param">size_average=None</em>, <em class="sig-param">reduce=None</em>, <em class="sig-param">reduction='mean'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/loss.html#BCELoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.BCELoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a criterion that measures the Binary Cross Entropy
between the target and the output:</p>
<p>The unreduced (i.e. with <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> set to <code class="docutils literal notranslate"><span class="pre">'none'</span></code>) loss can be described as:</p>
<div class="math">
<p><img src="_images/math/c744ad884d0b35a35025cd6dcfecbc42a45fd8a5.svg" alt="\ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad
l_n = - w_n \left[ y_n \cdot \log x_n + (1 - y_n) \cdot \log (1 - x_n) \right],"/></p>
</div><p>where <img class="math" src="_images/math/3bfb3a64189a14b2704f4610827762d5e3145114.svg" alt="N"/> is the batch size. If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is not <code class="docutils literal notranslate"><span class="pre">'none'</span></code>
(default <code class="docutils literal notranslate"><span class="pre">'mean'</span></code>), then</p>
<div class="math">
<p><img src="_images/math/bf5bc1607fa97f8831854774e0c5041da49d3d40.svg" alt="\ell(x, y) = \begin{cases}
    \operatorname{mean}(L), &amp; \text{if reduction} = \text{'mean';}\\
    \operatorname{sum}(L),  &amp; \text{if reduction} = \text{'sum'.}
\end{cases}"/></p>
</div><p>This is used for measuring the error of a reconstruction in for example
an auto-encoder. Note that the targets <img class="math" src="_images/math/1b5e577d6216dca3af7d87aa122a0b9b360d6cb3.svg" alt="y"/> should be numbers
between 0 and 1.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>weight</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) – a manual rescaling weight given to the loss
of each batch element. If given, has to be a Tensor of size <cite>nbatch</cite>.</p></li>
<li><p><strong>size_average</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>). By default,
the losses are averaged over each loss element in the batch. Note that for
some losses, there are multiple elements per sample. If the field <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>
is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, the losses are instead summed for each minibatch. Ignored
when reduce is <code class="docutils literal notranslate"><span class="pre">False</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>reduce</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>). By default, the
losses are averaged or summed over observations for each minibatch depending
on <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>. When <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code>, returns a loss per
batch element instead and ignores <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>reduction</strong> (<em>string</em><em>, </em><em>optional</em>) – Specifies the reduction to apply to the output:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. <code class="docutils literal notranslate"><span class="pre">'none'</span></code>: no reduction will be applied,
<code class="docutils literal notranslate"><span class="pre">'mean'</span></code>: the sum of the output will be divided by the number of
elements in the output, <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>: the output will be summed. Note: <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>
and <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> are in the process of being deprecated, and in the meantime,
specifying either of those two args will override <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/> where <img class="math" src="_images/math/520a99913b8ff14daccff07aa63cdb8d6583e0fc.svg" alt="*"/> means, any number of additional
dimensions</p></li>
<li><p>Target: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/>, same shape as the input</p></li>
<li><p>Output: scalar. If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <code class="docutils literal notranslate"><span class="pre">'none'</span></code>, then <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/>, same
shape as input.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">random_</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">),</span> <span class="n">target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="bcewithlogitsloss">
<h3><span class="hidden-section">BCEWithLogitsLoss</span><a class="headerlink" href="#bcewithlogitsloss" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.BCEWithLogitsLoss">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">BCEWithLogitsLoss</code><span class="sig-paren">(</span><em class="sig-param">weight=None</em>, <em class="sig-param">size_average=None</em>, <em class="sig-param">reduce=None</em>, <em class="sig-param">reduction='mean'</em>, <em class="sig-param">pos_weight=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/loss.html#BCEWithLogitsLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.BCEWithLogitsLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>This loss combines a <cite>Sigmoid</cite> layer and the <cite>BCELoss</cite> in one single
class. This version is more numerically stable than using a plain <cite>Sigmoid</cite>
followed by a <cite>BCELoss</cite> as, by combining the operations into one layer,
we take advantage of the log-sum-exp trick for numerical stability.</p>
<p>The unreduced (i.e. with <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> set to <code class="docutils literal notranslate"><span class="pre">'none'</span></code>) loss can be described as:</p>
<div class="math">
<p><img src="_images/math/e28e09de4d1e924162f08a0a528a6e02ec88a542.svg" alt="\ell(x, y) = L = \{l_1,\dots,l_N\}^\top, \quad
l_n = - w_n \left[ y_n \cdot \log \sigma(x_n)
+ (1 - y_n) \cdot \log (1 - \sigma(x_n)) \right],"/></p>
</div><p>where <img class="math" src="_images/math/3bfb3a64189a14b2704f4610827762d5e3145114.svg" alt="N"/> is the batch size. If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is not <code class="docutils literal notranslate"><span class="pre">'none'</span></code>
(default <code class="docutils literal notranslate"><span class="pre">'mean'</span></code>), then</p>
<div class="math">
<p><img src="_images/math/bf5bc1607fa97f8831854774e0c5041da49d3d40.svg" alt="\ell(x, y) = \begin{cases}
    \operatorname{mean}(L), &amp; \text{if reduction} = \text{'mean';}\\
    \operatorname{sum}(L),  &amp; \text{if reduction} = \text{'sum'.}
\end{cases}"/></p>
</div><p>This is used for measuring the error of a reconstruction in for example
an auto-encoder. Note that the targets <cite>t[i]</cite> should be numbers
between 0 and 1.</p>
<p>It’s possible to trade off recall and precision by adding weights to positive examples.
In the case of multi-label classification the loss can be described as:</p>
<div class="math">
<p><img src="_images/math/d0fdecafe14138cfc70101f78bb9704e5048a71a.svg" alt="\ell_c(x, y) = L_c = \{l_{1,c},\dots,l_{N,c}\}^\top, \quad
l_{n,c} = - w_{n,c} \left[ p_c y_{n,c} \cdot \log \sigma(x_{n,c})
+ (1 - y_{n,c}) \cdot \log (1 - \sigma(x_{n,c})) \right],"/></p>
</div><p>where <img class="math" src="_images/math/d520a12f1579170834c32ad5f656de081bbb36fe.svg" alt="c"/> is the class number (<img class="math" src="_images/math/cd1f088d8b40286a5ae30e12ebcfa5ff7f26e85a.svg" alt="c &gt; 1"/> for multi-label binary classification,
<img class="math" src="_images/math/f0eaa3b0b1004a2e133e97d287617624d53853a8.svg" alt="c = 1"/> for single-label binary classification),
<img class="math" src="_images/math/5a939c5280da7202ca4531f175a7780ad5e1f80a.svg" alt="n"/> is the number of the sample in the batch and
<img class="math" src="_images/math/c9a2dae7579ad73b54512e26917a8bd32ed44a96.svg" alt="p_c"/> is the weight of the positive answer for the class <img class="math" src="_images/math/d520a12f1579170834c32ad5f656de081bbb36fe.svg" alt="c"/>.</p>
<p><img class="math" src="_images/math/ec3b10799e1cd1b9ed0555fd1ac6640b62e5c030.svg" alt="p_c &gt; 1"/> increases the recall, <img class="math" src="_images/math/9e250d6148eea92fda2f0b636f5cbf975f73820c.svg" alt="p_c &lt; 1"/> increases the precision.</p>
<p>For example, if a dataset contains 100 positive and 300 negative examples of a single class,
then <cite>pos_weight</cite> for the class should be equal to <img class="math" src="_images/math/15ce9253aca19f3104e1b8c1b21bf8cf22e322f5.svg" alt="\frac{300}{100}=3"/>.
The loss would act as if the dataset contains <img class="math" src="_images/math/22a6c5612706e922a5d57a690adfd6a55ffdbfec.svg" alt="3\times 100=300"/> positive examples.</p>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">64</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>  <span class="c1"># 64 classes, batch size = 10</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">full</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">64</span><span class="p">],</span> <span class="mf">0.999</span><span class="p">)</span>  <span class="c1"># A prediction (logit)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pos_weight</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">64</span><span class="p">])</span>  <span class="c1"># All weights are equal to 1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">criterion</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">(</span><span class="n">pos_weight</span><span class="o">=</span><span class="n">pos_weight</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>  <span class="c1"># -log(sigmoid(0.999))</span>
<span class="go">tensor(0.3135)</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>weight</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) – a manual rescaling weight given to the loss
of each batch element. If given, has to be a Tensor of size <cite>nbatch</cite>.</p></li>
<li><p><strong>size_average</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>). By default,
the losses are averaged over each loss element in the batch. Note that for
some losses, there are multiple elements per sample. If the field <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>
is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, the losses are instead summed for each minibatch. Ignored
when reduce is <code class="docutils literal notranslate"><span class="pre">False</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>reduce</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>). By default, the
losses are averaged or summed over observations for each minibatch depending
on <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>. When <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code>, returns a loss per
batch element instead and ignores <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>reduction</strong> (<em>string</em><em>, </em><em>optional</em>) – Specifies the reduction to apply to the output:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. <code class="docutils literal notranslate"><span class="pre">'none'</span></code>: no reduction will be applied,
<code class="docutils literal notranslate"><span class="pre">'mean'</span></code>: the sum of the output will be divided by the number of
elements in the output, <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>: the output will be summed. Note: <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>
and <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> are in the process of being deprecated, and in the meantime,
specifying either of those two args will override <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
<li><p><strong>pos_weight</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) – a weight of positive examples.
Must be a vector with length equal to the number of classes.</p></li>
</ul>
</dd>
</dl>
<dl>
<dt>Shape:</dt><dd><blockquote>
<div><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/> where <img class="math" src="_images/math/520a99913b8ff14daccff07aa63cdb8d6583e0fc.svg" alt="*"/> means, any number of additional dimensions</p></li>
<li><p>Target: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/>, same shape as the input</p></li>
<li><p>Output: scalar. If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <code class="docutils literal notranslate"><span class="pre">'none'</span></code>, then <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/>, same
shape as input.</p></li>
</ul>
</div></blockquote>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCEWithLogitsLoss</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">target</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">random_</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="marginrankingloss">
<h3><span class="hidden-section">MarginRankingLoss</span><a class="headerlink" href="#marginrankingloss" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.MarginRankingLoss">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">MarginRankingLoss</code><span class="sig-paren">(</span><em class="sig-param">margin=0.0</em>, <em class="sig-param">size_average=None</em>, <em class="sig-param">reduce=None</em>, <em class="sig-param">reduction='mean'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/loss.html#MarginRankingLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.MarginRankingLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a criterion that measures the loss given
inputs <img class="math" src="_images/math/8937a62f7f84fde9a0c08119748a688667f09c7a.svg" alt="x1"/>, <img class="math" src="_images/math/a5fee8cdb586c31d330298b5e8706bcae8b8a4ee.svg" alt="x2"/>, two 1D mini-batch <cite>Tensors</cite>,
and a label 1D mini-batch tensor <img class="math" src="_images/math/1b5e577d6216dca3af7d87aa122a0b9b360d6cb3.svg" alt="y"/> (containing 1 or -1).</p>
<p>If <img class="math" src="_images/math/978513187884f43e921c9228f2367f56e20b7389.svg" alt="y = 1"/> then it assumed the first input should be ranked higher
(have a larger value) than the second input, and vice-versa for <img class="math" src="_images/math/d1c978c8fdf22a6192507a7da40154043f25824a.svg" alt="y = -1"/>.</p>
<p>The loss function for each sample in the mini-batch is:</p>
<div class="math">
<p><img src="_images/math/70f9d439ed93b848bc995c7523d001370e1c6cb1.svg" alt="\text{loss}(x, y) = \max(0, -y * (x1 - x2) + \text{margin})"/></p>
</div><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>margin</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em>) – Has a default value of <img class="math" src="_images/math/31fdf41b39df23c95e52c5aef07f59d9adf82f3c.svg" alt="0"/>.</p></li>
<li><p><strong>size_average</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>). By default,
the losses are averaged over each loss element in the batch. Note that for
some losses, there are multiple elements per sample. If the field <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>
is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, the losses are instead summed for each minibatch. Ignored
when reduce is <code class="docutils literal notranslate"><span class="pre">False</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>reduce</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>). By default, the
losses are averaged or summed over observations for each minibatch depending
on <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>. When <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code>, returns a loss per
batch element instead and ignores <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>reduction</strong> (<em>string</em><em>, </em><em>optional</em>) – Specifies the reduction to apply to the output:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. <code class="docutils literal notranslate"><span class="pre">'none'</span></code>: no reduction will be applied,
<code class="docutils literal notranslate"><span class="pre">'mean'</span></code>: the sum of the output will be divided by the number of
elements in the output, <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>: the output will be summed. Note: <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>
and <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> are in the process of being deprecated, and in the meantime,
specifying either of those two args will override <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/82c436ae5b51139f385d40c4ecddb4572bf8d5c4.svg" alt="(N, D)"/> where <cite>N</cite> is the batch size and <cite>D</cite> is the size of a sample.</p></li>
<li><p>Target: <img class="math" src="_images/math/53c49d40851a9450d6838659cff1081c4065b1ce.svg" alt="(N)"/></p></li>
<li><p>Output: scalar. If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <code class="docutils literal notranslate"><span class="pre">'none'</span></code>, then <img class="math" src="_images/math/53c49d40851a9450d6838659cff1081c4065b1ce.svg" alt="(N)"/>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="hingeembeddingloss">
<h3><span class="hidden-section">HingeEmbeddingLoss</span><a class="headerlink" href="#hingeembeddingloss" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.HingeEmbeddingLoss">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">HingeEmbeddingLoss</code><span class="sig-paren">(</span><em class="sig-param">margin=1.0</em>, <em class="sig-param">size_average=None</em>, <em class="sig-param">reduce=None</em>, <em class="sig-param">reduction='mean'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/loss.html#HingeEmbeddingLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.HingeEmbeddingLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Measures the loss given an input tensor <img class="math" src="_images/math/888f7c323ac0341871e867220ae2d76467d74d6e.svg" alt="x"/> and a labels tensor <img class="math" src="_images/math/1b5e577d6216dca3af7d87aa122a0b9b360d6cb3.svg" alt="y"/>
(containing 1 or -1).
This is usually used for measuring whether two inputs are similar or
dissimilar, e.g. using the L1 pairwise distance as <img class="math" src="_images/math/888f7c323ac0341871e867220ae2d76467d74d6e.svg" alt="x"/>, and is typically
used for learning nonlinear embeddings or semi-supervised learning.</p>
<p>The loss function for <img class="math" src="_images/math/5a939c5280da7202ca4531f175a7780ad5e1f80a.svg" alt="n"/>-th sample in the mini-batch is</p>
<div class="math">
<p><img src="_images/math/303c369bc5d611ff4bef8ba278b05d87e0b05dc5.svg" alt="l_n = \begin{cases}
    x_n, &amp; \text{if}\; y_n = 1,\\
    \max \{0, \Delta - x_n\}, &amp; \text{if}\; y_n = -1,
\end{cases}"/></p>
</div><p>and the total loss functions is</p>
<div class="math">
<p><img src="_images/math/bf5bc1607fa97f8831854774e0c5041da49d3d40.svg" alt="\ell(x, y) = \begin{cases}
    \operatorname{mean}(L), &amp; \text{if reduction} = \text{'mean';}\\
    \operatorname{sum}(L),  &amp; \text{if reduction} = \text{'sum'.}
\end{cases}"/></p>
</div><p>where <img class="math" src="_images/math/962b8440573f509b86e700c73291b73ee7c2188d.svg" alt="L = \{l_1,\dots,l_N\}^\top"/>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>margin</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em>) – Has a default value of <cite>1</cite>.</p></li>
<li><p><strong>size_average</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>). By default,
the losses are averaged over each loss element in the batch. Note that for
some losses, there are multiple elements per sample. If the field <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>
is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, the losses are instead summed for each minibatch. Ignored
when reduce is <code class="docutils literal notranslate"><span class="pre">False</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>reduce</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>). By default, the
losses are averaged or summed over observations for each minibatch depending
on <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>. When <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code>, returns a loss per
batch element instead and ignores <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>reduction</strong> (<em>string</em><em>, </em><em>optional</em>) – Specifies the reduction to apply to the output:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. <code class="docutils literal notranslate"><span class="pre">'none'</span></code>: no reduction will be applied,
<code class="docutils literal notranslate"><span class="pre">'mean'</span></code>: the sum of the output will be divided by the number of
elements in the output, <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>: the output will be summed. Note: <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>
and <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> are in the process of being deprecated, and in the meantime,
specifying either of those two args will override <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/2de0f5cf89ef2a5e8bd53fbaca25287a386e0784.svg" alt="(*)"/> where <img class="math" src="_images/math/520a99913b8ff14daccff07aa63cdb8d6583e0fc.svg" alt="*"/> means, any number of dimensions. The sum operation
operates over all the elements.</p></li>
<li><p>Target: <img class="math" src="_images/math/2de0f5cf89ef2a5e8bd53fbaca25287a386e0784.svg" alt="(*)"/>, same shape as the input</p></li>
<li><p>Output: scalar. If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <code class="docutils literal notranslate"><span class="pre">'none'</span></code>, then same shape as the input</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="multilabelmarginloss">
<h3><span class="hidden-section">MultiLabelMarginLoss</span><a class="headerlink" href="#multilabelmarginloss" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.MultiLabelMarginLoss">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">MultiLabelMarginLoss</code><span class="sig-paren">(</span><em class="sig-param">size_average=None</em>, <em class="sig-param">reduce=None</em>, <em class="sig-param">reduction='mean'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/loss.html#MultiLabelMarginLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.MultiLabelMarginLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a criterion that optimizes a multi-class multi-classification
hinge loss (margin-based loss) between input <img class="math" src="_images/math/888f7c323ac0341871e867220ae2d76467d74d6e.svg" alt="x"/> (a 2D mini-batch <cite>Tensor</cite>)
and output <img class="math" src="_images/math/1b5e577d6216dca3af7d87aa122a0b9b360d6cb3.svg" alt="y"/> (which is a 2D <cite>Tensor</cite> of target class indices).
For each sample in the mini-batch:</p>
<div class="math">
<p><img src="_images/math/599029ba57a0f0864067469d63f85a24788fbade.svg" alt="\text{loss}(x, y) = \sum_{ij}\frac{\max(0, 1 - (x[y[j]] - x[i]))}{\text{x.size}(0)}"/></p>
</div><p>where <img class="math" src="_images/math/3f64432bb521a99b7339385be177ce46e70e3d0c.svg" alt="x \in \left\{0, \; \cdots , \; \text{x.size}(0) - 1\right\}"/>, <img class="math" src="_images/math/aa501da8b7affe6a5f8654f88cbb453b01eb136d.svg" alt="y \in \left\{0, \; \cdots , \; \text{y.size}(0) - 1\right\}"/>, <img class="math" src="_images/math/af496108235e31763103e0cba1ce7107ce8ed931.svg" alt="0 \leq y[j] \leq \text{x.size}(0)-1"/>, and <img class="math" src="_images/math/b47a7fc398bb82a32f2c14fdf36ddf0c4975b8be.svg" alt="i \neq y[j]"/> for all <img class="math" src="_images/math/5aa339d4daf45a810dda332e3c80a0698e526e04.svg" alt="i"/> and <img class="math" src="_images/math/e3fc28292267f066fee7718c64f4bbfece521f24.svg" alt="j"/>.</p>
<p><img class="math" src="_images/math/1b5e577d6216dca3af7d87aa122a0b9b360d6cb3.svg" alt="y"/> and <img class="math" src="_images/math/888f7c323ac0341871e867220ae2d76467d74d6e.svg" alt="x"/> must have the same size.</p>
<p>The criterion only considers a contiguous block of non-negative targets that
starts at the front.</p>
<p>This allows for different samples to have variable amounts of target classes.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size_average</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>). By default,
the losses are averaged over each loss element in the batch. Note that for
some losses, there are multiple elements per sample. If the field <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>
is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, the losses are instead summed for each minibatch. Ignored
when reduce is <code class="docutils literal notranslate"><span class="pre">False</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>reduce</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>). By default, the
losses are averaged or summed over observations for each minibatch depending
on <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>. When <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code>, returns a loss per
batch element instead and ignores <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>reduction</strong> (<em>string</em><em>, </em><em>optional</em>) – Specifies the reduction to apply to the output:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. <code class="docutils literal notranslate"><span class="pre">'none'</span></code>: no reduction will be applied,
<code class="docutils literal notranslate"><span class="pre">'mean'</span></code>: the sum of the output will be divided by the number of
elements in the output, <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>: the output will be summed. Note: <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>
and <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> are in the process of being deprecated, and in the meantime,
specifying either of those two args will override <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/cbb9af5172986849eed0dda3128be36420586a0b.svg" alt="(C)"/> or <img class="math" src="_images/math/b1bbd46713f69174c0592644b159895f715a74fa.svg" alt="(N, C)"/> where <cite>N</cite> is the batch size and <cite>C</cite>
is the number of classes.</p></li>
<li><p>Target: <img class="math" src="_images/math/cbb9af5172986849eed0dda3128be36420586a0b.svg" alt="(C)"/> or <img class="math" src="_images/math/b1bbd46713f69174c0592644b159895f715a74fa.svg" alt="(N, C)"/>, label targets padded by -1 ensuring same shape as the input.</p></li>
<li><p>Output: scalar. If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <code class="docutils literal notranslate"><span class="pre">'none'</span></code>, then <img class="math" src="_images/math/53c49d40851a9450d6838659cff1081c4065b1ce.svg" alt="(N)"/>.</p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MultiLabelMarginLoss</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">FloatTensor</span><span class="p">([[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># for target y, only consider labels 3 and 0, not after label -1</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># 0.25 * ((1-(0.1-0.2)) + (1-(0.1-0.4)) + (1-(0.8-0.2)) + (1-(0.8-0.4)))</span>
<span class="go">tensor(0.8500)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="smoothl1loss">
<h3><span class="hidden-section">SmoothL1Loss</span><a class="headerlink" href="#smoothl1loss" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.SmoothL1Loss">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">SmoothL1Loss</code><span class="sig-paren">(</span><em class="sig-param">size_average=None</em>, <em class="sig-param">reduce=None</em>, <em class="sig-param">reduction='mean'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/loss.html#SmoothL1Loss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.SmoothL1Loss" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a criterion that uses a squared term if the absolute
element-wise error falls below 1 and an L1 term otherwise.
It is less sensitive to outliers than the <cite>MSELoss</cite> and in some cases
prevents exploding gradients (e.g. see <cite>Fast R-CNN</cite> paper by Ross Girshick).
Also known as the Huber loss:</p>
<div class="math">
<p><img src="_images/math/5f090c43b3faa7f861c116bd085a3a353bef191a.svg" alt="\text{loss}(x, y) = \frac{1}{n} \sum_{i} z_{i}"/></p>
</div><p>where <img class="math" src="_images/math/ba65f69dd9c400da3caba2f9bea6a428880c7e02.svg" alt="z_{i}"/> is given by:</p>
<div class="math">
<p><img src="_images/math/100c273c5170a2a7db2df648480c82a005862fb1.svg" alt="z_{i} =
\begin{cases}
0.5 (x_i - y_i)^2, &amp; \text{if } |x_i - y_i| &lt; 1 \\
|x_i - y_i| - 0.5, &amp; \text{otherwise }
\end{cases}"/></p>
</div><p><img class="math" src="_images/math/888f7c323ac0341871e867220ae2d76467d74d6e.svg" alt="x"/> and <img class="math" src="_images/math/1b5e577d6216dca3af7d87aa122a0b9b360d6cb3.svg" alt="y"/> arbitrary shapes with a total of <img class="math" src="_images/math/5a939c5280da7202ca4531f175a7780ad5e1f80a.svg" alt="n"/> elements each
the sum operation still operates over all the elements, and divides by <img class="math" src="_images/math/5a939c5280da7202ca4531f175a7780ad5e1f80a.svg" alt="n"/>.</p>
<p>The division by <img class="math" src="_images/math/5a939c5280da7202ca4531f175a7780ad5e1f80a.svg" alt="n"/> can be avoided if sets <code class="docutils literal notranslate"><span class="pre">reduction</span> <span class="pre">=</span> <span class="pre">'sum'</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size_average</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>). By default,
the losses are averaged over each loss element in the batch. Note that for
some losses, there are multiple elements per sample. If the field <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>
is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, the losses are instead summed for each minibatch. Ignored
when reduce is <code class="docutils literal notranslate"><span class="pre">False</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>reduce</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>). By default, the
losses are averaged or summed over observations for each minibatch depending
on <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>. When <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code>, returns a loss per
batch element instead and ignores <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>reduction</strong> (<em>string</em><em>, </em><em>optional</em>) – Specifies the reduction to apply to the output:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. <code class="docutils literal notranslate"><span class="pre">'none'</span></code>: no reduction will be applied,
<code class="docutils literal notranslate"><span class="pre">'mean'</span></code>: the sum of the output will be divided by the number of
elements in the output, <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>: the output will be summed. Note: <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>
and <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> are in the process of being deprecated, and in the meantime,
specifying either of those two args will override <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/> where <img class="math" src="_images/math/520a99913b8ff14daccff07aa63cdb8d6583e0fc.svg" alt="*"/> means, any number of additional
dimensions</p></li>
<li><p>Target: <img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/>, same shape as the input</p></li>
<li><p>Output: scalar. If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <code class="docutils literal notranslate"><span class="pre">'none'</span></code>, then
<img class="math" src="_images/math/564efe9a31f7798b47cf0cf6345eda8b2bf23406.svg" alt="(N, *)"/>, same shape as the input</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="softmarginloss">
<h3><span class="hidden-section">SoftMarginLoss</span><a class="headerlink" href="#softmarginloss" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.SoftMarginLoss">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">SoftMarginLoss</code><span class="sig-paren">(</span><em class="sig-param">size_average=None</em>, <em class="sig-param">reduce=None</em>, <em class="sig-param">reduction='mean'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/loss.html#SoftMarginLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.SoftMarginLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a criterion that optimizes a two-class classification
logistic loss between input tensor <img class="math" src="_images/math/888f7c323ac0341871e867220ae2d76467d74d6e.svg" alt="x"/> and target tensor <img class="math" src="_images/math/1b5e577d6216dca3af7d87aa122a0b9b360d6cb3.svg" alt="y"/>
(containing 1 or -1).</p>
<div class="math">
<p><img src="_images/math/b83c6c9f00b700ea3acebc7c9d6a15eda8b88a4a.svg" alt="\text{loss}(x, y) = \sum_i \frac{\log(1 + \exp(-y[i]*x[i]))}{\text{x.nelement}()}"/></p>
</div><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size_average</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>). By default,
the losses are averaged over each loss element in the batch. Note that for
some losses, there are multiple elements per sample. If the field <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>
is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, the losses are instead summed for each minibatch. Ignored
when reduce is <code class="docutils literal notranslate"><span class="pre">False</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>reduce</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>). By default, the
losses are averaged or summed over observations for each minibatch depending
on <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>. When <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code>, returns a loss per
batch element instead and ignores <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>reduction</strong> (<em>string</em><em>, </em><em>optional</em>) – Specifies the reduction to apply to the output:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. <code class="docutils literal notranslate"><span class="pre">'none'</span></code>: no reduction will be applied,
<code class="docutils literal notranslate"><span class="pre">'mean'</span></code>: the sum of the output will be divided by the number of
elements in the output, <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>: the output will be summed. Note: <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>
and <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> are in the process of being deprecated, and in the meantime,
specifying either of those two args will override <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/2de0f5cf89ef2a5e8bd53fbaca25287a386e0784.svg" alt="(*)"/> where <img class="math" src="_images/math/520a99913b8ff14daccff07aa63cdb8d6583e0fc.svg" alt="*"/> means, any number of additional
dimensions</p></li>
<li><p>Target: <img class="math" src="_images/math/2de0f5cf89ef2a5e8bd53fbaca25287a386e0784.svg" alt="(*)"/>, same shape as the input</p></li>
<li><p>Output: scalar. If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <code class="docutils literal notranslate"><span class="pre">'none'</span></code>, then same shape as the input</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="multilabelsoftmarginloss">
<h3><span class="hidden-section">MultiLabelSoftMarginLoss</span><a class="headerlink" href="#multilabelsoftmarginloss" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.MultiLabelSoftMarginLoss">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">MultiLabelSoftMarginLoss</code><span class="sig-paren">(</span><em class="sig-param">weight=None</em>, <em class="sig-param">size_average=None</em>, <em class="sig-param">reduce=None</em>, <em class="sig-param">reduction='mean'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/loss.html#MultiLabelSoftMarginLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.MultiLabelSoftMarginLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a criterion that optimizes a multi-label one-versus-all
loss based on max-entropy, between input <img class="math" src="_images/math/888f7c323ac0341871e867220ae2d76467d74d6e.svg" alt="x"/> and target <img class="math" src="_images/math/1b5e577d6216dca3af7d87aa122a0b9b360d6cb3.svg" alt="y"/> of size
<img class="math" src="_images/math/b1bbd46713f69174c0592644b159895f715a74fa.svg" alt="(N, C)"/>.
For each sample in the minibatch:</p>
<div class="math">
<p><img src="_images/math/65d9c48b8e5a24c4f573e4348ecd143956cd1228.svg" alt="loss(x, y) = - \frac{1}{C} * \sum_i y[i] * \log((1 + \exp(-x[i]))^{-1})
                 + (1-y[i]) * \log\left(\frac{\exp(-x[i])}{(1 + \exp(-x[i]))}\right)"/></p>
</div><p>where <img class="math" src="_images/math/40483bcf1c4e841d1352cf657c5eec9dfabced94.svg" alt="i \in \left\{0, \; \cdots , \; \text{x.nElement}() - 1\right\}"/>,
<img class="math" src="_images/math/1fc292159a32c9aefc15233f2bf15570767a3dc9.svg" alt="y[i] \in \left\{0, \; 1\right\}"/>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>weight</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) – a manual rescaling weight given to each
class. If given, it has to be a Tensor of size <cite>C</cite>. Otherwise, it is
treated as if having all ones.</p></li>
<li><p><strong>size_average</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>). By default,
the losses are averaged over each loss element in the batch. Note that for
some losses, there are multiple elements per sample. If the field <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>
is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, the losses are instead summed for each minibatch. Ignored
when reduce is <code class="docutils literal notranslate"><span class="pre">False</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>reduce</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>). By default, the
losses are averaged or summed over observations for each minibatch depending
on <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>. When <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code>, returns a loss per
batch element instead and ignores <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>reduction</strong> (<em>string</em><em>, </em><em>optional</em>) – Specifies the reduction to apply to the output:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. <code class="docutils literal notranslate"><span class="pre">'none'</span></code>: no reduction will be applied,
<code class="docutils literal notranslate"><span class="pre">'mean'</span></code>: the sum of the output will be divided by the number of
elements in the output, <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>: the output will be summed. Note: <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>
and <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> are in the process of being deprecated, and in the meantime,
specifying either of those two args will override <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/b1bbd46713f69174c0592644b159895f715a74fa.svg" alt="(N, C)"/> where <cite>N</cite> is the batch size and <cite>C</cite> is the number of classes.</p></li>
<li><p>Target: <img class="math" src="_images/math/b1bbd46713f69174c0592644b159895f715a74fa.svg" alt="(N, C)"/>, label targets padded by -1 ensuring same shape as the input.</p></li>
<li><p>Output: scalar. If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <code class="docutils literal notranslate"><span class="pre">'none'</span></code>, then <img class="math" src="_images/math/53c49d40851a9450d6838659cff1081c4065b1ce.svg" alt="(N)"/>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="cosineembeddingloss">
<h3><span class="hidden-section">CosineEmbeddingLoss</span><a class="headerlink" href="#cosineembeddingloss" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.CosineEmbeddingLoss">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">CosineEmbeddingLoss</code><span class="sig-paren">(</span><em class="sig-param">margin=0.0</em>, <em class="sig-param">size_average=None</em>, <em class="sig-param">reduce=None</em>, <em class="sig-param">reduction='mean'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/loss.html#CosineEmbeddingLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.CosineEmbeddingLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a criterion that measures the loss given input tensors
<img class="math" src="_images/math/5ea99039cd8359fa2e14317dbfae4497ebbc1360.svg" alt="x_1"/>, <img class="math" src="_images/math/b7bda214149c6fe0d7c6c494b0c896805bf51262.svg" alt="x_2"/> and a <cite>Tensor</cite> label <img class="math" src="_images/math/1b5e577d6216dca3af7d87aa122a0b9b360d6cb3.svg" alt="y"/> with values 1 or -1.
This is used for measuring whether two inputs are similar or dissimilar,
using the cosine distance, and is typically used for learning nonlinear
embeddings or semi-supervised learning.</p>
<p>The loss function for each sample is:</p>
<div class="math">
<p><img src="_images/math/9e1dd444b4ba55a62b4e32c9231e7d2d84a9ece5.svg" alt="\text{loss}(x, y) =
\begin{cases}
1 - \cos(x_1, x_2), &amp; \text{if } y = 1 \\
\max(0, \cos(x_1, x_2) - \text{margin}), &amp; \text{if } y = -1
\end{cases}"/></p>
</div><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>margin</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em>) – Should be a number from <img class="math" src="_images/math/bb3bcf4d88dfa961f520a0d0cea612b738596d66.svg" alt="-1"/> to <img class="math" src="_images/math/ec830c85a5fbb48028fe797044da6bdfb924c2fa.svg" alt="1"/>,
<img class="math" src="_images/math/31fdf41b39df23c95e52c5aef07f59d9adf82f3c.svg" alt="0"/> to <img class="math" src="_images/math/b44fd1b6dc8c77975b68a57eb25231239a15d7b5.svg" alt="0.5"/> is suggested. If <code class="xref py py-attr docutils literal notranslate"><span class="pre">margin</span></code> is missing, the
default value is <img class="math" src="_images/math/31fdf41b39df23c95e52c5aef07f59d9adf82f3c.svg" alt="0"/>.</p></li>
<li><p><strong>size_average</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>). By default,
the losses are averaged over each loss element in the batch. Note that for
some losses, there are multiple elements per sample. If the field <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>
is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, the losses are instead summed for each minibatch. Ignored
when reduce is <code class="docutils literal notranslate"><span class="pre">False</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>reduce</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>). By default, the
losses are averaged or summed over observations for each minibatch depending
on <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>. When <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code>, returns a loss per
batch element instead and ignores <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>reduction</strong> (<em>string</em><em>, </em><em>optional</em>) – Specifies the reduction to apply to the output:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. <code class="docutils literal notranslate"><span class="pre">'none'</span></code>: no reduction will be applied,
<code class="docutils literal notranslate"><span class="pre">'mean'</span></code>: the sum of the output will be divided by the number of
elements in the output, <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>: the output will be summed. Note: <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>
and <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> are in the process of being deprecated, and in the meantime,
specifying either of those two args will override <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="multimarginloss">
<h3><span class="hidden-section">MultiMarginLoss</span><a class="headerlink" href="#multimarginloss" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.MultiMarginLoss">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">MultiMarginLoss</code><span class="sig-paren">(</span><em class="sig-param">p=1</em>, <em class="sig-param">margin=1.0</em>, <em class="sig-param">weight=None</em>, <em class="sig-param">size_average=None</em>, <em class="sig-param">reduce=None</em>, <em class="sig-param">reduction='mean'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/loss.html#MultiMarginLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.MultiMarginLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a criterion that optimizes a multi-class classification hinge
loss (margin-based loss) between input <img class="math" src="_images/math/888f7c323ac0341871e867220ae2d76467d74d6e.svg" alt="x"/> (a 2D mini-batch <cite>Tensor</cite>) and
output <img class="math" src="_images/math/1b5e577d6216dca3af7d87aa122a0b9b360d6cb3.svg" alt="y"/> (which is a 1D tensor of target class indices,
<img class="math" src="_images/math/d17f215c2c42ddedfea1aa9a59f30491a5f3ecd2.svg" alt="0 \leq y \leq \text{x.size}(1)-1"/>):</p>
<p>For each mini-batch sample, the loss in terms of the 1D input <img class="math" src="_images/math/888f7c323ac0341871e867220ae2d76467d74d6e.svg" alt="x"/> and scalar
output <img class="math" src="_images/math/1b5e577d6216dca3af7d87aa122a0b9b360d6cb3.svg" alt="y"/> is:</p>
<div class="math">
<p><img src="_images/math/620e0ed151ccf70954c98b637e5e4829e1fab77b.svg" alt="\text{loss}(x, y) = \frac{\sum_i \max(0, \text{margin} - x[y] + x[i]))^p}{\text{x.size}(0)}"/></p>
</div><p>where <img class="math" src="_images/math/3f64432bb521a99b7339385be177ce46e70e3d0c.svg" alt="x \in \left\{0, \; \cdots , \; \text{x.size}(0) - 1\right\}"/>
and <img class="math" src="_images/math/53a1c2e97cc4573c023a4f2de0f4666f9f816c54.svg" alt="i \neq y"/>.</p>
<p>Optionally, you can give non-equal weighting on the classes by passing
a 1D <code class="xref py py-attr docutils literal notranslate"><span class="pre">weight</span></code> tensor into the constructor.</p>
<p>The loss function then becomes:</p>
<div class="math">
<p><img src="_images/math/a5596faa7024c09ff013012793f3ed169cda8233.svg" alt="\text{loss}(x, y) = \frac{\sum_i \max(0, w[y] * (\text{margin} - x[y] + x[i]))^p)}{\text{x.size}(0)}"/></p>
</div><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>p</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em>) – Has a default value of <img class="math" src="_images/math/ec830c85a5fbb48028fe797044da6bdfb924c2fa.svg" alt="1"/>. <img class="math" src="_images/math/ec830c85a5fbb48028fe797044da6bdfb924c2fa.svg" alt="1"/> and <img class="math" src="_images/math/d94997a2318fec7e8e5bc4d8d79bb633675f9411.svg" alt="2"/>
are the only supported values.</p></li>
<li><p><strong>margin</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em>) – Has a default value of <img class="math" src="_images/math/ec830c85a5fbb48028fe797044da6bdfb924c2fa.svg" alt="1"/>.</p></li>
<li><p><strong>weight</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) – a manual rescaling weight given to each
class. If given, it has to be a Tensor of size <cite>C</cite>. Otherwise, it is
treated as if having all ones.</p></li>
<li><p><strong>size_average</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>). By default,
the losses are averaged over each loss element in the batch. Note that for
some losses, there are multiple elements per sample. If the field <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>
is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, the losses are instead summed for each minibatch. Ignored
when reduce is <code class="docutils literal notranslate"><span class="pre">False</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>reduce</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>). By default, the
losses are averaged or summed over observations for each minibatch depending
on <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>. When <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code>, returns a loss per
batch element instead and ignores <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>reduction</strong> (<em>string</em><em>, </em><em>optional</em>) – Specifies the reduction to apply to the output:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. <code class="docutils literal notranslate"><span class="pre">'none'</span></code>: no reduction will be applied,
<code class="docutils literal notranslate"><span class="pre">'mean'</span></code>: the sum of the output will be divided by the number of
elements in the output, <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>: the output will be summed. Note: <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>
and <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> are in the process of being deprecated, and in the meantime,
specifying either of those two args will override <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="tripletmarginloss">
<h3><span class="hidden-section">TripletMarginLoss</span><a class="headerlink" href="#tripletmarginloss" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.TripletMarginLoss">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">TripletMarginLoss</code><span class="sig-paren">(</span><em class="sig-param">margin=1.0</em>, <em class="sig-param">p=2.0</em>, <em class="sig-param">eps=1e-06</em>, <em class="sig-param">swap=False</em>, <em class="sig-param">size_average=None</em>, <em class="sig-param">reduce=None</em>, <em class="sig-param">reduction='mean'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/loss.html#TripletMarginLoss"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.TripletMarginLoss" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates a criterion that measures the triplet loss given an input
tensors <img class="math" src="_images/math/8937a62f7f84fde9a0c08119748a688667f09c7a.svg" alt="x1"/>, <img class="math" src="_images/math/a5fee8cdb586c31d330298b5e8706bcae8b8a4ee.svg" alt="x2"/>, <img class="math" src="_images/math/7abb0b7b5b5cde53096835e91f4ee731c1efca6f.svg" alt="x3"/> and a margin with a value greater than <img class="math" src="_images/math/31fdf41b39df23c95e52c5aef07f59d9adf82f3c.svg" alt="0"/>.
This is used for measuring a relative similarity between samples. A triplet
is composed by <cite>a</cite>, <cite>p</cite> and <cite>n</cite> (i.e., <cite>anchor</cite>, <cite>positive examples</cite> and <cite>negative
examples</cite> respectively). The shapes of all input tensors should be
<img class="math" src="_images/math/82c436ae5b51139f385d40c4ecddb4572bf8d5c4.svg" alt="(N, D)"/>.</p>
<p>The distance swap is described in detail in the paper <a class="reference external" href="http://www.bmva.org/bmvc/2016/papers/paper119/index.html">Learning shallow
convolutional feature descriptors with triplet losses</a> by
V. Balntas, E. Riba et al.</p>
<p>The loss function for each sample in the mini-batch is:</p>
<div class="math">
<p><img src="_images/math/ab250e559e16b4c1dd68548c07f5951692ca25ca.svg" alt="L(a, p, n) = \max \{d(a_i, p_i) - d(a_i, n_i) + {\rm margin}, 0\}"/></p>
</div><p>where</p>
<div class="math">
<p><img src="_images/math/31148fe529511482b38b57960b752fe1c0f41a57.svg" alt="d(x_i, y_i) = \left\lVert {\bf x}_i - {\bf y}_i \right\rVert_p"/></p>
</div><dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>margin</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em>) – Default: <img class="math" src="_images/math/ec830c85a5fbb48028fe797044da6bdfb924c2fa.svg" alt="1"/>.</p></li>
<li><p><strong>p</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em>) – The norm degree for pairwise distance. Default: <img class="math" src="_images/math/d94997a2318fec7e8e5bc4d8d79bb633675f9411.svg" alt="2"/>.</p></li>
<li><p><strong>swap</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – The distance swap is described in detail in the paper
<cite>Learning shallow convolutional feature descriptors with triplet losses</cite> by
V. Balntas, E. Riba et al. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p></li>
<li><p><strong>size_average</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>). By default,
the losses are averaged over each loss element in the batch. Note that for
some losses, there are multiple elements per sample. If the field <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>
is set to <code class="docutils literal notranslate"><span class="pre">False</span></code>, the losses are instead summed for each minibatch. Ignored
when reduce is <code class="docutils literal notranslate"><span class="pre">False</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>reduce</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – Deprecated (see <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>). By default, the
losses are averaged or summed over observations for each minibatch depending
on <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>. When <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code>, returns a loss per
batch element instead and ignores <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code></p></li>
<li><p><strong>reduction</strong> (<em>string</em><em>, </em><em>optional</em>) – Specifies the reduction to apply to the output:
<code class="docutils literal notranslate"><span class="pre">'none'</span></code> | <code class="docutils literal notranslate"><span class="pre">'mean'</span></code> | <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>. <code class="docutils literal notranslate"><span class="pre">'none'</span></code>: no reduction will be applied,
<code class="docutils literal notranslate"><span class="pre">'mean'</span></code>: the sum of the output will be divided by the number of
elements in the output, <code class="docutils literal notranslate"><span class="pre">'sum'</span></code>: the output will be summed. Note: <code class="xref py py-attr docutils literal notranslate"><span class="pre">size_average</span></code>
and <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduce</span></code> are in the process of being deprecated, and in the meantime,
specifying either of those two args will override <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">'mean'</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/82c436ae5b51139f385d40c4ecddb4572bf8d5c4.svg" alt="(N, D)"/> where <img class="math" src="_images/math/0fcab9067b50b87e868c4fd70f213a086addb964.svg" alt="D"/> is the vector dimension.</p></li>
<li><p>Output: scalar. If <code class="xref py py-attr docutils literal notranslate"><span class="pre">reduction</span></code> is <code class="docutils literal notranslate"><span class="pre">'none'</span></code>, then <img class="math" src="_images/math/53c49d40851a9450d6838659cff1081c4065b1ce.svg" alt="(N)"/>.</p></li>
</ul>
</dd>
</dl>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">triplet_loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">TripletMarginLoss</span><span class="p">(</span><span class="n">margin</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">anchor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">positive</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">negative</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">triplet_loss</span><span class="p">(</span><span class="n">anchor</span><span class="p">,</span> <span class="n">positive</span><span class="p">,</span> <span class="n">negative</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

</div>
</div>
<div class="section" id="vision-layers">
<h2>Vision layers<a class="headerlink" href="#vision-layers" title="Permalink to this headline">¶</a></h2>
<div class="section" id="pixelshuffle">
<h3><span class="hidden-section">PixelShuffle</span><a class="headerlink" href="#pixelshuffle" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.PixelShuffle">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">PixelShuffle</code><span class="sig-paren">(</span><em class="sig-param">upscale_factor</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/pixelshuffle.html#PixelShuffle"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.PixelShuffle" title="Permalink to this definition">¶</a></dt>
<dd><p>Rearranges elements in a tensor of shape <img class="math" src="_images/math/6cf746408982a7627e7a8024e65179b728f2c4e6.svg" alt="(*, C \times r^2, H, W)"/>
to a tensor of shape <img class="math" src="_images/math/99a178fe12fce2e60a4e05b26ffa61223db3e986.svg" alt="(*, C, H \times r, W \times r)"/>.</p>
<p>This is useful for implementing efficient sub-pixel convolution
with a stride of <img class="math" src="_images/math/63a1c2bf461a8f3670bcd7fa8b1c6474cf62fcfc.svg" alt="1/r"/>.</p>
<p>Look at the paper:
<a class="reference external" href="https://arxiv.org/abs/1609.05158">Real-Time Single Image and Video Super-Resolution Using an Efficient Sub-Pixel Convolutional Neural Network</a>
by Shi et. al (2016) for more details.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>upscale_factor</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – factor to increase spatial resolution by</p>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/90575372a0c904dc51997038798852be0e4d6844.svg" alt="(N, L, H_{in}, W_{in})"/> where <img class="math" src="_images/math/f19d5b1193ce148c9231ca8b0b25fa266730e291.svg" alt="L=C \times \text{upscale\_factor}^2"/></p></li>
<li><p>Output: <img class="math" src="_images/math/4026633441f65aa86208d4b12337149db951eab6.svg" alt="(N, C, H_{out}, W_{out})"/> where
<img class="math" src="_images/math/3917d0fb1eb058433b4ca79b7240fe48f0d18d6a.svg" alt="H_{out} = H_{in} \times \text{upscale\_factor}"/>
and <img class="math" src="_images/math/5f793e7df39048bbb5041612a959036ce18a246a.svg" alt="W_{out} = W_{in} \times \text{upscale\_factor}"/></p></li>
</ul>
</dd>
</dl>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">pixel_shuffle</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">PixelShuffle</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">pixel_shuffle</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
<span class="go">torch.Size([1, 1, 12, 12])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="upsample">
<h3><span class="hidden-section">Upsample</span><a class="headerlink" href="#upsample" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.Upsample">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">Upsample</code><span class="sig-paren">(</span><em class="sig-param">size=None</em>, <em class="sig-param">scale_factor=None</em>, <em class="sig-param">mode='nearest'</em>, <em class="sig-param">align_corners=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/upsampling.html#Upsample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.Upsample" title="Permalink to this definition">¶</a></dt>
<dd><p>Upsamples a given multi-channel 1D (temporal), 2D (spatial) or 3D (volumetric) data.</p>
<p>The input data is assumed to be of the form
<cite>minibatch x channels x [optional depth] x [optional height] x width</cite>.
Hence, for spatial inputs, we expect a 4D Tensor and for volumetric inputs, we expect a 5D Tensor.</p>
<p>The algorithms available for upsampling are nearest neighbor and linear,
bilinear, bicubic and trilinear for 3D, 4D and 5D input Tensor,
respectively.</p>
<p>One can either give a <code class="xref py py-attr docutils literal notranslate"><span class="pre">scale_factor</span></code> or the target output <code class="xref py py-attr docutils literal notranslate"><span class="pre">size</span></code> to
calculate the output size. (You cannot give both, as it is ambiguous)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>] or </em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>] or </em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>]</em><em>, </em><em>optional</em>) – output spatial sizes</p></li>
<li><p><strong>scale_factor</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>] or </em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>] or </em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>]</em><em>, </em><em>optional</em>) – multiplier for spatial size. Has to match input size if it is a tuple.</p></li>
<li><p><strong>mode</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em>) – the upsampling algorithm: one of <code class="docutils literal notranslate"><span class="pre">'nearest'</span></code>,
<code class="docutils literal notranslate"><span class="pre">'linear'</span></code>, <code class="docutils literal notranslate"><span class="pre">'bilinear'</span></code>, <code class="docutils literal notranslate"><span class="pre">'bicubic'</span></code> and <code class="docutils literal notranslate"><span class="pre">'trilinear'</span></code>.
Default: <code class="docutils literal notranslate"><span class="pre">'nearest'</span></code></p></li>
<li><p><strong>align_corners</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, the corner pixels of the input
and output tensors are aligned, and thus preserving the values at
those pixels. This only has effect when <code class="xref py py-attr docutils literal notranslate"><span class="pre">mode</span></code> is
<code class="docutils literal notranslate"><span class="pre">'linear'</span></code>, <code class="docutils literal notranslate"><span class="pre">'bilinear'</span></code>, or <code class="docutils literal notranslate"><span class="pre">'trilinear'</span></code>. Default: <code class="docutils literal notranslate"><span class="pre">False</span></code></p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/09563747a48925dba1e37d3eb2a1b97f9bdfb2ed.svg" alt="(N, C, W_{in})"/>, <img class="math" src="_images/math/b7920897893b3a5399125387ef94f5084ff3d283.svg" alt="(N, C, H_{in}, W_{in})"/> or <img class="math" src="_images/math/4b57572f196d556e35bdc4edfa15573c3c68b667.svg" alt="(N, C, D_{in}, H_{in}, W_{in})"/></p></li>
<li><p>Output: <img class="math" src="_images/math/f68d1c24a459d81e851e068bc3107f13193c4362.svg" alt="(N, C, W_{out})"/>, <img class="math" src="_images/math/4026633441f65aa86208d4b12337149db951eab6.svg" alt="(N, C, H_{out}, W_{out})"/>
or <img class="math" src="_images/math/c01ac11b86bf5ae0b82c88e6bec50ac4ab4a8c15.svg" alt="(N, C, D_{out}, H_{out}, W_{out})"/>, where</p></li>
</ul>
</dd>
</dl>
<div class="math">
<p><img src="_images/math/ff6ab34c2c6d1fa8520b46a59e1032d4268b692d.svg" alt="D_{out} = \left\lfloor D_{in} \times \text{scale\_factor} \right\rfloor"/></p>
</div><div class="math">
<p><img src="_images/math/4347565003c428044d3715ec5f7b48f024591a82.svg" alt="H_{out} = \left\lfloor H_{in} \times \text{scale\_factor} \right\rfloor"/></p>
</div><div class="math">
<p><img src="_images/math/c9b6f98183e45ece0fa0488576edbf079c4316b0.svg" alt="W_{out} = \left\lfloor W_{in} \times \text{scale\_factor} \right\rfloor"/></p>
</div><div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>With <code class="docutils literal notranslate"><span class="pre">align_corners</span> <span class="pre">=</span> <span class="pre">True</span></code>, the linearly interpolating modes
(<cite>linear</cite>, <cite>bilinear</cite>, <cite>bicubic</cite>, and <cite>trilinear</cite>) don’t proportionally
align the output and input pixels, and thus the output values can depend
on the input size. This was the default behavior for these modes up to
version 0.3.1. Since then, the default behavior is
<code class="docutils literal notranslate"><span class="pre">align_corners</span> <span class="pre">=</span> <span class="pre">False</span></code>. See below for concrete examples on how this
affects the outputs.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you want downsampling/general resizing, you should use <code class="xref py py-func docutils literal notranslate"><span class="pre">interpolate()</span></code>.</p>
</div>
<p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span>
<span class="go">tensor([[[[ 1.,  2.],</span>
<span class="go">          [ 3.,  4.]]]])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Upsample</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[[ 1.,  1.,  2.,  2.],</span>
<span class="go">          [ 1.,  1.,  2.,  2.],</span>
<span class="go">          [ 3.,  3.,  4.,  4.],</span>
<span class="go">          [ 3.,  3.,  4.,  4.]]]])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Upsample</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;bilinear&#39;</span><span class="p">)</span>  <span class="c1"># align_corners=False</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[[ 1.0000,  1.2500,  1.7500,  2.0000],</span>
<span class="go">          [ 1.5000,  1.7500,  2.2500,  2.5000],</span>
<span class="go">          [ 2.5000,  2.7500,  3.2500,  3.5000],</span>
<span class="go">          [ 3.0000,  3.2500,  3.7500,  4.0000]]]])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Upsample</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;bilinear&#39;</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[[ 1.0000,  1.3333,  1.6667,  2.0000],</span>
<span class="go">          [ 1.6667,  2.0000,  2.3333,  2.6667],</span>
<span class="go">          [ 2.3333,  2.6667,  3.0000,  3.3333],</span>
<span class="go">          [ 3.0000,  3.3333,  3.6667,  4.0000]]]])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Try scaling the same data in a larger tensor</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_3x3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_3x3</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="p">:</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[[ 1.,  2.],</span>
<span class="go">          [ 3.,  4.]]]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">input_3x3</span>
<span class="go">tensor([[[[ 1.,  2.,  0.],</span>
<span class="go">          [ 3.,  4.,  0.],</span>
<span class="go">          [ 0.,  0.,  0.]]]])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Upsample</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;bilinear&#39;</span><span class="p">)</span>  <span class="c1"># align_corners=False</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Notice that values in top left corner are the same with the small input (except at boundary)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="p">(</span><span class="n">input_3x3</span><span class="p">)</span>
<span class="go">tensor([[[[ 1.0000,  1.2500,  1.7500,  1.5000,  0.5000,  0.0000],</span>
<span class="go">          [ 1.5000,  1.7500,  2.2500,  1.8750,  0.6250,  0.0000],</span>
<span class="go">          [ 2.5000,  2.7500,  3.2500,  2.6250,  0.8750,  0.0000],</span>
<span class="go">          [ 2.2500,  2.4375,  2.8125,  2.2500,  0.7500,  0.0000],</span>
<span class="go">          [ 0.7500,  0.8125,  0.9375,  0.7500,  0.2500,  0.0000],</span>
<span class="go">          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Upsample</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;bilinear&#39;</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Notice that values in top left corner are now changed</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="p">(</span><span class="n">input_3x3</span><span class="p">)</span>
<span class="go">tensor([[[[ 1.0000,  1.4000,  1.8000,  1.6000,  0.8000,  0.0000],</span>
<span class="go">          [ 1.8000,  2.2000,  2.6000,  2.2400,  1.1200,  0.0000],</span>
<span class="go">          [ 2.6000,  3.0000,  3.4000,  2.8800,  1.4400,  0.0000],</span>
<span class="go">          [ 2.4000,  2.7200,  3.0400,  2.5600,  1.2800,  0.0000],</span>
<span class="go">          [ 1.2000,  1.3600,  1.5200,  1.2800,  0.6400,  0.0000],</span>
<span class="go">          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]]])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="upsamplingnearest2d">
<h3><span class="hidden-section">UpsamplingNearest2d</span><a class="headerlink" href="#upsamplingnearest2d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.UpsamplingNearest2d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">UpsamplingNearest2d</code><span class="sig-paren">(</span><em class="sig-param">size=None</em>, <em class="sig-param">scale_factor=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/upsampling.html#UpsamplingNearest2d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.UpsamplingNearest2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a 2D nearest neighbor upsampling to an input signal composed of several input
channels.</p>
<p>To specify the scale, it takes either the <code class="xref py py-attr docutils literal notranslate"><span class="pre">size</span></code> or the <code class="xref py py-attr docutils literal notranslate"><span class="pre">scale_factor</span></code>
as it’s constructor argument.</p>
<p>When <code class="xref py py-attr docutils literal notranslate"><span class="pre">size</span></code> is given, it is the output size of the image <cite>(h, w)</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>]</em><em>, </em><em>optional</em>) – output spatial sizes</p></li>
<li><p><strong>scale_factor</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>]</em><em>, </em><em>optional</em>) – multiplier for
spatial size.</p></li>
</ul>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This class is deprecated in favor of <code class="xref py py-func docutils literal notranslate"><span class="pre">interpolate()</span></code>.</p>
</div>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/b7920897893b3a5399125387ef94f5084ff3d283.svg" alt="(N, C, H_{in}, W_{in})"/></p></li>
<li><p>Output: <img class="math" src="_images/math/4026633441f65aa86208d4b12337149db951eab6.svg" alt="(N, C, H_{out}, W_{out})"/> where</p></li>
</ul>
</dd>
</dl>
<div class="math">
<p><img src="_images/math/4347565003c428044d3715ec5f7b48f024591a82.svg" alt="H_{out} = \left\lfloor H_{in} \times \text{scale\_factor} \right\rfloor"/></p>
</div><div class="math">
<p><img src="_images/math/c9b6f98183e45ece0fa0488576edbf079c4316b0.svg" alt="W_{out} = \left\lfloor W_{in} \times \text{scale\_factor} \right\rfloor"/></p>
</div><p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span>
<span class="go">tensor([[[[ 1.,  2.],</span>
<span class="go">          [ 3.,  4.]]]])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">UpsamplingNearest2d</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[[ 1.,  1.,  2.,  2.],</span>
<span class="go">          [ 1.,  1.,  2.,  2.],</span>
<span class="go">          [ 3.,  3.,  4.,  4.],</span>
<span class="go">          [ 3.,  3.,  4.,  4.]]]])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="upsamplingbilinear2d">
<h3><span class="hidden-section">UpsamplingBilinear2d</span><a class="headerlink" href="#upsamplingbilinear2d" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.UpsamplingBilinear2d">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">UpsamplingBilinear2d</code><span class="sig-paren">(</span><em class="sig-param">size=None</em>, <em class="sig-param">scale_factor=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/modules/upsampling.html#UpsamplingBilinear2d"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.UpsamplingBilinear2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies a 2D bilinear upsampling to an input signal composed of several input
channels.</p>
<p>To specify the scale, it takes either the <code class="xref py py-attr docutils literal notranslate"><span class="pre">size</span></code> or the <code class="xref py py-attr docutils literal notranslate"><span class="pre">scale_factor</span></code>
as it’s constructor argument.</p>
<p>When <code class="xref py py-attr docutils literal notranslate"><span class="pre">size</span></code> is given, it is the output size of the image <cite>(h, w)</cite>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>]</em><em>, </em><em>optional</em>) – output spatial sizes</p></li>
<li><p><strong>scale_factor</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><em>Tuple</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>]</em><em>, </em><em>optional</em>) – multiplier for
spatial size.</p></li>
</ul>
</dd>
</dl>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This class is deprecated in favor of <code class="xref py py-func docutils literal notranslate"><span class="pre">interpolate()</span></code>. It is
equivalent to <code class="docutils literal notranslate"><span class="pre">nn.functional.interpolate(...,</span> <span class="pre">mode='bilinear',</span> <span class="pre">align_corners=True)</span></code>.</p>
</div>
<dl class="simple">
<dt>Shape:</dt><dd><ul class="simple">
<li><p>Input: <img class="math" src="_images/math/b7920897893b3a5399125387ef94f5084ff3d283.svg" alt="(N, C, H_{in}, W_{in})"/></p></li>
<li><p>Output: <img class="math" src="_images/math/4026633441f65aa86208d4b12337149db951eab6.svg" alt="(N, C, H_{out}, W_{out})"/> where</p></li>
</ul>
</dd>
</dl>
<div class="math">
<p><img src="_images/math/4347565003c428044d3715ec5f7b48f024591a82.svg" alt="H_{out} = \left\lfloor H_{in} \times \text{scale\_factor} \right\rfloor"/></p>
</div><div class="math">
<p><img src="_images/math/c9b6f98183e45ece0fa0488576edbf079c4316b0.svg" alt="W_{out} = \left\lfloor W_{in} \times \text{scale\_factor} \right\rfloor"/></p>
</div><p>Examples:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">input</span>
<span class="go">tensor([[[[ 1.,  2.],</span>
<span class="go">          [ 3.,  4.]]]])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">UpsamplingBilinear2d</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="go">tensor([[[[ 1.0000,  1.3333,  1.6667,  2.0000],</span>
<span class="go">          [ 1.6667,  2.0000,  2.3333,  2.6667],</span>
<span class="go">          [ 2.3333,  2.6667,  3.0000,  3.3333],</span>
<span class="go">          [ 3.0000,  3.3333,  3.6667,  4.0000]]]])</span>
</pre></div>
</div>
</dd></dl>

</div>
</div>
<div class="section" id="dataparallel-layers-multi-gpu-distributed">
<h2>DataParallel layers (multi-GPU, distributed)<a class="headerlink" href="#dataparallel-layers-multi-gpu-distributed" title="Permalink to this headline">¶</a></h2>
<div class="section" id="dataparallel">
<h3><span class="hidden-section">DataParallel</span><a class="headerlink" href="#dataparallel" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.DataParallel">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.</code><code class="sig-name descname">DataParallel</code><span class="sig-paren">(</span><em class="sig-param">module</em>, <em class="sig-param">device_ids=None</em>, <em class="sig-param">output_device=None</em>, <em class="sig-param">dim=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/parallel/data_parallel.html#DataParallel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.DataParallel" title="Permalink to this definition">¶</a></dt>
<dd><p>Implements data parallelism at the module level.</p>
<p>This container parallelizes the application of the given <code class="xref py py-attr docutils literal notranslate"><span class="pre">module</span></code> by
splitting the input across the specified devices by chunking in the batch
dimension (other objects will be copied once per device). In the forward
pass, the module is replicated on each device, and each replica handles a
portion of the input. During the backwards pass, gradients from each replica
are summed into the original module.</p>
<p>The batch size should be larger than the number of GPUs used.</p>
<p>See also: <a class="reference internal" href="notes/cuda.html#cuda-nn-dataparallel-instead"><span class="std std-ref">Use nn.DataParallel instead of multiprocessing</span></a></p>
<p>Arbitrary positional and keyword inputs are allowed to be passed into
DataParallel but some types are specially handled. tensors will be
<strong>scattered</strong> on dim specified (default 0). tuple, list and dict types will
be shallow copied. The other types will be shared among different threads
and can be corrupted if written to in the model’s forward pass.</p>
<p>The parallelized <code class="xref py py-attr docutils literal notranslate"><span class="pre">module</span></code> must have its parameters and buffers on
<code class="docutils literal notranslate"><span class="pre">device_ids[0]</span></code> before running this <a class="reference internal" href="#torch.nn.DataParallel" title="torch.nn.DataParallel"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataParallel</span></code></a>
module.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>In each forward, <code class="xref py py-attr docutils literal notranslate"><span class="pre">module</span></code> is <strong>replicated</strong> on each device, so any
updates to the running module in <code class="docutils literal notranslate"><span class="pre">forward</span></code> will be lost. For example,
if <code class="xref py py-attr docutils literal notranslate"><span class="pre">module</span></code> has a counter attribute that is incremented in each
<code class="docutils literal notranslate"><span class="pre">forward</span></code>, it will always stay at the initial value because the update
is done on the replicas which are destroyed after <code class="docutils literal notranslate"><span class="pre">forward</span></code>. However,
<a class="reference internal" href="#torch.nn.DataParallel" title="torch.nn.DataParallel"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataParallel</span></code></a> guarantees that the replica on
<code class="docutils literal notranslate"><span class="pre">device[0]</span></code> will have its parameters and buffers sharing storage with
the base parallelized <code class="xref py py-attr docutils literal notranslate"><span class="pre">module</span></code>. So <strong>in-place</strong> updates to the
parameters or buffers on <code class="docutils literal notranslate"><span class="pre">device[0]</span></code> will be recorded. E.g.,
<a class="reference internal" href="#torch.nn.BatchNorm2d" title="torch.nn.BatchNorm2d"><code class="xref py py-class docutils literal notranslate"><span class="pre">BatchNorm2d</span></code></a> and <a class="reference internal" href="#torch.nn.utils.spectral_norm" title="torch.nn.utils.spectral_norm"><code class="xref py py-func docutils literal notranslate"><span class="pre">spectral_norm()</span></code></a>
rely on this behavior to update the buffers.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Forward and backward hooks defined on <code class="xref py py-attr docutils literal notranslate"><span class="pre">module</span></code> and its submodules
will be invoked <code class="docutils literal notranslate"><span class="pre">len(device_ids)</span></code> times, each with inputs located on
a particular device. Particularly, the hooks are only guaranteed to be
executed in correct order with respect to operations on corresponding
devices. For example, it is not guaranteed that hooks set via
<a class="reference internal" href="#torch.nn.Module.register_forward_pre_hook" title="torch.nn.Module.register_forward_pre_hook"><code class="xref py py-meth docutils literal notranslate"><span class="pre">register_forward_pre_hook()</span></code></a> be executed before
<cite>all</cite> <code class="docutils literal notranslate"><span class="pre">len(device_ids)</span></code> <a class="reference internal" href="#torch.nn.Module.forward" title="torch.nn.Module.forward"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code></a> calls, but
that each such hook be executed before the corresponding
<a class="reference internal" href="#torch.nn.Module.forward" title="torch.nn.Module.forward"><code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code></a> call of that device.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When <code class="xref py py-attr docutils literal notranslate"><span class="pre">module</span></code> returns a scalar (i.e., 0-dimensional tensor) in
<code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code>, this wrapper will return a vector of length equal to
number of devices used in data parallelism, containing the result from
each device.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>There is a subtlety in using the
<code class="docutils literal notranslate"><span class="pre">pack</span> <span class="pre">sequence</span> <span class="pre">-&gt;</span> <span class="pre">recurrent</span> <span class="pre">network</span> <span class="pre">-&gt;</span> <span class="pre">unpack</span> <span class="pre">sequence</span></code> pattern in a
<a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a> wrapped in <a class="reference internal" href="#torch.nn.DataParallel" title="torch.nn.DataParallel"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataParallel</span></code></a>.
See <a class="reference internal" href="notes/faq.html#pack-rnn-unpack-with-data-parallelism"><span class="std std-ref">My recurrent network doesn’t work with data parallelism</span></a> section in FAQ for
details.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> (<a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module"><em>Module</em></a>) – module to be parallelized</p></li>
<li><p><strong>device_ids</strong> (<em>list of python:int</em><em> or </em><a class="reference internal" href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><em>torch.device</em></a>) – CUDA devices (default: all devices)</p></li>
<li><p><strong>output_device</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference internal" href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><em>torch.device</em></a>) – device location of output (default: device_ids[0])</p></li>
</ul>
</dd>
<dt class="field-even">Variables</dt>
<dd class="field-even"><p><strong>~DataParallel.module</strong> (<a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module"><em>Module</em></a>) – the module to be parallelized</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">DataParallel</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device_ids</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">input_var</span><span class="p">)</span>  <span class="c1"># input_var can be on any device, including CPU</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="distributeddataparallel">
<h3><span class="hidden-section">DistributedDataParallel</span><a class="headerlink" href="#distributeddataparallel" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="torch.nn.parallel.DistributedDataParallel">
<em class="property">class </em><code class="sig-prename descclassname">torch.nn.parallel.</code><code class="sig-name descname">DistributedDataParallel</code><span class="sig-paren">(</span><em class="sig-param">module</em>, <em class="sig-param">device_ids=None</em>, <em class="sig-param">output_device=None</em>, <em class="sig-param">dim=0</em>, <em class="sig-param">broadcast_buffers=True</em>, <em class="sig-param">process_group=None</em>, <em class="sig-param">bucket_cap_mb=25</em>, <em class="sig-param">find_unused_parameters=False</em>, <em class="sig-param">check_reduction=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/parallel/distributed.html#DistributedDataParallel"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.parallel.DistributedDataParallel" title="Permalink to this definition">¶</a></dt>
<dd><p>Implements distributed data parallelism that is based on
<code class="docutils literal notranslate"><span class="pre">torch.distributed</span></code> package at the module level.</p>
<p>This container parallelizes the application of the given module by
splitting the input across the specified devices by chunking in the batch
dimension. The module is replicated on each machine and each device, and
each such replica handles a portion of the input. During the backwards
pass, gradients from each node are averaged.</p>
<p>The batch size should be larger than the number of GPUs used locally.</p>
<p>See also: <a class="reference internal" href="distributed.html#distributed-basics"><span class="std std-ref">Basics</span></a> and <a class="reference internal" href="notes/cuda.html#cuda-nn-dataparallel-instead"><span class="std std-ref">Use nn.DataParallel instead of multiprocessing</span></a>.
The same constraints on input as in <a class="reference internal" href="#torch.nn.DataParallel" title="torch.nn.DataParallel"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.DataParallel</span></code></a> apply.</p>
<p>Creation of this class requires that <code class="docutils literal notranslate"><span class="pre">torch.distributed</span></code> to be already
initialized, by calling <code class="xref py py-func docutils literal notranslate"><span class="pre">torch.distributed.init_process_group()</span></code>.</p>
<p><code class="docutils literal notranslate"><span class="pre">DistributedDataParallel</span></code> can be used in the following two ways:</p>
<ol class="arabic simple">
<li><p>Single-Process Multi-GPU</p></li>
</ol>
<p>In this case, a single process will be
spawned on each host/node and each process will operate on all the GPUs
of the node where it’s running. To use <code class="docutils literal notranslate"><span class="pre">DistributedDataParallel</span></code> in
this way, you can simply construct the model as the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s2">&quot;nccl&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">DistributedDataParallel</span><span class="p">(</span><span class="n">model</span><span class="p">)</span> <span class="c1"># device_ids will include all GPU devices by default</span>
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>Multi-Process Single-GPU</p></li>
</ol>
<p>This is the highly recommended way to use <code class="docutils literal notranslate"><span class="pre">DistributedDataParallel</span></code>, with
multiple processes, each of which operates on a single GPU. This is
currently the fastest approach to do data parallel training using PyTorch
and applies to both single-node(multi-GPU) and multi-node data
parallel training. It is proven to be significantly faster than
<a class="reference internal" href="#torch.nn.DataParallel" title="torch.nn.DataParallel"><code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.DataParallel</span></code></a> for single-node multi-GPU data
parallel training.</p>
<p>Here is how to use it: on each host with N GPUs, you should spawn up N
processes, while ensuring that each process individually works on a single GPU
from 0 to N-1. Therefore, it is your job to ensure that your training script
operates on a single given GPU by calling:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">set_device</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
</pre></div>
</div>
<p>where i is from 0 to N-1. In each process, you should refer the following
to construct this module:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s1">&#39;nccl&#39;</span><span class="p">,</span> <span class="n">world_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">init_method</span><span class="o">=</span><span class="s1">&#39;...&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">DistributedDataParallel</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">device_ids</span><span class="o">=</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">output_device</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
</pre></div>
</div>
<p>In order to spawn up multiple processes per node, you can use either
<code class="docutils literal notranslate"><span class="pre">torch.distributed.launch</span></code> or <code class="docutils literal notranslate"><span class="pre">torch.multiprocessing.spawn</span></code></p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">nccl</span></code> backend is currently the fastest and
highly recommended backend to be used with Multi-Process Single-GPU
distributed training and this applies to both single-node and multi-node
distributed training</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This module also supports mixed-precision distributed training.
This means that your model can have different types of parameters such
as mixed types of fp16 and fp32, the gradient reduction on these
mixed types of parameters will just work fine.
Also note that <code class="docutils literal notranslate"><span class="pre">nccl</span></code> backend is currently the fastest and highly
recommended backend for fp16/fp32 mixed-precision training.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you use <code class="docutils literal notranslate"><span class="pre">torch.save</span></code> on one process to checkpoint the module,
and <code class="docutils literal notranslate"><span class="pre">torch.load</span></code> on some other processes to recover it, make sure that
<code class="docutils literal notranslate"><span class="pre">map_location</span></code> is configured properly for every process. Without
<code class="docutils literal notranslate"><span class="pre">map_location</span></code>, <code class="docutils literal notranslate"><span class="pre">torch.load</span></code> would recover the module to devices
where the module was saved from.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This module works only with the <code class="docutils literal notranslate"><span class="pre">gloo</span></code> and <code class="docutils literal notranslate"><span class="pre">nccl</span></code> backends.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Constructor, forward method, and differentiation of the output (or a
function of the output of this module) is a distributed synchronization
point. Take that into account in case different processes might be
executing different code.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This module assumes all parameters are registered in the model by the
time it is created. No parameters should be added nor removed later.
Same applies to buffers.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This module assumes all parameters are registered in the model of each
distributed processes are in the same order. The module itself will
conduct gradient all-reduction following the reverse order of the
registered parameters of the model. In other words, it is users’
responsibility to ensure that each distributed process has the exact
same model and thus the exact same parameter registration order.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This module assumes all buffers and gradients are dense.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This module doesn’t work with <a class="reference internal" href="autograd.html#torch.autograd.grad" title="torch.autograd.grad"><code class="xref py py-func docutils literal notranslate"><span class="pre">torch.autograd.grad()</span></code></a> (i.e. it will
only work if gradients are to be accumulated in <code class="docutils literal notranslate"><span class="pre">.grad</span></code> attributes of
parameters).</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>If you plan on using this module with a <code class="docutils literal notranslate"><span class="pre">nccl</span></code> backend or a <code class="docutils literal notranslate"><span class="pre">gloo</span></code>
backend (that uses Infiniband), together with a DataLoader that uses
multiple workers, please change the multiprocessing start method to
<code class="docutils literal notranslate"><span class="pre">forkserver</span></code> (Python 3 only) or <code class="docutils literal notranslate"><span class="pre">spawn</span></code>. Unfortunately
Gloo (that uses Infiniband) and NCCL2 are not fork safe, and you will
likely experience deadlocks if you don’t change this setting.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>Forward and backward hooks defined on <code class="xref py py-attr docutils literal notranslate"><span class="pre">module</span></code> and its submodules
won’t be invoked anymore, unless the hooks are initialized in the
<code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code> method.</p>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>You should never try to change your model’s parameters after wrapping
up your model with DistributedDataParallel. In other words, when
wrapping up your model with DistributedDataParallel, the constructor of
DistributedDataParallel will register the additional gradient
reduction functions on all the parameters of the model itself at the
time of construction. If you change the model’s parameters after
the DistributedDataParallel construction, this is not supported and
unexpected behaviors can happen, since some parameters’ gradient
reduction functions might not get called.</p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Parameters are never broadcast between processes. The module performs
an all-reduce step on gradients and assumes that they will be modified
by the optimizer in all processes in the same way. Buffers
(e.g. BatchNorm stats) are broadcast from the module in process of rank
0, to all other replicas in the system in every iteration.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> (<a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module"><em>Module</em></a>) – module to be parallelized</p></li>
<li><p><strong>device_ids</strong> (<em>list of python:int</em><em> or </em><a class="reference internal" href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><em>torch.device</em></a>) – CUDA devices. This should
only be provided when the input module resides on a single
CUDA device. For single-device modules, the <code class="docutils literal notranslate"><span class="pre">i``th</span>
<span class="pre">:attr:`module`</span> <span class="pre">replica</span> <span class="pre">is</span> <span class="pre">placed</span> <span class="pre">on</span> <span class="pre">``device_ids[i]</span></code>. For
multi-device modules and CPU modules, device_ids must be None
or an empty list, and input data for the forward pass must be
placed on the correct device. (default: all devices for
single-device modules)</p></li>
<li><p><strong>output_device</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><a class="reference internal" href="tensor_attributes.html#torch.torch.device" title="torch.torch.device"><em>torch.device</em></a>) – device location of output for
single-device CUDA modules. For multi-device modules and
CPU modules, it must be None, and the module itself
dictates the output location. (default: device_ids[0] for
single-device modules)</p></li>
<li><p><strong>broadcast_buffers</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – flag that enables syncing (broadcasting) buffers of
the module at beginning of the forward function.
(default: <code class="docutils literal notranslate"><span class="pre">True</span></code>)</p></li>
<li><p><strong>process_group</strong> – the process group to be used for distributed data
all-reduction. If <code class="docutils literal notranslate"><span class="pre">None</span></code>, the default process group, which
is created by <code class="docutils literal notranslate"><span class="pre">`torch.distributed.init_process_group`</span></code>,
will be used. (default: <code class="docutils literal notranslate"><span class="pre">None</span></code>)</p></li>
<li><p><strong>bucket_cap_mb</strong> – DistributedDataParallel will bucket parameters into
multiple buckets so that gradient reduction of each
bucket can potentially overlap with backward computation.
<code class="xref py py-attr docutils literal notranslate"><span class="pre">bucket_cap_mb</span></code> controls the bucket size in MegaBytes (MB)
(default: 25)</p></li>
<li><p><strong>find_unused_parameters</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a>) – Traverse the autograd graph of all tensors
contained in the return value of the wrapped
module’s <code class="docutils literal notranslate"><span class="pre">forward</span></code> function.
Parameters that don’t receive gradients as
part of this graph are preemptively marked
as being ready to be reduced. Note that all
<code class="docutils literal notranslate"><span class="pre">forward</span></code> outputs that are derived from
module parameters must participate in
calculating loss and later the gradient
computation. If they don’t, this wrapper will
hang waiting for autograd to produce gradients
for those parameters. Any outputs derived from
module parameters that are otherwise unused can
be detached from the autograd graph using
<code class="docutils literal notranslate"><span class="pre">torch.Tensor.detach</span></code>. (default: <code class="docutils literal notranslate"><span class="pre">False</span></code>)</p></li>
<li><p><strong>check_reduction</strong> – when setting to <code class="docutils literal notranslate"><span class="pre">True</span></code>, it enables DistributedDataParallel
to automatically check if the previous iteration’s
backward reductions were successfully issued at the
beginning of every iteration’s forward function.
You normally don’t need this option enabled unless you
are observing weird behaviors such as different ranks
are getting different gradients, which should not
happen if DistributedDataParallel is correctly used.
(default: <code class="docutils literal notranslate"><span class="pre">False</span></code>)</p></li>
</ul>
</dd>
<dt class="field-even">Variables</dt>
<dd class="field-even"><p><strong>~DistributedDataParallel.module</strong> (<a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module"><em>Module</em></a>) – the module to be parallelized</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">torch</span><span class="o">.</span><span class="n">distributed</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span><span class="n">backend</span><span class="o">=</span><span class="s1">&#39;nccl&#39;</span><span class="p">,</span> <span class="n">world_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">init_method</span><span class="o">=</span><span class="s1">&#39;...&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">net</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">DistributedDataParallel</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">pg</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="torch.nn.parallel.DistributedDataParallel.no_sync">
<code class="sig-name descname">no_sync</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/parallel/distributed.html#DistributedDataParallel.no_sync"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.parallel.DistributedDataParallel.no_sync" title="Permalink to this definition">¶</a></dt>
<dd><p>A context manager to disable gradient synchronizations across DDP
processes. Within this context, gradients will be accumulated on module
variables, which will later be synchronized in the first
forward-backward pass exiting the context.</p>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">ddp</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">DistributedDataParallel</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">pg</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">ddp</span><span class="o">.</span><span class="n">no_sync</span><span class="p">():</span>
<span class="gp">... </span>  <span class="k">for</span> <span class="nb">input</span> <span class="ow">in</span> <span class="n">inputs</span><span class="p">:</span>
<span class="gp">... </span>    <span class="n">ddp</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>  <span class="c1"># no synchronization, accumulate grads</span>
<span class="gp">... </span><span class="n">ddp</span><span class="p">(</span><span class="n">another_input</span><span class="p">)</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>  <span class="c1"># synchronize grads</span>
</pre></div>
</div>
</dd></dl>

</dd></dl>

</div>
</div>
<div class="section" id="utilities">
<h2>Utilities<a class="headerlink" href="#utilities" title="Permalink to this headline">¶</a></h2>
<div class="section" id="clip-grad-norm">
<h3><span class="hidden-section">clip_grad_norm_</span><a class="headerlink" href="#clip-grad-norm" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="torch.nn.utils.clip_grad_norm_">
<code class="sig-prename descclassname">torch.nn.utils.</code><code class="sig-name descname">clip_grad_norm_</code><span class="sig-paren">(</span><em class="sig-param">parameters</em>, <em class="sig-param">max_norm</em>, <em class="sig-param">norm_type=2</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/utils/clip_grad.html#clip_grad_norm_"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.utils.clip_grad_norm_" title="Permalink to this definition">¶</a></dt>
<dd><p>Clips gradient norm of an iterable of parameters.</p>
<p>The norm is computed over all gradients together, as if they were
concatenated into a single vector. Gradients are modified in-place.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>parameters</strong> (<em>Iterable</em><em>[</em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>] or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – an iterable of Tensors or a
single Tensor that will have gradients normalized</p></li>
<li><p><strong>max_norm</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – max norm of the gradients</p></li>
<li><p><strong>norm_type</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – type of the used p-norm. Can be <code class="docutils literal notranslate"><span class="pre">'inf'</span></code> for
infinity norm.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Total norm of the parameters (viewed as a single vector).</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="clip-grad-value">
<h3><span class="hidden-section">clip_grad_value_</span><a class="headerlink" href="#clip-grad-value" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="torch.nn.utils.clip_grad_value_">
<code class="sig-prename descclassname">torch.nn.utils.</code><code class="sig-name descname">clip_grad_value_</code><span class="sig-paren">(</span><em class="sig-param">parameters</em>, <em class="sig-param">clip_value</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/utils/clip_grad.html#clip_grad_value_"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.utils.clip_grad_value_" title="Permalink to this definition">¶</a></dt>
<dd><p>Clips gradient of an iterable of parameters at specified value.</p>
<p>Gradients are modified in-place.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>parameters</strong> (<em>Iterable</em><em>[</em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>] or </em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – an iterable of Tensors or a
single Tensor that will have gradients normalized</p></li>
<li><p><strong>clip_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – maximum allowed value of the gradients.
The gradients are clipped in the range
<img class="math" src="_images/math/460c71b9316bf2456e980049083ddc6fcf5c927d.svg" alt="\left[\text{-clip\_value}, \text{clip\_value}\right]"/></p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="parameters-to-vector">
<h3><span class="hidden-section">parameters_to_vector</span><a class="headerlink" href="#parameters-to-vector" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="torch.nn.utils.parameters_to_vector">
<code class="sig-prename descclassname">torch.nn.utils.</code><code class="sig-name descname">parameters_to_vector</code><span class="sig-paren">(</span><em class="sig-param">parameters</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/utils/convert_parameters.html#parameters_to_vector"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.utils.parameters_to_vector" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert parameters to one vector</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>parameters</strong> (<em>Iterable</em><em>[</em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>]</em>) – an iterator of Tensors that are the
parameters of a model.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The parameters represented by a single vector</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="vector-to-parameters">
<h3><span class="hidden-section">vector_to_parameters</span><a class="headerlink" href="#vector-to-parameters" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="torch.nn.utils.vector_to_parameters">
<code class="sig-prename descclassname">torch.nn.utils.</code><code class="sig-name descname">vector_to_parameters</code><span class="sig-paren">(</span><em class="sig-param">vec</em>, <em class="sig-param">parameters</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/utils/convert_parameters.html#vector_to_parameters"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.utils.vector_to_parameters" title="Permalink to this definition">¶</a></dt>
<dd><p>Convert one vector to the parameters</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>vec</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – a single vector represents the parameters of a model.</p></li>
<li><p><strong>parameters</strong> (<em>Iterable</em><em>[</em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>]</em>) – an iterator of Tensors that are the
parameters of a model.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="weight-norm">
<h3><span class="hidden-section">weight_norm</span><a class="headerlink" href="#weight-norm" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="torch.nn.utils.weight_norm">
<code class="sig-prename descclassname">torch.nn.utils.</code><code class="sig-name descname">weight_norm</code><span class="sig-paren">(</span><em class="sig-param">module</em>, <em class="sig-param">name='weight'</em>, <em class="sig-param">dim=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/utils/weight_norm.html#weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.utils.weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies weight normalization to a parameter in the given module.</p>
<div class="math">
<p><img src="_images/math/0d0b55fd6b7f0fd714652a7ba7a1befe7ec1710c.svg" alt="\mathbf{w} = g \dfrac{\mathbf{v}}{\|\mathbf{v}\|}"/></p>
</div><p>Weight normalization is a reparameterization that decouples the magnitude
of a weight tensor from its direction. This replaces the parameter specified
by <code class="xref py py-attr docutils literal notranslate"><span class="pre">name</span></code> (e.g. <code class="docutils literal notranslate"><span class="pre">'weight'</span></code>) with two parameters: one specifying the magnitude
(e.g. <code class="docutils literal notranslate"><span class="pre">'weight_g'</span></code>) and one specifying the direction (e.g. <code class="docutils literal notranslate"><span class="pre">'weight_v'</span></code>).
Weight normalization is implemented via a hook that recomputes the weight
tensor from the magnitude and direction before every <code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code>
call.</p>
<p>By default, with <code class="docutils literal notranslate"><span class="pre">dim=0</span></code>, the norm is computed independently per output
channel/plane. To compute a norm over the entire weight tensor, use
<code class="docutils literal notranslate"><span class="pre">dim=None</span></code>.</p>
<p>See <a class="reference external" href="https://arxiv.org/abs/1602.07868">https://arxiv.org/abs/1602.07868</a></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> (<a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module"><em>Module</em></a>) – containing module</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em>) – name of weight parameter</p></li>
<li><p><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em>) – dimension over which to compute the norm</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The original module with the weight norm hook</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">weight_norm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">40</span><span class="p">),</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;weight&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span>
<span class="go">Linear(in_features=20, out_features=40, bias=True)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">weight_g</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<span class="go">torch.Size([40, 1])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">weight_v</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<span class="go">torch.Size([40, 20])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="remove-weight-norm">
<h3><span class="hidden-section">remove_weight_norm</span><a class="headerlink" href="#remove-weight-norm" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="torch.nn.utils.remove_weight_norm">
<code class="sig-prename descclassname">torch.nn.utils.</code><code class="sig-name descname">remove_weight_norm</code><span class="sig-paren">(</span><em class="sig-param">module</em>, <em class="sig-param">name='weight'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/utils/weight_norm.html#remove_weight_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.utils.remove_weight_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Removes the weight normalization reparameterization from a module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> (<a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module"><em>Module</em></a>) – containing module</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em>) – name of weight parameter</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">weight_norm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">40</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">remove_weight_norm</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="spectral-norm">
<h3><span class="hidden-section">spectral_norm</span><a class="headerlink" href="#spectral-norm" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="torch.nn.utils.spectral_norm">
<code class="sig-prename descclassname">torch.nn.utils.</code><code class="sig-name descname">spectral_norm</code><span class="sig-paren">(</span><em class="sig-param">module</em>, <em class="sig-param">name='weight'</em>, <em class="sig-param">n_power_iterations=1</em>, <em class="sig-param">eps=1e-12</em>, <em class="sig-param">dim=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/utils/spectral_norm.html#spectral_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.utils.spectral_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Applies spectral normalization to a parameter in the given module.</p>
<div class="math">
<p><img src="_images/math/bbbbc551ec19c16b5d5d84b841ced4e3174741fb.svg" alt="\mathbf{W}_{SN} = \dfrac{\mathbf{W}}{\sigma(\mathbf{W})},
\sigma(\mathbf{W}) = \max_{\mathbf{h}: \mathbf{h} \ne 0} \dfrac{\|\mathbf{W} \mathbf{h}\|_2}{\|\mathbf{h}\|_2}"/></p>
</div><p>Spectral normalization stabilizes the training of discriminators (critics)
in Generative Adversarial Networks (GANs) by rescaling the weight tensor
with spectral norm <img class="math" src="_images/math/b52df27bfb0b1e3af0c2c68a7b9da459178c2a7d.svg" alt="\sigma"/> of the weight matrix calculated using
power iteration method. If the dimension of the weight tensor is greater
than 2, it is reshaped to 2D in power iteration method to get spectral
norm. This is implemented via a hook that calculates spectral norm and
rescales weight before every <code class="xref py py-meth docutils literal notranslate"><span class="pre">forward()</span></code> call.</p>
<p>See <a class="reference external" href="https://arxiv.org/abs/1802.05957">Spectral Normalization for Generative Adversarial Networks</a> .</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> (<a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module"><em>nn.Module</em></a>) – containing module</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em>) – name of weight parameter</p></li>
<li><p><strong>n_power_iterations</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em>) – number of power iterations to
calculate spectral norm</p></li>
<li><p><strong>eps</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em>) – epsilon for numerical stability in
calculating norms</p></li>
<li><p><strong>dim</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em>) – dimension corresponding to number of outputs,
the default is <code class="docutils literal notranslate"><span class="pre">0</span></code>, except for modules that are instances of
ConvTranspose{1,2,3}d, when it is <code class="docutils literal notranslate"><span class="pre">1</span></code></p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The original module with the spectral norm hook</p>
</dd>
</dl>
<p>Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">spectral_norm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">40</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span>
<span class="go">Linear(in_features=20, out_features=40, bias=True)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">m</span><span class="o">.</span><span class="n">weight_u</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<span class="go">torch.Size([40])</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="remove-spectral-norm">
<h3><span class="hidden-section">remove_spectral_norm</span><a class="headerlink" href="#remove-spectral-norm" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="torch.nn.utils.remove_spectral_norm">
<code class="sig-prename descclassname">torch.nn.utils.</code><code class="sig-name descname">remove_spectral_norm</code><span class="sig-paren">(</span><em class="sig-param">module</em>, <em class="sig-param">name='weight'</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/utils/spectral_norm.html#remove_spectral_norm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.utils.remove_spectral_norm" title="Permalink to this definition">¶</a></dt>
<dd><p>Removes the spectral normalization reparameterization from a module.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module</strong> (<a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module"><em>Module</em></a>) – containing module</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>optional</em>) – name of weight parameter</p></li>
</ul>
</dd>
</dl>
<p class="rubric">Example</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">m</span> <span class="o">=</span> <span class="n">spectral_norm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">remove_spectral_norm</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="packedsequence">
<h3><span class="hidden-section">PackedSequence</span><a class="headerlink" href="#packedsequence" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="torch.nn.utils.rnn.PackedSequence">
<code class="sig-prename descclassname">torch.nn.utils.rnn.</code><code class="sig-name descname">PackedSequence</code><span class="sig-paren">(</span><em class="sig-param">data</em>, <em class="sig-param">batch_sizes=None</em>, <em class="sig-param">sorted_indices=None</em>, <em class="sig-param">unsorted_indices=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/utils/rnn.html#PackedSequence"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.utils.rnn.PackedSequence" title="Permalink to this definition">¶</a></dt>
<dd><p>Holds the data and list of <code class="xref py py-attr docutils literal notranslate"><span class="pre">batch_sizes</span></code> of a packed sequence.</p>
<p>All RNN modules accept packed sequences as inputs.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Instances of this class should never be created manually. They are meant
to be instantiated by functions like <a class="reference internal" href="#torch.nn.utils.rnn.pack_padded_sequence" title="torch.nn.utils.rnn.pack_padded_sequence"><code class="xref py py-func docutils literal notranslate"><span class="pre">pack_padded_sequence()</span></code></a>.</p>
<p>Batch sizes represent the number elements at each sequence step in
the batch, not the varying sequence lengths passed to
<a class="reference internal" href="#torch.nn.utils.rnn.pack_padded_sequence" title="torch.nn.utils.rnn.pack_padded_sequence"><code class="xref py py-func docutils literal notranslate"><span class="pre">pack_padded_sequence()</span></code></a>.  For instance, given data <code class="docutils literal notranslate"><span class="pre">abc</span></code> and <code class="docutils literal notranslate"><span class="pre">x</span></code>
the <a class="reference internal" href="#torch.nn.utils.rnn.PackedSequence" title="torch.nn.utils.rnn.PackedSequence"><code class="xref py py-class docutils literal notranslate"><span class="pre">PackedSequence</span></code></a> would contain data <code class="docutils literal notranslate"><span class="pre">axbc</span></code> with
<code class="docutils literal notranslate"><span class="pre">batch_sizes=[2,1,1]</span></code>.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Variables</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>~PackedSequence.data</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – Tensor containing packed sequence</p></li>
<li><p><strong>~PackedSequence.batch_sizes</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – Tensor of integers holding
information about the batch size at each sequence step</p></li>
<li><p><strong>~PackedSequence.sorted_indices</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) – Tensor of integers holding how this
<a class="reference internal" href="#torch.nn.utils.rnn.PackedSequence" title="torch.nn.utils.rnn.PackedSequence"><code class="xref py py-class docutils literal notranslate"><span class="pre">PackedSequence</span></code></a> is constructed from sequences.</p></li>
<li><p><strong>~PackedSequence.unsorted_indices</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>, </em><em>optional</em>) – Tensor of integers holding how this
to recover the original sequences with correct order.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="xref py py-attr docutils literal notranslate"><span class="pre">data</span></code> can be on arbitrary device and of arbitrary dtype.
<code class="xref py py-attr docutils literal notranslate"><span class="pre">sorted_indices</span></code> and <code class="xref py py-attr docutils literal notranslate"><span class="pre">unsorted_indices</span></code> must be <code class="docutils literal notranslate"><span class="pre">torch.int64</span></code>
tensors on the same device as <code class="xref py py-attr docutils literal notranslate"><span class="pre">data</span></code>.</p>
<p>However, <code class="xref py py-attr docutils literal notranslate"><span class="pre">batch_sizes</span></code> should always be a CPU <code class="docutils literal notranslate"><span class="pre">torch.int64</span></code> tensor.</p>
<p>This invariant is maintained throughout <a class="reference internal" href="#torch.nn.utils.rnn.PackedSequence" title="torch.nn.utils.rnn.PackedSequence"><code class="xref py py-class docutils literal notranslate"><span class="pre">PackedSequence</span></code></a> class,
and all functions that construct a <cite>:class:PackedSequence</cite> in PyTorch
(i.e., they only pass in tensors conforming to this constraint).</p>
</div>
</dd></dl>

</div>
<div class="section" id="pack-padded-sequence">
<h3><span class="hidden-section">pack_padded_sequence</span><a class="headerlink" href="#pack-padded-sequence" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="torch.nn.utils.rnn.pack_padded_sequence">
<code class="sig-prename descclassname">torch.nn.utils.rnn.</code><code class="sig-name descname">pack_padded_sequence</code><span class="sig-paren">(</span><em class="sig-param">input</em>, <em class="sig-param">lengths</em>, <em class="sig-param">batch_first=False</em>, <em class="sig-param">enforce_sorted=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/utils/rnn.html#pack_padded_sequence"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.utils.rnn.pack_padded_sequence" title="Permalink to this definition">¶</a></dt>
<dd><p>Packs a Tensor containing padded sequences of variable length.</p>
<p><code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> can be of size <code class="docutils literal notranslate"><span class="pre">T</span> <span class="pre">x</span> <span class="pre">B</span> <span class="pre">x</span> <span class="pre">*</span></code> where <cite>T</cite> is the length of the
longest sequence (equal to <code class="docutils literal notranslate"><span class="pre">lengths[0]</span></code>), <code class="docutils literal notranslate"><span class="pre">B</span></code> is the batch size, and
<code class="docutils literal notranslate"><span class="pre">*</span></code> is any number of dimensions (including 0). If <code class="docutils literal notranslate"><span class="pre">batch_first</span></code> is
<code class="docutils literal notranslate"><span class="pre">True</span></code>, <code class="docutils literal notranslate"><span class="pre">B</span> <span class="pre">x</span> <span class="pre">T</span> <span class="pre">x</span> <span class="pre">*</span></code> <code class="xref py py-attr docutils literal notranslate"><span class="pre">input</span></code> is expected.</p>
<p>For unsorted sequences, use <cite>enforce_sorted = False</cite>. If <code class="xref py py-attr docutils literal notranslate"><span class="pre">enforce_sorted</span></code> is
<code class="docutils literal notranslate"><span class="pre">True</span></code>, the sequences should be sorted by length in a decreasing order, i.e.
<code class="docutils literal notranslate"><span class="pre">input[:,0]</span></code> should be the longest sequence, and <code class="docutils literal notranslate"><span class="pre">input[:,B-1]</span></code> the shortest
one. <cite>enforce_sorted = True</cite> is only necessary for ONNX export.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function accepts any input that has at least two dimensions. You
can apply it to pack the labels, and use the output of the RNN with
them to compute the loss directly. A Tensor can be retrieved from
a <a class="reference internal" href="#torch.nn.utils.rnn.PackedSequence" title="torch.nn.utils.rnn.PackedSequence"><code class="xref py py-class docutils literal notranslate"><span class="pre">PackedSequence</span></code></a> object by accessing its <code class="docutils literal notranslate"><span class="pre">.data</span></code> attribute.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – padded batch of variable length sequences.</p></li>
<li><p><strong>lengths</strong> (<a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a>) – list of sequences lengths of each batch element.</p></li>
<li><p><strong>batch_first</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, the input is expected in <code class="docutils literal notranslate"><span class="pre">B</span> <span class="pre">x</span> <span class="pre">T</span> <span class="pre">x</span> <span class="pre">*</span></code>
format.</p></li>
<li><p><strong>enforce_sorted</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, the input is expected to
contain sequences sorted by length in a decreasing order. If
<code class="docutils literal notranslate"><span class="pre">False</span></code>, this condition is not checked. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a <a class="reference internal" href="#torch.nn.utils.rnn.PackedSequence" title="torch.nn.utils.rnn.PackedSequence"><code class="xref py py-class docutils literal notranslate"><span class="pre">PackedSequence</span></code></a> object</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="pad-packed-sequence">
<h3><span class="hidden-section">pad_packed_sequence</span><a class="headerlink" href="#pad-packed-sequence" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="torch.nn.utils.rnn.pad_packed_sequence">
<code class="sig-prename descclassname">torch.nn.utils.rnn.</code><code class="sig-name descname">pad_packed_sequence</code><span class="sig-paren">(</span><em class="sig-param">sequence</em>, <em class="sig-param">batch_first=False</em>, <em class="sig-param">padding_value=0.0</em>, <em class="sig-param">total_length=None</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/utils/rnn.html#pad_packed_sequence"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.utils.rnn.pad_packed_sequence" title="Permalink to this definition">¶</a></dt>
<dd><p>Pads a packed batch of variable length sequences.</p>
<p>It is an inverse operation to <a class="reference internal" href="#torch.nn.utils.rnn.pack_padded_sequence" title="torch.nn.utils.rnn.pack_padded_sequence"><code class="xref py py-func docutils literal notranslate"><span class="pre">pack_padded_sequence()</span></code></a>.</p>
<p>The returned Tensor’s data will be of size <code class="docutils literal notranslate"><span class="pre">T</span> <span class="pre">x</span> <span class="pre">B</span> <span class="pre">x</span> <span class="pre">*</span></code>, where <cite>T</cite> is the length
of the longest sequence and <cite>B</cite> is the batch size. If <code class="docutils literal notranslate"><span class="pre">batch_first</span></code> is True,
the data will be transposed into <code class="docutils literal notranslate"><span class="pre">B</span> <span class="pre">x</span> <span class="pre">T</span> <span class="pre">x</span> <span class="pre">*</span></code> format.</p>
<p>Batch elements will be ordered decreasingly by their length.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="xref py py-attr docutils literal notranslate"><span class="pre">total_length</span></code> is useful to implement the
<code class="docutils literal notranslate"><span class="pre">pack</span> <span class="pre">sequence</span> <span class="pre">-&gt;</span> <span class="pre">recurrent</span> <span class="pre">network</span> <span class="pre">-&gt;</span> <span class="pre">unpack</span> <span class="pre">sequence</span></code> pattern in a
<a class="reference internal" href="#torch.nn.Module" title="torch.nn.Module"><code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></a> wrapped in <a class="reference internal" href="#torch.nn.DataParallel" title="torch.nn.DataParallel"><code class="xref py py-class docutils literal notranslate"><span class="pre">DataParallel</span></code></a>.
See <a class="reference internal" href="notes/faq.html#pack-rnn-unpack-with-data-parallelism"><span class="std std-ref">this FAQ section</span></a> for
details.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sequence</strong> (<em>PackedSequence</em>) – batch to pad</p></li>
<li><p><strong>batch_first</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, the output will be in <code class="docutils literal notranslate"><span class="pre">B</span> <span class="pre">x</span> <span class="pre">T</span> <span class="pre">x</span> <span class="pre">*</span></code>
format.</p></li>
<li><p><strong>padding_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em>) – values for padded elements.</p></li>
<li><p><strong>total_length</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em>, </em><em>optional</em>) – if not <code class="docutils literal notranslate"><span class="pre">None</span></code>, the output will be padded to
have length <code class="xref py py-attr docutils literal notranslate"><span class="pre">total_length</span></code>. This method will throw <a class="reference external" href="https://docs.python.org/3/library/exceptions.html#ValueError" title="(in Python v3.7)"><code class="xref py py-class docutils literal notranslate"><span class="pre">ValueError</span></code></a>
if <code class="xref py py-attr docutils literal notranslate"><span class="pre">total_length</span></code> is less than the max sequence length in
<code class="xref py py-attr docutils literal notranslate"><span class="pre">sequence</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tuple of Tensor containing the padded sequence, and a Tensor
containing the list of lengths of each sequence in the batch.</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="pad-sequence">
<h3><span class="hidden-section">pad_sequence</span><a class="headerlink" href="#pad-sequence" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="torch.nn.utils.rnn.pad_sequence">
<code class="sig-prename descclassname">torch.nn.utils.rnn.</code><code class="sig-name descname">pad_sequence</code><span class="sig-paren">(</span><em class="sig-param">sequences</em>, <em class="sig-param">batch_first=False</em>, <em class="sig-param">padding_value=0</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/utils/rnn.html#pad_sequence"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.utils.rnn.pad_sequence" title="Permalink to this definition">¶</a></dt>
<dd><p>Pad a list of variable length Tensors with <code class="docutils literal notranslate"><span class="pre">padding_value</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">pad_sequence</span></code> stacks a list of Tensors along a new dimension,
and pads them to equal length. For example, if the input is list of
sequences with size <code class="docutils literal notranslate"><span class="pre">L</span> <span class="pre">x</span> <span class="pre">*</span></code> and if batch_first is False, and <code class="docutils literal notranslate"><span class="pre">T</span> <span class="pre">x</span> <span class="pre">B</span> <span class="pre">x</span> <span class="pre">*</span></code>
otherwise.</p>
<p><cite>B</cite> is batch size. It is equal to the number of elements in <code class="docutils literal notranslate"><span class="pre">sequences</span></code>.
<cite>T</cite> is length of the longest sequence.
<cite>L</cite> is length of the sequence.
<cite>*</cite> is any number of trailing dimensions, including none.</p>
<p class="rubric">Example</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">torch.nn.utils.rnn</span> <span class="k">import</span> <span class="n">pad_sequence</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">25</span><span class="p">,</span> <span class="mi">300</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">22</span><span class="p">,</span> <span class="mi">300</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">300</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pad_sequence</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">])</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
<span class="go">torch.Size([25, 3, 300])</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This function returns a Tensor of size <code class="docutils literal notranslate"><span class="pre">T</span> <span class="pre">x</span> <span class="pre">B</span> <span class="pre">x</span> <span class="pre">*</span></code> or <code class="docutils literal notranslate"><span class="pre">B</span> <span class="pre">x</span> <span class="pre">T</span> <span class="pre">x</span> <span class="pre">*</span></code>
where <cite>T</cite> is the length of the longest sequence. This function assumes
trailing dimensions and type of all the Tensors in sequences are same.</p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sequences</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.7)"><em>list</em></a><em>[</em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>]</em>) – list of variable length sequences.</p></li>
<li><p><strong>batch_first</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – output will be in <code class="docutils literal notranslate"><span class="pre">B</span> <span class="pre">x</span> <span class="pre">T</span> <span class="pre">x</span> <span class="pre">*</span></code> if True, or in
<code class="docutils literal notranslate"><span class="pre">T</span> <span class="pre">x</span> <span class="pre">B</span> <span class="pre">x</span> <span class="pre">*</span></code> otherwise</p></li>
<li><p><strong>padding_value</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a><em>, </em><em>optional</em>) – value for padded elements. Default: 0.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>Tensor of size <code class="docutils literal notranslate"><span class="pre">T</span> <span class="pre">x</span> <span class="pre">B</span> <span class="pre">x</span> <span class="pre">*</span></code> if <code class="xref py py-attr docutils literal notranslate"><span class="pre">batch_first</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code>.
Tensor of size <code class="docutils literal notranslate"><span class="pre">B</span> <span class="pre">x</span> <span class="pre">T</span> <span class="pre">x</span> <span class="pre">*</span></code> otherwise</p>
</dd>
</dl>
</dd></dl>

</div>
<div class="section" id="pack-sequence">
<h3><span class="hidden-section">pack_sequence</span><a class="headerlink" href="#pack-sequence" title="Permalink to this headline">¶</a></h3>
<dl class="function">
<dt id="torch.nn.utils.rnn.pack_sequence">
<code class="sig-prename descclassname">torch.nn.utils.rnn.</code><code class="sig-name descname">pack_sequence</code><span class="sig-paren">(</span><em class="sig-param">sequences</em>, <em class="sig-param">enforce_sorted=True</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/nn/utils/rnn.html#pack_sequence"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.nn.utils.rnn.pack_sequence" title="Permalink to this definition">¶</a></dt>
<dd><p>Packs a list of variable length Tensors</p>
<p><code class="docutils literal notranslate"><span class="pre">sequences</span></code> should be a list of Tensors of size <code class="docutils literal notranslate"><span class="pre">L</span> <span class="pre">x</span> <span class="pre">*</span></code>, where <cite>L</cite> is
the length of a sequence and <cite>*</cite> is any number of trailing dimensions,
including zero.</p>
<p>For unsorted sequences, use <cite>enforce_sorted = False</cite>. If <code class="docutils literal notranslate"><span class="pre">enforce_sorted</span></code>
is <code class="docutils literal notranslate"><span class="pre">True</span></code>, the sequences should be sorted in the order of decreasing length.
<code class="docutils literal notranslate"><span class="pre">enforce_sorted</span> <span class="pre">=</span> <span class="pre">True</span></code> is only necessary for ONNX export.</p>
<p class="rubric">Example</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">torch.nn.utils.rnn</span> <span class="k">import</span> <span class="n">pack_sequence</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">a</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">6</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pack_sequence</span><span class="p">([</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span><span class="p">])</span>
<span class="go">PackedSequence(data=tensor([ 1,  4,  6,  2,  5,  3]), batch_sizes=tensor([ 3,  2,  1]))</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sequences</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#list" title="(in Python v3.7)"><em>list</em></a><em>[</em><a class="reference internal" href="tensors.html#torch.Tensor" title="torch.Tensor"><em>Tensor</em></a><em>]</em>) – A list of sequences of decreasing length.</p></li>
<li><p><strong>enforce_sorted</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.7)"><em>bool</em></a><em>, </em><em>optional</em>) – if <code class="docutils literal notranslate"><span class="pre">True</span></code>, checks that the input
contains sequences sorted by length in a decreasing order. If
<code class="docutils literal notranslate"><span class="pre">False</span></code>, this condition is not checked. Default: <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a <a class="reference internal" href="#torch.nn.utils.rnn.PackedSequence" title="torch.nn.utils.rnn.PackedSequence"><code class="xref py py-class docutils literal notranslate"><span class="pre">PackedSequence</span></code></a> object</p>
</dd>
</dl>
</dd></dl>

</div>
</div>
</div>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="nn.functional.html" class="btn btn-neutral float-right" title="torch.nn.functional" accesskey="n" rel="next">Next <img src="_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="storage.html" class="btn btn-neutral" title="torch.Storage" accesskey="p" rel="prev"><img src="_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Torch Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">torch.nn</a><ul>
<li><a class="reference internal" href="#parameters">Parameters</a></li>
<li><a class="reference internal" href="#containers">Containers</a><ul>
<li><a class="reference internal" href="#module"><span class="hidden-section">Module</span></a></li>
<li><a class="reference internal" href="#sequential"><span class="hidden-section">Sequential</span></a></li>
<li><a class="reference internal" href="#modulelist"><span class="hidden-section">ModuleList</span></a></li>
<li><a class="reference internal" href="#moduledict"><span class="hidden-section">ModuleDict</span></a></li>
<li><a class="reference internal" href="#parameterlist"><span class="hidden-section">ParameterList</span></a></li>
<li><a class="reference internal" href="#parameterdict"><span class="hidden-section">ParameterDict</span></a></li>
</ul>
</li>
<li><a class="reference internal" href="#convolution-layers">Convolution layers</a><ul>
<li><a class="reference internal" href="#conv1d"><span class="hidden-section">Conv1d</span></a></li>
<li><a class="reference internal" href="#conv2d"><span class="hidden-section">Conv2d</span></a></li>
<li><a class="reference internal" href="#conv3d"><span class="hidden-section">Conv3d</span></a></li>
<li><a class="reference internal" href="#convtranspose1d"><span class="hidden-section">ConvTranspose1d</span></a></li>
<li><a class="reference internal" href="#convtranspose2d"><span class="hidden-section">ConvTranspose2d</span></a></li>
<li><a class="reference internal" href="#convtranspose3d"><span class="hidden-section">ConvTranspose3d</span></a></li>
<li><a class="reference internal" href="#unfold"><span class="hidden-section">Unfold</span></a></li>
<li><a class="reference internal" href="#fold"><span class="hidden-section">Fold</span></a></li>
</ul>
</li>
<li><a class="reference internal" href="#pooling-layers">Pooling layers</a><ul>
<li><a class="reference internal" href="#maxpool1d"><span class="hidden-section">MaxPool1d</span></a></li>
<li><a class="reference internal" href="#maxpool2d"><span class="hidden-section">MaxPool2d</span></a></li>
<li><a class="reference internal" href="#maxpool3d"><span class="hidden-section">MaxPool3d</span></a></li>
<li><a class="reference internal" href="#maxunpool1d"><span class="hidden-section">MaxUnpool1d</span></a></li>
<li><a class="reference internal" href="#maxunpool2d"><span class="hidden-section">MaxUnpool2d</span></a></li>
<li><a class="reference internal" href="#maxunpool3d"><span class="hidden-section">MaxUnpool3d</span></a></li>
<li><a class="reference internal" href="#avgpool1d"><span class="hidden-section">AvgPool1d</span></a></li>
<li><a class="reference internal" href="#avgpool2d"><span class="hidden-section">AvgPool2d</span></a></li>
<li><a class="reference internal" href="#avgpool3d"><span class="hidden-section">AvgPool3d</span></a></li>
<li><a class="reference internal" href="#fractionalmaxpool2d"><span class="hidden-section">FractionalMaxPool2d</span></a></li>
<li><a class="reference internal" href="#lppool1d"><span class="hidden-section">LPPool1d</span></a></li>
<li><a class="reference internal" href="#lppool2d"><span class="hidden-section">LPPool2d</span></a></li>
<li><a class="reference internal" href="#adaptivemaxpool1d"><span class="hidden-section">AdaptiveMaxPool1d</span></a></li>
<li><a class="reference internal" href="#adaptivemaxpool2d"><span class="hidden-section">AdaptiveMaxPool2d</span></a></li>
<li><a class="reference internal" href="#adaptivemaxpool3d"><span class="hidden-section">AdaptiveMaxPool3d</span></a></li>
<li><a class="reference internal" href="#adaptiveavgpool1d"><span class="hidden-section">AdaptiveAvgPool1d</span></a></li>
<li><a class="reference internal" href="#adaptiveavgpool2d"><span class="hidden-section">AdaptiveAvgPool2d</span></a></li>
<li><a class="reference internal" href="#adaptiveavgpool3d"><span class="hidden-section">AdaptiveAvgPool3d</span></a></li>
</ul>
</li>
<li><a class="reference internal" href="#padding-layers">Padding layers</a><ul>
<li><a class="reference internal" href="#reflectionpad1d"><span class="hidden-section">ReflectionPad1d</span></a></li>
<li><a class="reference internal" href="#reflectionpad2d"><span class="hidden-section">ReflectionPad2d</span></a></li>
<li><a class="reference internal" href="#replicationpad1d"><span class="hidden-section">ReplicationPad1d</span></a></li>
<li><a class="reference internal" href="#replicationpad2d"><span class="hidden-section">ReplicationPad2d</span></a></li>
<li><a class="reference internal" href="#replicationpad3d"><span class="hidden-section">ReplicationPad3d</span></a></li>
<li><a class="reference internal" href="#zeropad2d"><span class="hidden-section">ZeroPad2d</span></a></li>
<li><a class="reference internal" href="#constantpad1d"><span class="hidden-section">ConstantPad1d</span></a></li>
<li><a class="reference internal" href="#constantpad2d"><span class="hidden-section">ConstantPad2d</span></a></li>
<li><a class="reference internal" href="#constantpad3d"><span class="hidden-section">ConstantPad3d</span></a></li>
</ul>
</li>
<li><a class="reference internal" href="#non-linear-activations-weighted-sum-nonlinearity">Non-linear activations (weighted sum, nonlinearity)</a><ul>
<li><a class="reference internal" href="#elu"><span class="hidden-section">ELU</span></a></li>
<li><a class="reference internal" href="#hardshrink"><span class="hidden-section">Hardshrink</span></a></li>
<li><a class="reference internal" href="#hardtanh"><span class="hidden-section">Hardtanh</span></a></li>
<li><a class="reference internal" href="#leakyrelu"><span class="hidden-section">LeakyReLU</span></a></li>
<li><a class="reference internal" href="#logsigmoid"><span class="hidden-section">LogSigmoid</span></a></li>
<li><a class="reference internal" href="#multiheadattention"><span class="hidden-section">MultiheadAttention</span></a></li>
<li><a class="reference internal" href="#prelu"><span class="hidden-section">PReLU</span></a></li>
<li><a class="reference internal" href="#relu"><span class="hidden-section">ReLU</span></a></li>
<li><a class="reference internal" href="#relu6"><span class="hidden-section">ReLU6</span></a></li>
<li><a class="reference internal" href="#rrelu"><span class="hidden-section">RReLU</span></a></li>
<li><a class="reference internal" href="#selu"><span class="hidden-section">SELU</span></a></li>
<li><a class="reference internal" href="#celu"><span class="hidden-section">CELU</span></a></li>
<li><a class="reference internal" href="#sigmoid"><span class="hidden-section">Sigmoid</span></a></li>
<li><a class="reference internal" href="#softplus"><span class="hidden-section">Softplus</span></a></li>
<li><a class="reference internal" href="#softshrink"><span class="hidden-section">Softshrink</span></a></li>
<li><a class="reference internal" href="#softsign"><span class="hidden-section">Softsign</span></a></li>
<li><a class="reference internal" href="#tanh"><span class="hidden-section">Tanh</span></a></li>
<li><a class="reference internal" href="#tanhshrink"><span class="hidden-section">Tanhshrink</span></a></li>
<li><a class="reference internal" href="#threshold"><span class="hidden-section">Threshold</span></a></li>
</ul>
</li>
<li><a class="reference internal" href="#non-linear-activations-other">Non-linear activations (other)</a><ul>
<li><a class="reference internal" href="#softmin"><span class="hidden-section">Softmin</span></a></li>
<li><a class="reference internal" href="#softmax"><span class="hidden-section">Softmax</span></a></li>
<li><a class="reference internal" href="#softmax2d"><span class="hidden-section">Softmax2d</span></a></li>
<li><a class="reference internal" href="#logsoftmax"><span class="hidden-section">LogSoftmax</span></a></li>
<li><a class="reference internal" href="#adaptivelogsoftmaxwithloss"><span class="hidden-section">AdaptiveLogSoftmaxWithLoss</span></a></li>
</ul>
</li>
<li><a class="reference internal" href="#normalization-layers">Normalization layers</a><ul>
<li><a class="reference internal" href="#batchnorm1d"><span class="hidden-section">BatchNorm1d</span></a></li>
<li><a class="reference internal" href="#batchnorm2d"><span class="hidden-section">BatchNorm2d</span></a></li>
<li><a class="reference internal" href="#batchnorm3d"><span class="hidden-section">BatchNorm3d</span></a></li>
<li><a class="reference internal" href="#groupnorm"><span class="hidden-section">GroupNorm</span></a></li>
<li><a class="reference internal" href="#syncbatchnorm"><span class="hidden-section">SyncBatchNorm</span></a></li>
<li><a class="reference internal" href="#instancenorm1d"><span class="hidden-section">InstanceNorm1d</span></a></li>
<li><a class="reference internal" href="#instancenorm2d"><span class="hidden-section">InstanceNorm2d</span></a></li>
<li><a class="reference internal" href="#instancenorm3d"><span class="hidden-section">InstanceNorm3d</span></a></li>
<li><a class="reference internal" href="#layernorm"><span class="hidden-section">LayerNorm</span></a></li>
<li><a class="reference internal" href="#localresponsenorm"><span class="hidden-section">LocalResponseNorm</span></a></li>
</ul>
</li>
<li><a class="reference internal" href="#recurrent-layers">Recurrent layers</a><ul>
<li><a class="reference internal" href="#rnn"><span class="hidden-section">RNN</span></a></li>
<li><a class="reference internal" href="#lstm"><span class="hidden-section">LSTM</span></a></li>
<li><a class="reference internal" href="#gru"><span class="hidden-section">GRU</span></a></li>
<li><a class="reference internal" href="#rnncell"><span class="hidden-section">RNNCell</span></a></li>
<li><a class="reference internal" href="#lstmcell"><span class="hidden-section">LSTMCell</span></a></li>
<li><a class="reference internal" href="#grucell"><span class="hidden-section">GRUCell</span></a></li>
</ul>
</li>
<li><a class="reference internal" href="#transformer-layers">Transformer layers</a><ul>
<li><a class="reference internal" href="#transformer"><span class="hidden-section">Transformer</span></a></li>
<li><a class="reference internal" href="#transformerencoder"><span class="hidden-section">TransformerEncoder</span></a></li>
<li><a class="reference internal" href="#transformerdecoder"><span class="hidden-section">TransformerDecoder</span></a></li>
<li><a class="reference internal" href="#transformerencoderlayer"><span class="hidden-section">TransformerEncoderLayer</span></a></li>
<li><a class="reference internal" href="#transformerdecoderlayer"><span class="hidden-section">TransformerDecoderLayer</span></a></li>
</ul>
</li>
<li><a class="reference internal" href="#linear-layers">Linear layers</a><ul>
<li><a class="reference internal" href="#identity"><span class="hidden-section">Identity</span></a></li>
<li><a class="reference internal" href="#linear"><span class="hidden-section">Linear</span></a></li>
<li><a class="reference internal" href="#bilinear"><span class="hidden-section">Bilinear</span></a></li>
</ul>
</li>
<li><a class="reference internal" href="#dropout-layers">Dropout layers</a><ul>
<li><a class="reference internal" href="#dropout"><span class="hidden-section">Dropout</span></a></li>
<li><a class="reference internal" href="#dropout2d"><span class="hidden-section">Dropout2d</span></a></li>
<li><a class="reference internal" href="#dropout3d"><span class="hidden-section">Dropout3d</span></a></li>
<li><a class="reference internal" href="#alphadropout"><span class="hidden-section">AlphaDropout</span></a></li>
</ul>
</li>
<li><a class="reference internal" href="#sparse-layers">Sparse layers</a><ul>
<li><a class="reference internal" href="#embedding"><span class="hidden-section">Embedding</span></a></li>
<li><a class="reference internal" href="#embeddingbag"><span class="hidden-section">EmbeddingBag</span></a></li>
</ul>
</li>
<li><a class="reference internal" href="#distance-functions">Distance functions</a><ul>
<li><a class="reference internal" href="#cosinesimilarity"><span class="hidden-section">CosineSimilarity</span></a></li>
<li><a class="reference internal" href="#pairwisedistance"><span class="hidden-section">PairwiseDistance</span></a></li>
</ul>
</li>
<li><a class="reference internal" href="#loss-functions">Loss functions</a><ul>
<li><a class="reference internal" href="#l1loss"><span class="hidden-section">L1Loss</span></a></li>
<li><a class="reference internal" href="#mseloss"><span class="hidden-section">MSELoss</span></a></li>
<li><a class="reference internal" href="#crossentropyloss"><span class="hidden-section">CrossEntropyLoss</span></a></li>
<li><a class="reference internal" href="#ctcloss"><span class="hidden-section">CTCLoss</span></a></li>
<li><a class="reference internal" href="#nllloss"><span class="hidden-section">NLLLoss</span></a></li>
<li><a class="reference internal" href="#poissonnllloss"><span class="hidden-section">PoissonNLLLoss</span></a></li>
<li><a class="reference internal" href="#kldivloss"><span class="hidden-section">KLDivLoss</span></a></li>
<li><a class="reference internal" href="#bceloss"><span class="hidden-section">BCELoss</span></a></li>
<li><a class="reference internal" href="#bcewithlogitsloss"><span class="hidden-section">BCEWithLogitsLoss</span></a></li>
<li><a class="reference internal" href="#marginrankingloss"><span class="hidden-section">MarginRankingLoss</span></a></li>
<li><a class="reference internal" href="#hingeembeddingloss"><span class="hidden-section">HingeEmbeddingLoss</span></a></li>
<li><a class="reference internal" href="#multilabelmarginloss"><span class="hidden-section">MultiLabelMarginLoss</span></a></li>
<li><a class="reference internal" href="#smoothl1loss"><span class="hidden-section">SmoothL1Loss</span></a></li>
<li><a class="reference internal" href="#softmarginloss"><span class="hidden-section">SoftMarginLoss</span></a></li>
<li><a class="reference internal" href="#multilabelsoftmarginloss"><span class="hidden-section">MultiLabelSoftMarginLoss</span></a></li>
<li><a class="reference internal" href="#cosineembeddingloss"><span class="hidden-section">CosineEmbeddingLoss</span></a></li>
<li><a class="reference internal" href="#multimarginloss"><span class="hidden-section">MultiMarginLoss</span></a></li>
<li><a class="reference internal" href="#tripletmarginloss"><span class="hidden-section">TripletMarginLoss</span></a></li>
</ul>
</li>
<li><a class="reference internal" href="#vision-layers">Vision layers</a><ul>
<li><a class="reference internal" href="#pixelshuffle"><span class="hidden-section">PixelShuffle</span></a></li>
<li><a class="reference internal" href="#upsample"><span class="hidden-section">Upsample</span></a></li>
<li><a class="reference internal" href="#upsamplingnearest2d"><span class="hidden-section">UpsamplingNearest2d</span></a></li>
<li><a class="reference internal" href="#upsamplingbilinear2d"><span class="hidden-section">UpsamplingBilinear2d</span></a></li>
</ul>
</li>
<li><a class="reference internal" href="#dataparallel-layers-multi-gpu-distributed">DataParallel layers (multi-GPU, distributed)</a><ul>
<li><a class="reference internal" href="#dataparallel"><span class="hidden-section">DataParallel</span></a></li>
<li><a class="reference internal" href="#distributeddataparallel"><span class="hidden-section">DistributedDataParallel</span></a></li>
</ul>
</li>
<li><a class="reference internal" href="#utilities">Utilities</a><ul>
<li><a class="reference internal" href="#clip-grad-norm"><span class="hidden-section">clip_grad_norm_</span></a></li>
<li><a class="reference internal" href="#clip-grad-value"><span class="hidden-section">clip_grad_value_</span></a></li>
<li><a class="reference internal" href="#parameters-to-vector"><span class="hidden-section">parameters_to_vector</span></a></li>
<li><a class="reference internal" href="#vector-to-parameters"><span class="hidden-section">vector_to_parameters</span></a></li>
<li><a class="reference internal" href="#weight-norm"><span class="hidden-section">weight_norm</span></a></li>
<li><a class="reference internal" href="#remove-weight-norm"><span class="hidden-section">remove_weight_norm</span></a></li>
<li><a class="reference internal" href="#spectral-norm"><span class="hidden-section">spectral_norm</span></a></li>
<li><a class="reference internal" href="#remove-spectral-norm"><span class="hidden-section">remove_spectral_norm</span></a></li>
<li><a class="reference internal" href="#packedsequence"><span class="hidden-section">PackedSequence</span></a></li>
<li><a class="reference internal" href="#pack-padded-sequence"><span class="hidden-section">pack_padded_sequence</span></a></li>
<li><a class="reference internal" href="#pad-packed-sequence"><span class="hidden-section">pad_packed_sequence</span></a></li>
<li><a class="reference internal" href="#pad-sequence"><span class="hidden-section">pad_sequence</span></a></li>
<li><a class="reference internal" href="#pack-sequence"><span class="hidden-section">pack_sequence</span></a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
         <script type="text/javascript" src="_static/jquery.js"></script>
         <script type="text/javascript" src="_static/underscore.js"></script>
         <script type="text/javascript" src="_static/doctools.js"></script>
         <script type="text/javascript" src="_static/language_data.js"></script>
     

  

  <script type="text/javascript" src="_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="_static/js/vendor/bootstrap.min.js"></script>
  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-90545585-1', 'auto');
  ga('send', 'pageview');

</script>

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"></script>

<script>
  window.dataLayer = window.dataLayer || [];

  function gtag(){dataLayer.push(arguments);}

  gtag('js', new Date());
  gtag('config', 'UA-117752657-2');
</script>

<img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://pytorch.org/resources">Resources</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/support">Support</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.slack.com" target="_blank">Slack</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md" target="_blank">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Follow Us</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="#">Get Started</a>
          </li>

          <li>
            <a href="#">Features</a>
          </li>

          <li>
            <a href="#">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/docs/stable/index.html">Docs</a>
          </li>

          <li>
            <a href="https://pytorch.org/resources">Resources</a>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>